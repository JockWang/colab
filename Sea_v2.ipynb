{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sea_v2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcQbpbqV1WWTV6TKYhe/8z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JockWang/colab/blob/master/Sea_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWFL_ywP9d0n",
        "colab_type": "code",
        "outputId": "7751db4d-0ca3-4ff0-c6e5-3e0d0c261dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBfshI2-AnbX",
        "colab_type": "code",
        "outputId": "ee5b9a37-5873-4db2-c67c-af9f6a1660d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "!pip install --upgrade tables\n",
        "!pip install catboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tables\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Installing collected packages: tables\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "Successfully installed tables-3.6.1\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ae/aaff63662f7f5d2af7ec8d61a6f39e78ada9348e5df4f43e665ecc4bea10/catboost-0.21-cp36-none-manylinux1_x86_64.whl (64.0MB)\n",
            "\u001b[K     |████████████████████████████████| 64.0MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.1.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (45.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIVe2VlA94Ej",
        "colab_type": "code",
        "outputId": "7cdaeb0f-addb-448e-c72d-ebeaf36263b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import catboost as cat\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import warnings\n",
        "from imblearn.over_sampling import SMOTE\n",
        "pd.set_option('display.max_rows', 50)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZxRM1h1-SBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_hdf('/content/drive/My Drive/Colab Notebooks/Sea/hy_round1_testA_20200102.h5')\n",
        "train = pd.read_hdf('/content/drive/My Drive/Colab Notebooks/Sea/hy_round1_train_20200102.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkkG5lJNEKBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getSecond(x):\n",
        "  day = str(x).split(' ')\n",
        "  base = int(day[0])*24*60*60\n",
        "  hour = int(day[1].split(':')[0])*60*60\n",
        "  minute = int(day[1].split(':')[1])*60\n",
        "  second = int(day[1].split(':')[-1])\n",
        "  return base+hour+minute+second"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf3DEaY2_UuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def base_feature(data,mode='train'):\n",
        "  train_data = data.sort_values(['ship','time'])\n",
        "  if mode == 'train':\n",
        "    type_map = dict(zip(['拖网','围网','刺网'], [0,1,2]))\n",
        "    train_data['type'] = train_data['type'].map(type_map)\n",
        "  train_data['second'] = train_data['time'].apply(getSecond)\n",
        "  train_data = train_data.drop(columns=['time'])\n",
        "  for col in list(train_data.columns):\n",
        "    if col not in ['ship','type','time']:\n",
        "      train_data[col+'_forward'] = train_data.groupby('ship')[col].apply(lambda x: x-x.shift(1))\n",
        "      if col != 'second':\n",
        "        train_data[col+'_forward'] = train_data[col+'_forward'].fillna(0)\n",
        "      else:\n",
        "        train_data[col+'_forward'] = train_data[col+'_forward'].fillna(600)\n",
        "  train_data['distance'] = (train_data['v']-train_data['v_forward']/2)*(train_data['second_forward']/3600)\n",
        "  return train_data\n",
        "def extract_feature(train_data):\n",
        "  data = train_data.copy()\n",
        "  df = data.groupby('ship')['distance','v'].sum()\n",
        "  df = pd.merge(df, data.groupby('ship')['distance'].count().to_frame(), how='left', on='ship')\n",
        "  for col in list(data.columns):\n",
        "    if col not in ['ship','type']:\n",
        "      temp = data.groupby('ship')[col].agg({col+'_min':'min', col+'_max':'max', col+'_mean':'mean', col+'_std':'std', col+'_skew':'skew'})\n",
        "      df = pd.merge(df, temp, how='left', on='ship')\n",
        "    if col == 'type':\n",
        "      type_df = data.groupby('ship')['type'].mean()\n",
        "      df = pd.merge(df, type_df, how='left', on='ship')\n",
        "  # times\n",
        "  temp = data.groupby('ship')['second'].apply(lambda x: x.max()-x.min()).to_frame()\n",
        "  df = pd.merge(df, temp, how='left', on='ship')\n",
        "  df['speed'] = df['distance_x']/df['second']\n",
        "  df['bias'] = df['v']/df['second']\n",
        "  df['x_max_x_min'] = df['x_max'] - df['x_min']\n",
        "  df['y_max_y_min'] = df['y_max'] - df['y_min']\n",
        "  df['area'] = df['x_max_x_min']*df['y_max_y_min']\n",
        "  return df.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCXsHB2CAVfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = base_feature(data=train)\n",
        "test_data = base_feature(data=test,mode='test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKuPQPHCP4L2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd.to_pickle(train_data, '/content/drive/My Drive/Colab Notebooks/Sea/train.pkl')\n",
        "# pd.to_pickle(test_data, '/content/drive/My Drive/Colab Notebooks/Sea/test.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KSD_3Y0USFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = extract_feature(train_data=train_data)\n",
        "test_dataset = extract_feature(train_data=test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjelP4o3bD7u",
        "colab_type": "code",
        "outputId": "3934d9b7-252e-4fec-95eb-3d2a2f3060f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train_dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ship</th>\n",
              "      <th>distance_x</th>\n",
              "      <th>v</th>\n",
              "      <th>distance_y</th>\n",
              "      <th>x_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>x_mean</th>\n",
              "      <th>x_std</th>\n",
              "      <th>x_skew</th>\n",
              "      <th>y_min</th>\n",
              "      <th>y_max</th>\n",
              "      <th>y_mean</th>\n",
              "      <th>y_std</th>\n",
              "      <th>y_skew</th>\n",
              "      <th>v_min</th>\n",
              "      <th>v_max</th>\n",
              "      <th>v_mean</th>\n",
              "      <th>v_std</th>\n",
              "      <th>v_skew</th>\n",
              "      <th>d_min</th>\n",
              "      <th>d_max</th>\n",
              "      <th>d_mean</th>\n",
              "      <th>d_std</th>\n",
              "      <th>d_skew</th>\n",
              "      <th>type</th>\n",
              "      <th>second_min</th>\n",
              "      <th>second_max</th>\n",
              "      <th>second_mean</th>\n",
              "      <th>second_std</th>\n",
              "      <th>second_skew</th>\n",
              "      <th>x_forward_min</th>\n",
              "      <th>x_forward_max</th>\n",
              "      <th>x_forward_mean</th>\n",
              "      <th>x_forward_std</th>\n",
              "      <th>x_forward_skew</th>\n",
              "      <th>y_forward_min</th>\n",
              "      <th>y_forward_max</th>\n",
              "      <th>y_forward_mean</th>\n",
              "      <th>y_forward_std</th>\n",
              "      <th>y_forward_skew</th>\n",
              "      <th>v_forward_min</th>\n",
              "      <th>v_forward_max</th>\n",
              "      <th>v_forward_mean</th>\n",
              "      <th>v_forward_std</th>\n",
              "      <th>v_forward_skew</th>\n",
              "      <th>d_forward_min</th>\n",
              "      <th>d_forward_max</th>\n",
              "      <th>d_forward_mean</th>\n",
              "      <th>d_forward_std</th>\n",
              "      <th>d_forward_skew</th>\n",
              "      <th>second_forward_min</th>\n",
              "      <th>second_forward_max</th>\n",
              "      <th>second_forward_mean</th>\n",
              "      <th>second_forward_std</th>\n",
              "      <th>second_forward_skew</th>\n",
              "      <th>distance_min</th>\n",
              "      <th>distance_max</th>\n",
              "      <th>distance_mean</th>\n",
              "      <th>distance_std</th>\n",
              "      <th>distance_skew</th>\n",
              "      <th>second</th>\n",
              "      <th>speed</th>\n",
              "      <th>bias</th>\n",
              "      <th>x_max_x_min</th>\n",
              "      <th>y_max_y_min</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19.471035</td>\n",
              "      <td>110.11</td>\n",
              "      <td>414</td>\n",
              "      <td>6.118352e+06</td>\n",
              "      <td>6.152038e+06</td>\n",
              "      <td>6.119351e+06</td>\n",
              "      <td>5037.320747</td>\n",
              "      <td>5.255558</td>\n",
              "      <td>5.124873e+06</td>\n",
              "      <td>5.130781e+06</td>\n",
              "      <td>5.130494e+06</td>\n",
              "      <td>850.264541</td>\n",
              "      <td>-4.762308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.39</td>\n",
              "      <td>0.265966</td>\n",
              "      <td>1.321248</td>\n",
              "      <td>5.520205</td>\n",
              "      <td>0</td>\n",
              "      <td>129</td>\n",
              "      <td>4.613527</td>\n",
              "      <td>21.247770</td>\n",
              "      <td>4.483093</td>\n",
              "      <td>0</td>\n",
              "      <td>95688568</td>\n",
              "      <td>95947099</td>\n",
              "      <td>9.581780e+07</td>\n",
              "      <td>74546.711433</td>\n",
              "      <td>-0.002061</td>\n",
              "      <td>-1.939802</td>\n",
              "      <td>3816.791567</td>\n",
              "      <td>81.368762</td>\n",
              "      <td>420.811680</td>\n",
              "      <td>5.887690</td>\n",
              "      <td>-2820.558404</td>\n",
              "      <td>620.168819</td>\n",
              "      <td>-14.007109</td>\n",
              "      <td>160.276396</td>\n",
              "      <td>-13.645926</td>\n",
              "      <td>-6.80</td>\n",
              "      <td>6.31</td>\n",
              "      <td>0.006256</td>\n",
              "      <td>0.498274</td>\n",
              "      <td>-0.806297</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0.246377</td>\n",
              "      <td>6.041196</td>\n",
              "      <td>15.817086</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2343.0</td>\n",
              "      <td>625.920290</td>\n",
              "      <td>168.254710</td>\n",
              "      <td>4.816803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.751217</td>\n",
              "      <td>0.047031</td>\n",
              "      <td>0.243856</td>\n",
              "      <td>6.663203</td>\n",
              "      <td>258531</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000426</td>\n",
              "      <td>33686.667453</td>\n",
              "      <td>5907.975523</td>\n",
              "      <td>1.990200e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>114.703739</td>\n",
              "      <td>619.05</td>\n",
              "      <td>385</td>\n",
              "      <td>6.049472e+06</td>\n",
              "      <td>6.102450e+06</td>\n",
              "      <td>6.091460e+06</td>\n",
              "      <td>16543.394419</td>\n",
              "      <td>-1.058454</td>\n",
              "      <td>5.042857e+06</td>\n",
              "      <td>5.112874e+06</td>\n",
              "      <td>5.094050e+06</td>\n",
              "      <td>26764.042729</td>\n",
              "      <td>-0.802446</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.47</td>\n",
              "      <td>1.607922</td>\n",
              "      <td>2.412688</td>\n",
              "      <td>1.590284</td>\n",
              "      <td>0</td>\n",
              "      <td>336</td>\n",
              "      <td>56.153247</td>\n",
              "      <td>91.449382</td>\n",
              "      <td>1.418867</td>\n",
              "      <td>0</td>\n",
              "      <td>95688034</td>\n",
              "      <td>95946021</td>\n",
              "      <td>9.581889e+07</td>\n",
              "      <td>75191.027261</td>\n",
              "      <td>-0.052810</td>\n",
              "      <td>-3521.669135</td>\n",
              "      <td>1645.199578</td>\n",
              "      <td>-68.040756</td>\n",
              "      <td>644.454376</td>\n",
              "      <td>-1.457187</td>\n",
              "      <td>-5621.840326</td>\n",
              "      <td>981.739643</td>\n",
              "      <td>-132.511905</td>\n",
              "      <td>723.286591</td>\n",
              "      <td>-3.455362</td>\n",
              "      <td>-3.19</td>\n",
              "      <td>4.58</td>\n",
              "      <td>0.010364</td>\n",
              "      <td>0.640811</td>\n",
              "      <td>1.466994</td>\n",
              "      <td>-309.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>0.722078</td>\n",
              "      <td>43.950590</td>\n",
              "      <td>1.072888</td>\n",
              "      <td>50.0</td>\n",
              "      <td>2948.0</td>\n",
              "      <td>671.654545</td>\n",
              "      <td>296.749689</td>\n",
              "      <td>4.362058</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.037467</td>\n",
              "      <td>0.297932</td>\n",
              "      <td>0.482421</td>\n",
              "      <td>2.247008</td>\n",
              "      <td>257987</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>52978.013345</td>\n",
              "      <td>70016.655842</td>\n",
              "      <td>3.709343e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>36.114347</td>\n",
              "      <td>138.67</td>\n",
              "      <td>233</td>\n",
              "      <td>6.182482e+06</td>\n",
              "      <td>6.183191e+06</td>\n",
              "      <td>6.183011e+06</td>\n",
              "      <td>207.869601</td>\n",
              "      <td>-2.155218</td>\n",
              "      <td>5.193576e+06</td>\n",
              "      <td>5.193696e+06</td>\n",
              "      <td>5.193682e+06</td>\n",
              "      <td>21.740609</td>\n",
              "      <td>-4.563165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.46</td>\n",
              "      <td>0.595150</td>\n",
              "      <td>3.415824</td>\n",
              "      <td>13.631590</td>\n",
              "      <td>0</td>\n",
              "      <td>360</td>\n",
              "      <td>123.356223</td>\n",
              "      <td>123.097127</td>\n",
              "      <td>0.657506</td>\n",
              "      <td>0</td>\n",
              "      <td>96293221</td>\n",
              "      <td>96550918</td>\n",
              "      <td>9.641397e+07</td>\n",
              "      <td>77479.193128</td>\n",
              "      <td>-0.008964</td>\n",
              "      <td>-101.262336</td>\n",
              "      <td>607.572811</td>\n",
              "      <td>2.607609</td>\n",
              "      <td>44.023529</td>\n",
              "      <td>11.249243</td>\n",
              "      <td>-109.260145</td>\n",
              "      <td>109.260145</td>\n",
              "      <td>-0.048519</td>\n",
              "      <td>30.444662</td>\n",
              "      <td>0.004600</td>\n",
              "      <td>-49.97</td>\n",
              "      <td>50.46</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>4.839439</td>\n",
              "      <td>0.140277</td>\n",
              "      <td>-351.0</td>\n",
              "      <td>353.0</td>\n",
              "      <td>-0.699571</td>\n",
              "      <td>161.985432</td>\n",
              "      <td>-0.014550</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3613.0</td>\n",
              "      <td>1108.570815</td>\n",
              "      <td>577.544300</td>\n",
              "      <td>0.470879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.562425</td>\n",
              "      <td>0.154997</td>\n",
              "      <td>0.453222</td>\n",
              "      <td>7.172655</td>\n",
              "      <td>257697</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.000538</td>\n",
              "      <td>708.835147</td>\n",
              "      <td>120.565000</td>\n",
              "      <td>8.546071e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>88.520229</td>\n",
              "      <td>492.90</td>\n",
              "      <td>335</td>\n",
              "      <td>5.228590e+06</td>\n",
              "      <td>5.287805e+06</td>\n",
              "      <td>5.239159e+06</td>\n",
              "      <td>17503.714347</td>\n",
              "      <td>1.608637</td>\n",
              "      <td>4.577467e+06</td>\n",
              "      <td>4.608628e+06</td>\n",
              "      <td>4.601532e+06</td>\n",
              "      <td>11590.605179</td>\n",
              "      <td>-1.194210</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.09</td>\n",
              "      <td>1.471343</td>\n",
              "      <td>2.528593</td>\n",
              "      <td>2.135446</td>\n",
              "      <td>0</td>\n",
              "      <td>352</td>\n",
              "      <td>121.134328</td>\n",
              "      <td>121.758165</td>\n",
              "      <td>0.469794</td>\n",
              "      <td>0</td>\n",
              "      <td>95688911</td>\n",
              "      <td>95946610</td>\n",
              "      <td>9.582413e+07</td>\n",
              "      <td>72643.328675</td>\n",
              "      <td>-0.165167</td>\n",
              "      <td>-2626.819263</td>\n",
              "      <td>2529.710292</td>\n",
              "      <td>3.758332</td>\n",
              "      <td>752.631229</td>\n",
              "      <td>0.450728</td>\n",
              "      <td>-3988.536391</td>\n",
              "      <td>2813.795154</td>\n",
              "      <td>5.329341</td>\n",
              "      <td>573.369647</td>\n",
              "      <td>-0.094017</td>\n",
              "      <td>-8.58</td>\n",
              "      <td>9.39</td>\n",
              "      <td>-0.004030</td>\n",
              "      <td>1.613107</td>\n",
              "      <td>0.214012</td>\n",
              "      <td>-328.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>-0.629851</td>\n",
              "      <td>117.016557</td>\n",
              "      <td>0.038799</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3025.0</td>\n",
              "      <td>771.041791</td>\n",
              "      <td>469.420663</td>\n",
              "      <td>1.288274</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.666940</td>\n",
              "      <td>0.264239</td>\n",
              "      <td>0.408792</td>\n",
              "      <td>1.904609</td>\n",
              "      <td>257699</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.001913</td>\n",
              "      <td>59214.738740</td>\n",
              "      <td>31160.661097</td>\n",
              "      <td>1.845170e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>104.498388</td>\n",
              "      <td>566.30</td>\n",
              "      <td>401</td>\n",
              "      <td>7.049394e+06</td>\n",
              "      <td>7.070797e+06</td>\n",
              "      <td>7.062005e+06</td>\n",
              "      <td>5979.578887</td>\n",
              "      <td>-0.596732</td>\n",
              "      <td>6.094996e+06</td>\n",
              "      <td>6.136033e+06</td>\n",
              "      <td>6.116389e+06</td>\n",
              "      <td>12055.148984</td>\n",
              "      <td>-0.331618</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.09</td>\n",
              "      <td>1.412219</td>\n",
              "      <td>2.496836</td>\n",
              "      <td>1.910336</td>\n",
              "      <td>0</td>\n",
              "      <td>359</td>\n",
              "      <td>139.067332</td>\n",
              "      <td>121.130025</td>\n",
              "      <td>0.372601</td>\n",
              "      <td>1</td>\n",
              "      <td>96292812</td>\n",
              "      <td>96551844</td>\n",
              "      <td>9.642151e+07</td>\n",
              "      <td>75855.456648</td>\n",
              "      <td>0.010843</td>\n",
              "      <td>-2603.619533</td>\n",
              "      <td>3556.700658</td>\n",
              "      <td>-9.382649</td>\n",
              "      <td>585.334897</td>\n",
              "      <td>-0.224270</td>\n",
              "      <td>-2354.712763</td>\n",
              "      <td>4910.804362</td>\n",
              "      <td>20.965048</td>\n",
              "      <td>673.238864</td>\n",
              "      <td>2.093895</td>\n",
              "      <td>-7.40</td>\n",
              "      <td>9.39</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>2.028397</td>\n",
              "      <td>0.356495</td>\n",
              "      <td>-351.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>-0.019950</td>\n",
              "      <td>151.983156</td>\n",
              "      <td>0.044284</td>\n",
              "      <td>537.0</td>\n",
              "      <td>2453.0</td>\n",
              "      <td>647.461347</td>\n",
              "      <td>186.231305</td>\n",
              "      <td>4.732627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.107556</td>\n",
              "      <td>0.260594</td>\n",
              "      <td>0.442751</td>\n",
              "      <td>2.319658</td>\n",
              "      <td>259032</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.002186</td>\n",
              "      <td>21402.484584</td>\n",
              "      <td>41036.883038</td>\n",
              "      <td>8.782913e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ship  distance_x       v  ...   x_max_x_min   y_max_y_min          area\n",
              "0     0   19.471035  110.11  ...  33686.667453   5907.975523  1.990200e+08\n",
              "1     1  114.703739  619.05  ...  52978.013345  70016.655842  3.709343e+09\n",
              "2     2   36.114347  138.67  ...    708.835147    120.565000  8.546071e+04\n",
              "3     3   88.520229  492.90  ...  59214.738740  31160.661097  1.845170e+09\n",
              "4     4  104.498388  566.30  ...  21402.484584  41036.883038  8.782913e+08\n",
              "\n",
              "[5 rows x 66 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNWtumpLF_1F",
        "colab_type": "code",
        "outputId": "2dc434c3-a653-4a8c-9878-72ca9ef6247f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "features = [col for col in list(train_dataset.columns) if col not in ['type']]\n",
        "x_middle, y_middle = train_dataset[features], train_dataset['type']\n",
        "x_final, y_final = SMOTE(random_state=2020).fit_sample(x_middle, y_middle)\n",
        "print(x_final.shape,y_final.shape)\n",
        "test_final = test_dataset[features]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13083, 65) (13083,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q7Jsuz5dsel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_final.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9KOBPvDecg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def selectMost(preds):\n",
        "  res = []\n",
        "  for i in range(preds.shape[1]):\n",
        "    res.append(Counter(preds[:,i]).most_common(1)[0][0])\n",
        "  return np.array(res)\n",
        "def finalRes(res):\n",
        "  result = []\n",
        "  for r in res:\n",
        "    result.append(yu_type[r])\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwmmBJstGDDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "  'objective': 'multiclass',\n",
        "  'num_class': 3,\n",
        "  'learning_rate': 0.01,\n",
        "  'num_leaves': 31,\n",
        "  'bagging_fraction': .8,\n",
        "  'feature_fraction': .8,\n",
        "  'lambda_l1': 0,\n",
        "  'lambda_l2': 0.5,\n",
        "  'early_stopping_rounds': 100,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkdNTWwHVp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LGBKfoldResult(train=x_final,test=test_final,label=y_final,params=params,K=20):\n",
        "  fold = StratifiedKFold(n_splits=K,shuffle=True)\n",
        "  preds = []\n",
        "  models = []\n",
        "  i = 0\n",
        "  for train_index, valid_index in fold.split(train,label):\n",
        "      print('第',str(i),'个Fold')\n",
        "      i += 1\n",
        "      # train_x,valid_x,train_y,valid_y = train.iloc[train_index],train.iloc[valid_index],label[train_index],label[valid_index]\n",
        "      train_x,valid_x,train_y,valid_y = train[train_index],train[valid_index],label[train_index],label[valid_index]\n",
        "      lgb_train = lgb.Dataset(train_x,train_y)\n",
        "      lgb_valid = lgb.Dataset(valid_x,valid_y)\n",
        "      model = lgb.train(params,train_set=lgb_train,valid_sets=lgb_valid,num_boost_round=5000,early_stopping_rounds=50, verbose_eval=50)\n",
        "      models.append(model)\n",
        "      val_pred = model.predict(valid_x,num_iteration=model.best_iteration).argmax(axis=1)\n",
        "      print(metrics.f1_score(valid_y, val_pred, average='macro'))\n",
        "      preds.append(model.predict(test,num_iteration=model.best_iteration).argmax(axis=1))\n",
        "  preds = np.array(preds)\n",
        "  return models,preds.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHHtqy4CI5GT",
        "colab_type": "code",
        "outputId": "ee3dbf0a-c50f-4642-e6e2-66cf549bb6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models, lgb_preds = LGBKfoldResult()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4400]\tvalid_0's multi_logloss: 0.131264\n",
            "[4450]\tvalid_0's multi_logloss: 0.131038\n",
            "[4500]\tvalid_0's multi_logloss: 0.130755\n",
            "[4550]\tvalid_0's multi_logloss: 0.130615\n",
            "[4600]\tvalid_0's multi_logloss: 0.130419\n",
            "[4650]\tvalid_0's multi_logloss: 0.130138\n",
            "[4700]\tvalid_0's multi_logloss: 0.129951\n",
            "[4750]\tvalid_0's multi_logloss: 0.129672\n",
            "[4800]\tvalid_0's multi_logloss: 0.129466\n",
            "[4850]\tvalid_0's multi_logloss: 0.129292\n",
            "[4900]\tvalid_0's multi_logloss: 0.129341\n",
            "[4950]\tvalid_0's multi_logloss: 0.129335\n",
            "Early stopping, best iteration is:\n",
            "[4854]\tvalid_0's multi_logloss: 0.129266\n",
            "0.9539956623289957\n",
            "第 13 个Fold\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's multi_logloss: 0.800993\n",
            "[100]\tvalid_0's multi_logloss: 0.639309\n",
            "[150]\tvalid_0's multi_logloss: 0.541364\n",
            "[200]\tvalid_0's multi_logloss: 0.476898\n",
            "[250]\tvalid_0's multi_logloss: 0.430513\n",
            "[300]\tvalid_0's multi_logloss: 0.396905\n",
            "[350]\tvalid_0's multi_logloss: 0.370666\n",
            "[400]\tvalid_0's multi_logloss: 0.348003\n",
            "[450]\tvalid_0's multi_logloss: 0.32942\n",
            "[500]\tvalid_0's multi_logloss: 0.313994\n",
            "[550]\tvalid_0's multi_logloss: 0.300889\n",
            "[600]\tvalid_0's multi_logloss: 0.289516\n",
            "[650]\tvalid_0's multi_logloss: 0.278919\n",
            "[700]\tvalid_0's multi_logloss: 0.269941\n",
            "[750]\tvalid_0's multi_logloss: 0.262167\n",
            "[800]\tvalid_0's multi_logloss: 0.254742\n",
            "[850]\tvalid_0's multi_logloss: 0.247971\n",
            "[900]\tvalid_0's multi_logloss: 0.241183\n",
            "[950]\tvalid_0's multi_logloss: 0.235378\n",
            "[1000]\tvalid_0's multi_logloss: 0.230169\n",
            "[1050]\tvalid_0's multi_logloss: 0.224957\n",
            "[1100]\tvalid_0's multi_logloss: 0.220106\n",
            "[1150]\tvalid_0's multi_logloss: 0.215747\n",
            "[1200]\tvalid_0's multi_logloss: 0.211687\n",
            "[1250]\tvalid_0's multi_logloss: 0.20795\n",
            "[1300]\tvalid_0's multi_logloss: 0.204313\n",
            "[1350]\tvalid_0's multi_logloss: 0.200943\n",
            "[1400]\tvalid_0's multi_logloss: 0.19786\n",
            "[1450]\tvalid_0's multi_logloss: 0.194789\n",
            "[1500]\tvalid_0's multi_logloss: 0.191642\n",
            "[1550]\tvalid_0's multi_logloss: 0.188909\n",
            "[1600]\tvalid_0's multi_logloss: 0.186256\n",
            "[1650]\tvalid_0's multi_logloss: 0.18405\n",
            "[1700]\tvalid_0's multi_logloss: 0.181932\n",
            "[1750]\tvalid_0's multi_logloss: 0.180096\n",
            "[1800]\tvalid_0's multi_logloss: 0.17811\n",
            "[1850]\tvalid_0's multi_logloss: 0.17617\n",
            "[1900]\tvalid_0's multi_logloss: 0.174185\n",
            "[1950]\tvalid_0's multi_logloss: 0.172437\n",
            "[2000]\tvalid_0's multi_logloss: 0.170787\n",
            "[2050]\tvalid_0's multi_logloss: 0.168962\n",
            "[2100]\tvalid_0's multi_logloss: 0.167018\n",
            "[2150]\tvalid_0's multi_logloss: 0.165394\n",
            "[2200]\tvalid_0's multi_logloss: 0.163866\n",
            "[2250]\tvalid_0's multi_logloss: 0.16258\n",
            "[2300]\tvalid_0's multi_logloss: 0.161229\n",
            "[2350]\tvalid_0's multi_logloss: 0.160053\n",
            "[2400]\tvalid_0's multi_logloss: 0.158714\n",
            "[2450]\tvalid_0's multi_logloss: 0.157489\n",
            "[2500]\tvalid_0's multi_logloss: 0.156174\n",
            "[2550]\tvalid_0's multi_logloss: 0.155214\n",
            "[2600]\tvalid_0's multi_logloss: 0.154181\n",
            "[2650]\tvalid_0's multi_logloss: 0.153411\n",
            "[2700]\tvalid_0's multi_logloss: 0.152618\n",
            "[2750]\tvalid_0's multi_logloss: 0.151775\n",
            "[2800]\tvalid_0's multi_logloss: 0.151053\n",
            "[2850]\tvalid_0's multi_logloss: 0.15022\n",
            "[2900]\tvalid_0's multi_logloss: 0.149468\n",
            "[2950]\tvalid_0's multi_logloss: 0.148699\n",
            "[3000]\tvalid_0's multi_logloss: 0.148141\n",
            "[3050]\tvalid_0's multi_logloss: 0.147413\n",
            "[3100]\tvalid_0's multi_logloss: 0.146729\n",
            "[3150]\tvalid_0's multi_logloss: 0.146052\n",
            "[3200]\tvalid_0's multi_logloss: 0.145339\n",
            "[3250]\tvalid_0's multi_logloss: 0.144716\n",
            "[3300]\tvalid_0's multi_logloss: 0.144247\n",
            "[3350]\tvalid_0's multi_logloss: 0.14396\n",
            "[3400]\tvalid_0's multi_logloss: 0.143269\n",
            "[3450]\tvalid_0's multi_logloss: 0.142674\n",
            "[3500]\tvalid_0's multi_logloss: 0.142263\n",
            "[3550]\tvalid_0's multi_logloss: 0.141935\n",
            "[3600]\tvalid_0's multi_logloss: 0.141528\n",
            "[3650]\tvalid_0's multi_logloss: 0.14108\n",
            "[3700]\tvalid_0's multi_logloss: 0.14063\n",
            "[3750]\tvalid_0's multi_logloss: 0.139995\n",
            "[3800]\tvalid_0's multi_logloss: 0.139603\n",
            "[3850]\tvalid_0's multi_logloss: 0.139311\n",
            "[3900]\tvalid_0's multi_logloss: 0.138864\n",
            "[3950]\tvalid_0's multi_logloss: 0.138392\n",
            "[4000]\tvalid_0's multi_logloss: 0.138161\n",
            "[4050]\tvalid_0's multi_logloss: 0.137893\n",
            "[4100]\tvalid_0's multi_logloss: 0.137697\n",
            "[4150]\tvalid_0's multi_logloss: 0.137378\n",
            "[4200]\tvalid_0's multi_logloss: 0.13718\n",
            "[4250]\tvalid_0's multi_logloss: 0.136936\n",
            "[4300]\tvalid_0's multi_logloss: 0.136765\n",
            "[4350]\tvalid_0's multi_logloss: 0.136574\n",
            "[4400]\tvalid_0's multi_logloss: 0.136288\n",
            "[4450]\tvalid_0's multi_logloss: 0.13608\n",
            "[4500]\tvalid_0's multi_logloss: 0.135859\n",
            "[4550]\tvalid_0's multi_logloss: 0.135693\n",
            "[4600]\tvalid_0's multi_logloss: 0.135567\n",
            "[4650]\tvalid_0's multi_logloss: 0.135507\n",
            "[4700]\tvalid_0's multi_logloss: 0.135364\n",
            "[4750]\tvalid_0's multi_logloss: 0.135257\n",
            "[4800]\tvalid_0's multi_logloss: 0.135159\n",
            "[4850]\tvalid_0's multi_logloss: 0.135125\n",
            "[4900]\tvalid_0's multi_logloss: 0.135059\n",
            "[4950]\tvalid_0's multi_logloss: 0.135035\n",
            "[5000]\tvalid_0's multi_logloss: 0.13506\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[4916]\tvalid_0's multi_logloss: 0.134934\n",
            "0.949436008673648\n",
            "第 14 个Fold\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's multi_logloss: 0.801107\n",
            "[100]\tvalid_0's multi_logloss: 0.640608\n",
            "[150]\tvalid_0's multi_logloss: 0.541314\n",
            "[200]\tvalid_0's multi_logloss: 0.476558\n",
            "[250]\tvalid_0's multi_logloss: 0.430367\n",
            "[300]\tvalid_0's multi_logloss: 0.395465\n",
            "[350]\tvalid_0's multi_logloss: 0.367262\n",
            "[400]\tvalid_0's multi_logloss: 0.345536\n",
            "[450]\tvalid_0's multi_logloss: 0.326035\n",
            "[500]\tvalid_0's multi_logloss: 0.308877\n",
            "[550]\tvalid_0's multi_logloss: 0.292868\n",
            "[600]\tvalid_0's multi_logloss: 0.280329\n",
            "[650]\tvalid_0's multi_logloss: 0.268402\n",
            "[700]\tvalid_0's multi_logloss: 0.258203\n",
            "[750]\tvalid_0's multi_logloss: 0.248787\n",
            "[800]\tvalid_0's multi_logloss: 0.240928\n",
            "[850]\tvalid_0's multi_logloss: 0.234239\n",
            "[900]\tvalid_0's multi_logloss: 0.228357\n",
            "[950]\tvalid_0's multi_logloss: 0.222914\n",
            "[1000]\tvalid_0's multi_logloss: 0.218065\n",
            "[1050]\tvalid_0's multi_logloss: 0.213601\n",
            "[1100]\tvalid_0's multi_logloss: 0.209365\n",
            "[1150]\tvalid_0's multi_logloss: 0.205601\n",
            "[1200]\tvalid_0's multi_logloss: 0.202096\n",
            "[1250]\tvalid_0's multi_logloss: 0.198511\n",
            "[1300]\tvalid_0's multi_logloss: 0.195328\n",
            "[1350]\tvalid_0's multi_logloss: 0.192383\n",
            "[1400]\tvalid_0's multi_logloss: 0.18965\n",
            "[1450]\tvalid_0's multi_logloss: 0.187084\n",
            "[1500]\tvalid_0's multi_logloss: 0.184835\n",
            "[1550]\tvalid_0's multi_logloss: 0.182443\n",
            "[1600]\tvalid_0's multi_logloss: 0.180415\n",
            "[1650]\tvalid_0's multi_logloss: 0.178262\n",
            "[1700]\tvalid_0's multi_logloss: 0.176336\n",
            "[1750]\tvalid_0's multi_logloss: 0.174602\n",
            "[1800]\tvalid_0's multi_logloss: 0.172702\n",
            "[1850]\tvalid_0's multi_logloss: 0.170951\n",
            "[1900]\tvalid_0's multi_logloss: 0.169307\n",
            "[1950]\tvalid_0's multi_logloss: 0.167862\n",
            "[2000]\tvalid_0's multi_logloss: 0.166546\n",
            "[2050]\tvalid_0's multi_logloss: 0.165098\n",
            "[2100]\tvalid_0's multi_logloss: 0.163563\n",
            "[2150]\tvalid_0's multi_logloss: 0.162279\n",
            "[2200]\tvalid_0's multi_logloss: 0.160976\n",
            "[2250]\tvalid_0's multi_logloss: 0.15984\n",
            "[2300]\tvalid_0's multi_logloss: 0.158753\n",
            "[2350]\tvalid_0's multi_logloss: 0.157804\n",
            "[2400]\tvalid_0's multi_logloss: 0.156849\n",
            "[2450]\tvalid_0's multi_logloss: 0.155986\n",
            "[2500]\tvalid_0's multi_logloss: 0.15514\n",
            "[2550]\tvalid_0's multi_logloss: 0.15439\n",
            "[2600]\tvalid_0's multi_logloss: 0.153554\n",
            "[2650]\tvalid_0's multi_logloss: 0.152846\n",
            "[2700]\tvalid_0's multi_logloss: 0.152199\n",
            "[2750]\tvalid_0's multi_logloss: 0.151384\n",
            "[2800]\tvalid_0's multi_logloss: 0.150734\n",
            "[2850]\tvalid_0's multi_logloss: 0.149997\n",
            "[2900]\tvalid_0's multi_logloss: 0.149101\n",
            "[2950]\tvalid_0's multi_logloss: 0.148486\n",
            "[3000]\tvalid_0's multi_logloss: 0.147785\n",
            "[3050]\tvalid_0's multi_logloss: 0.147311\n",
            "[3100]\tvalid_0's multi_logloss: 0.146687\n",
            "[3150]\tvalid_0's multi_logloss: 0.146202\n",
            "[3200]\tvalid_0's multi_logloss: 0.145832\n",
            "[3250]\tvalid_0's multi_logloss: 0.145282\n",
            "[3300]\tvalid_0's multi_logloss: 0.144866\n",
            "[3350]\tvalid_0's multi_logloss: 0.144375\n",
            "[3400]\tvalid_0's multi_logloss: 0.144034\n",
            "[3450]\tvalid_0's multi_logloss: 0.143744\n",
            "[3500]\tvalid_0's multi_logloss: 0.143413\n",
            "[3550]\tvalid_0's multi_logloss: 0.143078\n",
            "[3600]\tvalid_0's multi_logloss: 0.142767\n",
            "[3650]\tvalid_0's multi_logloss: 0.142123\n",
            "[3700]\tvalid_0's multi_logloss: 0.141783\n",
            "[3750]\tvalid_0's multi_logloss: 0.141359\n",
            "[3800]\tvalid_0's multi_logloss: 0.141102\n",
            "[3850]\tvalid_0's multi_logloss: 0.140848\n",
            "[3900]\tvalid_0's multi_logloss: 0.140557\n",
            "[3950]\tvalid_0's multi_logloss: 0.140194\n",
            "[4000]\tvalid_0's multi_logloss: 0.140002\n",
            "[4050]\tvalid_0's multi_logloss: 0.139643\n",
            "[4100]\tvalid_0's multi_logloss: 0.13943\n",
            "[4150]\tvalid_0's multi_logloss: 0.139083\n",
            "[4200]\tvalid_0's multi_logloss: 0.138833\n",
            "[4250]\tvalid_0's multi_logloss: 0.13848\n",
            "[4300]\tvalid_0's multi_logloss: 0.138211\n",
            "[4350]\tvalid_0's multi_logloss: 0.138092\n",
            "[4400]\tvalid_0's multi_logloss: 0.137873\n",
            "[4450]\tvalid_0's multi_logloss: 0.137635\n",
            "[4500]\tvalid_0's multi_logloss: 0.13735\n",
            "[4550]\tvalid_0's multi_logloss: 0.13708\n",
            "[4600]\tvalid_0's multi_logloss: 0.137053\n",
            "[4650]\tvalid_0's multi_logloss: 0.137107\n",
            "Early stopping, best iteration is:\n",
            "[4593]\tvalid_0's multi_logloss: 0.136971\n",
            "0.9525841751963284\n",
            "第 15 个Fold\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's multi_logloss: 0.799682\n",
            "[100]\tvalid_0's multi_logloss: 0.63771\n",
            "[150]\tvalid_0's multi_logloss: 0.54091\n",
            "[200]\tvalid_0's multi_logloss: 0.476001\n",
            "[250]\tvalid_0's multi_logloss: 0.430543\n",
            "[300]\tvalid_0's multi_logloss: 0.396266\n",
            "[350]\tvalid_0's multi_logloss: 0.369494\n",
            "[400]\tvalid_0's multi_logloss: 0.349451\n",
            "[450]\tvalid_0's multi_logloss: 0.33224\n",
            "[500]\tvalid_0's multi_logloss: 0.31705\n",
            "[550]\tvalid_0's multi_logloss: 0.304221\n",
            "[600]\tvalid_0's multi_logloss: 0.293186\n",
            "[650]\tvalid_0's multi_logloss: 0.283257\n",
            "[700]\tvalid_0's multi_logloss: 0.274309\n",
            "[750]\tvalid_0's multi_logloss: 0.266546\n",
            "[800]\tvalid_0's multi_logloss: 0.259447\n",
            "[850]\tvalid_0's multi_logloss: 0.252798\n",
            "[900]\tvalid_0's multi_logloss: 0.247137\n",
            "[950]\tvalid_0's multi_logloss: 0.241571\n",
            "[1000]\tvalid_0's multi_logloss: 0.236701\n",
            "[1050]\tvalid_0's multi_logloss: 0.232101\n",
            "[1100]\tvalid_0's multi_logloss: 0.227825\n",
            "[1150]\tvalid_0's multi_logloss: 0.224343\n",
            "[1200]\tvalid_0's multi_logloss: 0.219959\n",
            "[1250]\tvalid_0's multi_logloss: 0.216378\n",
            "[1300]\tvalid_0's multi_logloss: 0.212715\n",
            "[1350]\tvalid_0's multi_logloss: 0.209441\n",
            "[1400]\tvalid_0's multi_logloss: 0.206833\n",
            "[1450]\tvalid_0's multi_logloss: 0.204069\n",
            "[1500]\tvalid_0's multi_logloss: 0.201362\n",
            "[1550]\tvalid_0's multi_logloss: 0.198801\n",
            "[1600]\tvalid_0's multi_logloss: 0.196627\n",
            "[1650]\tvalid_0's multi_logloss: 0.194479\n",
            "[1700]\tvalid_0's multi_logloss: 0.192333\n",
            "[1750]\tvalid_0's multi_logloss: 0.190402\n",
            "[1800]\tvalid_0's multi_logloss: 0.188477\n",
            "[1850]\tvalid_0's multi_logloss: 0.187027\n",
            "[1900]\tvalid_0's multi_logloss: 0.185565\n",
            "[1950]\tvalid_0's multi_logloss: 0.183704\n",
            "[2000]\tvalid_0's multi_logloss: 0.181761\n",
            "[2050]\tvalid_0's multi_logloss: 0.179913\n",
            "[2100]\tvalid_0's multi_logloss: 0.178389\n",
            "[2150]\tvalid_0's multi_logloss: 0.177047\n",
            "[2200]\tvalid_0's multi_logloss: 0.17551\n",
            "[2250]\tvalid_0's multi_logloss: 0.174351\n",
            "[2300]\tvalid_0's multi_logloss: 0.173004\n",
            "[2350]\tvalid_0's multi_logloss: 0.17176\n",
            "[2400]\tvalid_0's multi_logloss: 0.170758\n",
            "[2450]\tvalid_0's multi_logloss: 0.169926\n",
            "[2500]\tvalid_0's multi_logloss: 0.169095\n",
            "[2550]\tvalid_0's multi_logloss: 0.16781\n",
            "[2600]\tvalid_0's multi_logloss: 0.16708\n",
            "[2650]\tvalid_0's multi_logloss: 0.166484\n",
            "[2700]\tvalid_0's multi_logloss: 0.165698\n",
            "[2750]\tvalid_0's multi_logloss: 0.16495\n",
            "[2800]\tvalid_0's multi_logloss: 0.164177\n",
            "[2850]\tvalid_0's multi_logloss: 0.163313\n",
            "[2900]\tvalid_0's multi_logloss: 0.162934\n",
            "[2950]\tvalid_0's multi_logloss: 0.162416\n",
            "[3000]\tvalid_0's multi_logloss: 0.162139\n",
            "[3050]\tvalid_0's multi_logloss: 0.161452\n",
            "[3100]\tvalid_0's multi_logloss: 0.161049\n",
            "[3150]\tvalid_0's multi_logloss: 0.160367\n",
            "[3200]\tvalid_0's multi_logloss: 0.15966\n",
            "[3250]\tvalid_0's multi_logloss: 0.158989\n",
            "[3300]\tvalid_0's multi_logloss: 0.158598\n",
            "[3350]\tvalid_0's multi_logloss: 0.158294\n",
            "[3400]\tvalid_0's multi_logloss: 0.157654\n",
            "[3450]\tvalid_0's multi_logloss: 0.157275\n",
            "[3500]\tvalid_0's multi_logloss: 0.15691\n",
            "[3550]\tvalid_0's multi_logloss: 0.156495\n",
            "[3600]\tvalid_0's multi_logloss: 0.156042\n",
            "[3650]\tvalid_0's multi_logloss: 0.155642\n",
            "[3700]\tvalid_0's multi_logloss: 0.155366\n",
            "[3750]\tvalid_0's multi_logloss: 0.154923\n",
            "[3800]\tvalid_0's multi_logloss: 0.154756\n",
            "[3850]\tvalid_0's multi_logloss: 0.154395\n",
            "[3900]\tvalid_0's multi_logloss: 0.153952\n",
            "[3950]\tvalid_0's multi_logloss: 0.153722\n",
            "[4000]\tvalid_0's multi_logloss: 0.153385\n",
            "[4050]\tvalid_0's multi_logloss: 0.153424\n",
            "[4100]\tvalid_0's multi_logloss: 0.153415\n",
            "Early stopping, best iteration is:\n",
            "[4042]\tvalid_0's multi_logloss: 0.15328\n",
            "0.9432902731991382\n",
            "第 16 个Fold\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's multi_logloss: 0.797759\n",
            "[100]\tvalid_0's multi_logloss: 0.637046\n",
            "[150]\tvalid_0's multi_logloss: 0.542138\n",
            "[200]\tvalid_0's multi_logloss: 0.479671\n",
            "[250]\tvalid_0's multi_logloss: 0.435919\n",
            "[300]\tvalid_0's multi_logloss: 0.404586\n",
            "[350]\tvalid_0's multi_logloss: 0.378147\n",
            "[400]\tvalid_0's multi_logloss: 0.355724\n",
            "[450]\tvalid_0's multi_logloss: 0.335891\n",
            "[500]\tvalid_0's multi_logloss: 0.318126\n",
            "[550]\tvalid_0's multi_logloss: 0.303119\n",
            "[600]\tvalid_0's multi_logloss: 0.289311\n",
            "[650]\tvalid_0's multi_logloss: 0.277921\n",
            "[700]\tvalid_0's multi_logloss: 0.268131\n",
            "[750]\tvalid_0's multi_logloss: 0.259417\n",
            "[800]\tvalid_0's multi_logloss: 0.252271\n",
            "[850]\tvalid_0's multi_logloss: 0.245051\n",
            "[900]\tvalid_0's multi_logloss: 0.238933\n",
            "[950]\tvalid_0's multi_logloss: 0.23344\n",
            "[1000]\tvalid_0's multi_logloss: 0.228605\n",
            "[1050]\tvalid_0's multi_logloss: 0.223933\n",
            "[1100]\tvalid_0's multi_logloss: 0.21993\n",
            "[1150]\tvalid_0's multi_logloss: 0.215933\n",
            "[1200]\tvalid_0's multi_logloss: 0.212371\n",
            "[1250]\tvalid_0's multi_logloss: 0.208482\n",
            "[1300]\tvalid_0's multi_logloss: 0.204902\n",
            "[1350]\tvalid_0's multi_logloss: 0.201632\n",
            "[1400]\tvalid_0's multi_logloss: 0.198352\n",
            "[1450]\tvalid_0's multi_logloss: 0.195479\n",
            "[1500]\tvalid_0's multi_logloss: 0.192914\n",
            "[1550]\tvalid_0's multi_logloss: 0.190494\n",
            "[1600]\tvalid_0's multi_logloss: 0.188115\n",
            "[1650]\tvalid_0's multi_logloss: 0.185889\n",
            "[1700]\tvalid_0's multi_logloss: 0.183982\n",
            "[1750]\tvalid_0's multi_logloss: 0.182092\n",
            "[1800]\tvalid_0's multi_logloss: 0.180159\n",
            "[1850]\tvalid_0's multi_logloss: 0.178468\n",
            "[1900]\tvalid_0's multi_logloss: 0.176879\n",
            "[1950]\tvalid_0's multi_logloss: 0.175504\n",
            "[2000]\tvalid_0's multi_logloss: 0.173942\n",
            "[2050]\tvalid_0's multi_logloss: 0.172589\n",
            "[2100]\tvalid_0's multi_logloss: 0.171021\n",
            "[2150]\tvalid_0's multi_logloss: 0.169693\n",
            "[2200]\tvalid_0's multi_logloss: 0.168394\n",
            "[2250]\tvalid_0's multi_logloss: 0.167278\n",
            "[2300]\tvalid_0's multi_logloss: 0.165877\n",
            "[2350]\tvalid_0's multi_logloss: 0.164671\n",
            "[2400]\tvalid_0's multi_logloss: 0.163605\n",
            "[2450]\tvalid_0's multi_logloss: 0.162537\n",
            "[2500]\tvalid_0's multi_logloss: 0.161454\n",
            "[2550]\tvalid_0's multi_logloss: 0.160295\n",
            "[2600]\tvalid_0's multi_logloss: 0.159359\n",
            "[2650]\tvalid_0's multi_logloss: 0.158496\n",
            "[2700]\tvalid_0's multi_logloss: 0.157753\n",
            "[2750]\tvalid_0's multi_logloss: 0.157016\n",
            "[2800]\tvalid_0's multi_logloss: 0.156321\n",
            "[2850]\tvalid_0's multi_logloss: 0.155704\n",
            "[2900]\tvalid_0's multi_logloss: 0.154954\n",
            "[2950]\tvalid_0's multi_logloss: 0.154436\n",
            "[3000]\tvalid_0's multi_logloss: 0.153926\n",
            "[3050]\tvalid_0's multi_logloss: 0.153476\n",
            "[3100]\tvalid_0's multi_logloss: 0.153112\n",
            "[3150]\tvalid_0's multi_logloss: 0.152938\n",
            "[3200]\tvalid_0's multi_logloss: 0.152415\n",
            "[3250]\tvalid_0's multi_logloss: 0.152006\n",
            "[3300]\tvalid_0's multi_logloss: 0.151652\n",
            "[3350]\tvalid_0's multi_logloss: 0.15137\n",
            "[3400]\tvalid_0's multi_logloss: 0.151193\n",
            "[3450]\tvalid_0's multi_logloss: 0.150987\n",
            "[3500]\tvalid_0's multi_logloss: 0.150855\n",
            "[3550]\tvalid_0's multi_logloss: 0.150708\n",
            "[3600]\tvalid_0's multi_logloss: 0.150267\n",
            "[3650]\tvalid_0's multi_logloss: 0.150093\n",
            "[3700]\tvalid_0's multi_logloss: 0.149897\n",
            "[3750]\tvalid_0's multi_logloss: 0.149715\n",
            "[3800]\tvalid_0's multi_logloss: 0.149901\n",
            "Early stopping, best iteration is:\n",
            "[3744]\tvalid_0's multi_logloss: 0.149684\n",
            "0.9434453665400548\n",
            "第 17 个Fold\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's multi_logloss: 0.79096\n",
            "[100]\tvalid_0's multi_logloss: 0.623063\n",
            "[150]\tvalid_0's multi_logloss: 0.523124\n",
            "[200]\tvalid_0's multi_logloss: 0.458848\n",
            "[250]\tvalid_0's multi_logloss: 0.413618\n",
            "[300]\tvalid_0's multi_logloss: 0.377409\n",
            "[350]\tvalid_0's multi_logloss: 0.350006\n",
            "[400]\tvalid_0's multi_logloss: 0.329576\n",
            "[450]\tvalid_0's multi_logloss: 0.312768\n",
            "[500]\tvalid_0's multi_logloss: 0.296378\n",
            "[550]\tvalid_0's multi_logloss: 0.283207\n",
            "[600]\tvalid_0's multi_logloss: 0.272206\n",
            "[650]\tvalid_0's multi_logloss: 0.262351\n",
            "[700]\tvalid_0's multi_logloss: 0.254037\n",
            "[750]\tvalid_0's multi_logloss: 0.246551\n",
            "[800]\tvalid_0's multi_logloss: 0.239519\n",
            "[850]\tvalid_0's multi_logloss: 0.233183\n",
            "[900]\tvalid_0's multi_logloss: 0.22752\n",
            "[950]\tvalid_0's multi_logloss: 0.221741\n",
            "[1000]\tvalid_0's multi_logloss: 0.216185\n",
            "[1050]\tvalid_0's multi_logloss: 0.211236\n",
            "[1100]\tvalid_0's multi_logloss: 0.206417\n",
            "[1150]\tvalid_0's multi_logloss: 0.20189\n",
            "[1200]\tvalid_0's multi_logloss: 0.197938\n",
            "[1250]\tvalid_0's multi_logloss: 0.194067\n",
            "[1300]\tvalid_0's multi_logloss: 0.190385\n",
            "[1350]\tvalid_0's multi_logloss: 0.186742\n",
            "[1400]\tvalid_0's multi_logloss: 0.183468\n",
            "[1450]\tvalid_0's multi_logloss: 0.180342\n",
            "[1500]\tvalid_0's multi_logloss: 0.177582\n",
            "[1550]\tvalid_0's multi_logloss: 0.174671\n",
            "[1600]\tvalid_0's multi_logloss: 0.171937\n",
            "[1650]\tvalid_0's multi_logloss: 0.169275\n",
            "[1700]\tvalid_0's multi_logloss: 0.166757\n",
            "[1750]\tvalid_0's multi_logloss: 0.164398\n",
            "[1800]\tvalid_0's multi_logloss: 0.162484\n",
            "[1850]\tvalid_0's multi_logloss: 0.160475\n",
            "[1900]\tvalid_0's multi_logloss: 0.158493\n",
            "[1950]\tvalid_0's multi_logloss: 0.156298\n",
            "[2000]\tvalid_0's multi_logloss: 0.154108\n",
            "[2050]\tvalid_0's multi_logloss: 0.152157\n",
            "[2100]\tvalid_0's multi_logloss: 0.150519\n",
            "[2150]\tvalid_0's multi_logloss: 0.148993\n",
            "[2200]\tvalid_0's multi_logloss: 0.147327\n",
            "[2250]\tvalid_0's multi_logloss: 0.145641\n",
            "[2300]\tvalid_0's multi_logloss: 0.144184\n",
            "[2350]\tvalid_0's multi_logloss: 0.142562\n",
            "[2400]\tvalid_0's multi_logloss: 0.141454\n",
            "[2450]\tvalid_0's multi_logloss: 0.140158\n",
            "[2500]\tvalid_0's multi_logloss: 0.139007\n",
            "[2550]\tvalid_0's multi_logloss: 0.137809\n",
            "[2600]\tvalid_0's multi_logloss: 0.136927\n",
            "[2650]\tvalid_0's multi_logloss: 0.1359\n",
            "[2700]\tvalid_0's multi_logloss: 0.135023\n",
            "[2750]\tvalid_0's multi_logloss: 0.13405\n",
            "[2800]\tvalid_0's multi_logloss: 0.133122\n",
            "[2850]\tvalid_0's multi_logloss: 0.132345\n",
            "[2900]\tvalid_0's multi_logloss: 0.131464\n",
            "[2950]\tvalid_0's multi_logloss: 0.130618\n",
            "[3000]\tvalid_0's multi_logloss: 0.129836\n",
            "[3050]\tvalid_0's multi_logloss: 0.128895\n",
            "[3100]\tvalid_0's multi_logloss: 0.128079\n",
            "[3150]\tvalid_0's multi_logloss: 0.12744\n",
            "[3200]\tvalid_0's multi_logloss: 0.1267\n",
            "[3250]\tvalid_0's multi_logloss: 0.126025\n",
            "[3300]\tvalid_0's multi_logloss: 0.125387\n",
            "[3350]\tvalid_0's multi_logloss: 0.124909\n",
            "[3400]\tvalid_0's multi_logloss: 0.124211\n",
            "[3450]\tvalid_0's multi_logloss: 0.123589\n",
            "[3500]\tvalid_0's multi_logloss: 0.123057\n",
            "[3550]\tvalid_0's multi_logloss: 0.122396\n",
            "[3600]\tvalid_0's multi_logloss: 0.12175\n",
            "[3650]\tvalid_0's multi_logloss: 0.121197\n",
            "[3700]\tvalid_0's multi_logloss: 0.120722\n",
            "[3750]\tvalid_0's multi_logloss: 0.120236\n",
            "[3800]\tvalid_0's multi_logloss: 0.119735\n",
            "[3850]\tvalid_0's multi_logloss: 0.119586\n",
            "[3900]\tvalid_0's multi_logloss: 0.119455\n",
            "[3950]\tvalid_0's multi_logloss: 0.119322\n",
            "[4000]\tvalid_0's multi_logloss: 0.119086\n",
            "[4050]\tvalid_0's multi_logloss: 0.118811\n",
            "[4100]\tvalid_0's multi_logloss: 0.118642\n",
            "[4150]\tvalid_0's multi_logloss: 0.118613\n",
            "[4200]\tvalid_0's multi_logloss: 0.118269\n",
            "[4250]\tvalid_0's multi_logloss: 0.118035\n",
            "[4300]\tvalid_0's multi_logloss: 0.117725\n",
            "[4350]\tvalid_0's multi_logloss: 0.117335\n",
            "[4400]\tvalid_0's multi_logloss: 0.117097\n",
            "[4450]\tvalid_0's multi_logloss: 0.116935\n",
            "[4500]\tvalid_0's multi_logloss: 0.11666\n",
            "[4550]\tvalid_0's multi_logloss: 0.116545\n",
            "[4600]\tvalid_0's multi_logloss: 0.116468\n",
            "[4650]\tvalid_0's multi_logloss: 0.116279\n",
            "[4700]\tvalid_0's multi_logloss: 0.116276\n",
            "[4750]\tvalid_0's multi_logloss: 0.116269\n",
            "[4800]\tvalid_0's multi_logloss: 0.116111\n",
            "[4850]\tvalid_0's multi_logloss: 0.115751\n",
            "[4900]\tvalid_0's multi_logloss: 0.115488\n",
            "[4950]\tvalid_0's multi_logloss: 0.11546\n",
            "[5000]\tvalid_0's multi_logloss: 0.115236\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's multi_logloss: 0.115236\n",
            "0.960232418158054\n",
            "第 18 个Fold\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's multi_logloss: 0.790512\n",
            "[100]\tvalid_0's multi_logloss: 0.623743\n",
            "[150]\tvalid_0's multi_logloss: 0.524131\n",
            "[200]\tvalid_0's multi_logloss: 0.459189\n",
            "[250]\tvalid_0's multi_logloss: 0.414453\n",
            "[300]\tvalid_0's multi_logloss: 0.379981\n",
            "[350]\tvalid_0's multi_logloss: 0.351827\n",
            "[400]\tvalid_0's multi_logloss: 0.329352\n",
            "[450]\tvalid_0's multi_logloss: 0.311277\n",
            "[500]\tvalid_0's multi_logloss: 0.294962\n",
            "[550]\tvalid_0's multi_logloss: 0.281294\n",
            "[600]\tvalid_0's multi_logloss: 0.270276\n",
            "[650]\tvalid_0's multi_logloss: 0.261\n",
            "[700]\tvalid_0's multi_logloss: 0.252457\n",
            "[750]\tvalid_0's multi_logloss: 0.244835\n",
            "[800]\tvalid_0's multi_logloss: 0.238054\n",
            "[850]\tvalid_0's multi_logloss: 0.231941\n",
            "[900]\tvalid_0's multi_logloss: 0.226228\n",
            "[950]\tvalid_0's multi_logloss: 0.221601\n",
            "[1000]\tvalid_0's multi_logloss: 0.217649\n",
            "[1050]\tvalid_0's multi_logloss: 0.213763\n",
            "[1100]\tvalid_0's multi_logloss: 0.209932\n",
            "[1150]\tvalid_0's multi_logloss: 0.206839\n",
            "[1200]\tvalid_0's multi_logloss: 0.204\n",
            "[1250]\tvalid_0's multi_logloss: 0.201253\n",
            "[1300]\tvalid_0's multi_logloss: 0.198337\n",
            "[1350]\tvalid_0's multi_logloss: 0.195382\n",
            "[1400]\tvalid_0's multi_logloss: 0.192939\n",
            "[1450]\tvalid_0's multi_logloss: 0.190546\n",
            "[1500]\tvalid_0's multi_logloss: 0.188409\n",
            "[1550]\tvalid_0's multi_logloss: 0.186166\n",
            "[1600]\tvalid_0's multi_logloss: 0.184028\n",
            "[1650]\tvalid_0's multi_logloss: 0.182069\n",
            "[1700]\tvalid_0's multi_logloss: 0.180252\n",
            "[1750]\tvalid_0's multi_logloss: 0.178082\n",
            "[1800]\tvalid_0's multi_logloss: 0.17609\n",
            "[1850]\tvalid_0's multi_logloss: 0.174121\n",
            "[1900]\tvalid_0's multi_logloss: 0.172511\n",
            "[1950]\tvalid_0's multi_logloss: 0.171207\n",
            "[2000]\tvalid_0's multi_logloss: 0.169751\n",
            "[2050]\tvalid_0's multi_logloss: 0.167963\n",
            "[2100]\tvalid_0's multi_logloss: 0.1667\n",
            "[2150]\tvalid_0's multi_logloss: 0.165662\n",
            "[2200]\tvalid_0's multi_logloss: 0.164557\n",
            "[2250]\tvalid_0's multi_logloss: 0.163384\n",
            "[2300]\tvalid_0's multi_logloss: 0.162423\n",
            "[2350]\tvalid_0's multi_logloss: 0.16137\n",
            "[2400]\tvalid_0's multi_logloss: 0.160337\n",
            "[2450]\tvalid_0's multi_logloss: 0.15915\n",
            "[2500]\tvalid_0's multi_logloss: 0.158318\n",
            "[2550]\tvalid_0's multi_logloss: 0.157293\n",
            "[2600]\tvalid_0's multi_logloss: 0.156712\n",
            "[2650]\tvalid_0's multi_logloss: 0.155974\n",
            "[2700]\tvalid_0's multi_logloss: 0.155145\n",
            "[2750]\tvalid_0's multi_logloss: 0.154554\n",
            "[2800]\tvalid_0's multi_logloss: 0.153844\n",
            "[2850]\tvalid_0's multi_logloss: 0.153244\n",
            "[2900]\tvalid_0's multi_logloss: 0.152551\n",
            "[2950]\tvalid_0's multi_logloss: 0.15211\n",
            "[3000]\tvalid_0's multi_logloss: 0.151399\n",
            "[3050]\tvalid_0's multi_logloss: 0.150786\n",
            "[3100]\tvalid_0's multi_logloss: 0.150313\n",
            "[3150]\tvalid_0's multi_logloss: 0.149951\n",
            "[3200]\tvalid_0's multi_logloss: 0.149873\n",
            "[3250]\tvalid_0's multi_logloss: 0.149273\n",
            "[3300]\tvalid_0's multi_logloss: 0.148866\n",
            "[3350]\tvalid_0's multi_logloss: 0.148497\n",
            "[3400]\tvalid_0's multi_logloss: 0.148081\n",
            "[3450]\tvalid_0's multi_logloss: 0.147631\n",
            "[3500]\tvalid_0's multi_logloss: 0.14729\n",
            "[3550]\tvalid_0's multi_logloss: 0.147026\n",
            "[3600]\tvalid_0's multi_logloss: 0.146616\n",
            "[3650]\tvalid_0's multi_logloss: 0.146356\n",
            "[3700]\tvalid_0's multi_logloss: 0.14611\n",
            "[3750]\tvalid_0's multi_logloss: 0.146026\n",
            "[3800]\tvalid_0's multi_logloss: 0.145823\n",
            "[3850]\tvalid_0's multi_logloss: 0.145464\n",
            "[3900]\tvalid_0's multi_logloss: 0.145192\n",
            "[3950]\tvalid_0's multi_logloss: 0.144986\n",
            "[4000]\tvalid_0's multi_logloss: 0.144783\n",
            "[4050]\tvalid_0's multi_logloss: 0.144643\n",
            "[4100]\tvalid_0's multi_logloss: 0.144546\n",
            "[4150]\tvalid_0's multi_logloss: 0.144566\n",
            "[4200]\tvalid_0's multi_logloss: 0.144554\n",
            "[4250]\tvalid_0's multi_logloss: 0.144426\n",
            "[4300]\tvalid_0's multi_logloss: 0.144326\n",
            "[4350]\tvalid_0's multi_logloss: 0.144396\n",
            "[4400]\tvalid_0's multi_logloss: 0.144099\n",
            "[4450]\tvalid_0's multi_logloss: 0.144137\n",
            "[4500]\tvalid_0's multi_logloss: 0.144281\n",
            "[4550]\tvalid_0's multi_logloss: 0.144496\n",
            "Early stopping, best iteration is:\n",
            "[4467]\tvalid_0's multi_logloss: 0.144053\n",
            "0.9402257121446235\n",
            "第 19 个Fold\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's multi_logloss: 0.803042\n",
            "[100]\tvalid_0's multi_logloss: 0.642682\n",
            "[150]\tvalid_0's multi_logloss: 0.543339\n",
            "[200]\tvalid_0's multi_logloss: 0.478269\n",
            "[250]\tvalid_0's multi_logloss: 0.431711\n",
            "[300]\tvalid_0's multi_logloss: 0.397544\n",
            "[350]\tvalid_0's multi_logloss: 0.370683\n",
            "[400]\tvalid_0's multi_logloss: 0.347838\n",
            "[450]\tvalid_0's multi_logloss: 0.328871\n",
            "[500]\tvalid_0's multi_logloss: 0.312169\n",
            "[550]\tvalid_0's multi_logloss: 0.298064\n",
            "[600]\tvalid_0's multi_logloss: 0.285275\n",
            "[650]\tvalid_0's multi_logloss: 0.274684\n",
            "[700]\tvalid_0's multi_logloss: 0.265491\n",
            "[750]\tvalid_0's multi_logloss: 0.256956\n",
            "[800]\tvalid_0's multi_logloss: 0.249361\n",
            "[850]\tvalid_0's multi_logloss: 0.242929\n",
            "[900]\tvalid_0's multi_logloss: 0.236787\n",
            "[950]\tvalid_0's multi_logloss: 0.231136\n",
            "[1000]\tvalid_0's multi_logloss: 0.226209\n",
            "[1050]\tvalid_0's multi_logloss: 0.22175\n",
            "[1100]\tvalid_0's multi_logloss: 0.216878\n",
            "[1150]\tvalid_0's multi_logloss: 0.212395\n",
            "[1200]\tvalid_0's multi_logloss: 0.207927\n",
            "[1250]\tvalid_0's multi_logloss: 0.203939\n",
            "[1300]\tvalid_0's multi_logloss: 0.20056\n",
            "[1350]\tvalid_0's multi_logloss: 0.197063\n",
            "[1400]\tvalid_0's multi_logloss: 0.193887\n",
            "[1450]\tvalid_0's multi_logloss: 0.19065\n",
            "[1500]\tvalid_0's multi_logloss: 0.188096\n",
            "[1550]\tvalid_0's multi_logloss: 0.185081\n",
            "[1600]\tvalid_0's multi_logloss: 0.182497\n",
            "[1650]\tvalid_0's multi_logloss: 0.180122\n",
            "[1700]\tvalid_0's multi_logloss: 0.177876\n",
            "[1750]\tvalid_0's multi_logloss: 0.17557\n",
            "[1800]\tvalid_0's multi_logloss: 0.173597\n",
            "[1850]\tvalid_0's multi_logloss: 0.171531\n",
            "[1900]\tvalid_0's multi_logloss: 0.169424\n",
            "[1950]\tvalid_0's multi_logloss: 0.167722\n",
            "[2000]\tvalid_0's multi_logloss: 0.165763\n",
            "[2050]\tvalid_0's multi_logloss: 0.163923\n",
            "[2100]\tvalid_0's multi_logloss: 0.162078\n",
            "[2150]\tvalid_0's multi_logloss: 0.16045\n",
            "[2200]\tvalid_0's multi_logloss: 0.15907\n",
            "[2250]\tvalid_0's multi_logloss: 0.157578\n",
            "[2300]\tvalid_0's multi_logloss: 0.156285\n",
            "[2350]\tvalid_0's multi_logloss: 0.154721\n",
            "[2400]\tvalid_0's multi_logloss: 0.153358\n",
            "[2450]\tvalid_0's multi_logloss: 0.152099\n",
            "[2500]\tvalid_0's multi_logloss: 0.151096\n",
            "[2550]\tvalid_0's multi_logloss: 0.150376\n",
            "[2600]\tvalid_0's multi_logloss: 0.149474\n",
            "[2650]\tvalid_0's multi_logloss: 0.148265\n",
            "[2700]\tvalid_0's multi_logloss: 0.147289\n",
            "[2750]\tvalid_0's multi_logloss: 0.146404\n",
            "[2800]\tvalid_0's multi_logloss: 0.145463\n",
            "[2850]\tvalid_0's multi_logloss: 0.144768\n",
            "[2900]\tvalid_0's multi_logloss: 0.143896\n",
            "[2950]\tvalid_0's multi_logloss: 0.143216\n",
            "[3000]\tvalid_0's multi_logloss: 0.142596\n",
            "[3050]\tvalid_0's multi_logloss: 0.141731\n",
            "[3100]\tvalid_0's multi_logloss: 0.141196\n",
            "[3150]\tvalid_0's multi_logloss: 0.140557\n",
            "[3200]\tvalid_0's multi_logloss: 0.139863\n",
            "[3250]\tvalid_0's multi_logloss: 0.139298\n",
            "[3300]\tvalid_0's multi_logloss: 0.138963\n",
            "[3350]\tvalid_0's multi_logloss: 0.138332\n",
            "[3400]\tvalid_0's multi_logloss: 0.137876\n",
            "[3450]\tvalid_0's multi_logloss: 0.13759\n",
            "[3500]\tvalid_0's multi_logloss: 0.137223\n",
            "[3550]\tvalid_0's multi_logloss: 0.137132\n",
            "[3600]\tvalid_0's multi_logloss: 0.136857\n",
            "[3650]\tvalid_0's multi_logloss: 0.136287\n",
            "[3700]\tvalid_0's multi_logloss: 0.136006\n",
            "[3750]\tvalid_0's multi_logloss: 0.135889\n",
            "[3800]\tvalid_0's multi_logloss: 0.135607\n",
            "[3850]\tvalid_0's multi_logloss: 0.135723\n",
            "[3900]\tvalid_0's multi_logloss: 0.135523\n",
            "[3950]\tvalid_0's multi_logloss: 0.13507\n",
            "[4000]\tvalid_0's multi_logloss: 0.134837\n",
            "[4050]\tvalid_0's multi_logloss: 0.134545\n",
            "[4100]\tvalid_0's multi_logloss: 0.134398\n",
            "[4150]\tvalid_0's multi_logloss: 0.134044\n",
            "[4200]\tvalid_0's multi_logloss: 0.133818\n",
            "[4250]\tvalid_0's multi_logloss: 0.133536\n",
            "[4300]\tvalid_0's multi_logloss: 0.133245\n",
            "[4350]\tvalid_0's multi_logloss: 0.132913\n",
            "[4400]\tvalid_0's multi_logloss: 0.132571\n",
            "[4450]\tvalid_0's multi_logloss: 0.132343\n",
            "[4500]\tvalid_0's multi_logloss: 0.132219\n",
            "[4550]\tvalid_0's multi_logloss: 0.132074\n",
            "[4600]\tvalid_0's multi_logloss: 0.131983\n",
            "[4650]\tvalid_0's multi_logloss: 0.131874\n",
            "[4700]\tvalid_0's multi_logloss: 0.131851\n",
            "[4750]\tvalid_0's multi_logloss: 0.13155\n",
            "[4800]\tvalid_0's multi_logloss: 0.131461\n",
            "[4850]\tvalid_0's multi_logloss: 0.13147\n",
            "[4900]\tvalid_0's multi_logloss: 0.13136\n",
            "[4950]\tvalid_0's multi_logloss: 0.131204\n",
            "[5000]\tvalid_0's multi_logloss: 0.131024\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's multi_logloss: 0.131024\n",
            "0.9495060045529736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i37LSHN2Nhs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = finalRes(selectMost(lgb_preds))\n",
        "sub = test_dataset[['ship']]\n",
        "sub['pred'] = res\n",
        "sub.to_csv('/content/drive/My Drive/result_lgb.csv',index=False,header=False,encoding='utf_8_sig')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvU2DjSKGl1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_params = {\n",
        "    'learning_rate': 0.01,\n",
        "    'objective': 'multi:softmax',\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'num_class': 3,\n",
        "    'max_depth': 7,\n",
        "    'subsample': .7,\n",
        "    'colsample_bytree': .7,\n",
        "    'colsample_bylevel': .7,\n",
        "    'lambda': 0.5,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOUqf5jZKnWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def XGBKfoldResult(train=x_final,test=test_final,label=y_final,params=xgb_params,K=20):\n",
        "  fold = StratifiedKFold(n_splits=K,shuffle=True)\n",
        "  preds = []\n",
        "  models = []\n",
        "  i = 0\n",
        "  # test = xgb.DMatrix(test.copy())\n",
        "  test = xgb.DMatrix(test.values.copy())\n",
        "  for train_index, valid_index in fold.split(train,label):\n",
        "      print('第',str(i),'个Fold')\n",
        "      i += 1\n",
        "      # train_x,valid_x,train_y,valid_y = train.iloc[train_index],train.iloc[valid_index],label[train_index],label[valid_index]\n",
        "      train_x,valid_x,train_y,valid_y = train[train_index],train[valid_index],label[train_index],label[valid_index]\n",
        "      xgb_train = xgb.DMatrix(train_x,train_y)\n",
        "      xgb_valid = xgb.DMatrix(valid_x,valid_y)\n",
        "      evallist = [(xgb_valid,'eval')]\n",
        "      model = xgb.train(params,dtrain=xgb_train,num_boost_round=5000,early_stopping_rounds=100,evals=evallist,verbose_eval=50)\n",
        "      models.append(model)\n",
        "      val_pred = model.predict(xgb_valid).reshape((-1))\n",
        "      print(metrics.f1_score(valid_y, val_pred, average='macro'))\n",
        "      preds.append(model.predict(test).reshape((-1)))\n",
        "  preds = np.array(preds)\n",
        "  return models,preds.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA4oN-cLPP6-",
        "colab_type": "code",
        "outputId": "5d20ca7c-2f25-490b-e185-32261c0e628e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xgb_models, xgb_preds = XGBKfoldResult()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "第 0 个Fold\n",
            "[0]\teval-mlogloss:1.08966\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.768116\n",
            "[100]\teval-mlogloss:0.591639\n",
            "[150]\teval-mlogloss:0.483887\n",
            "[200]\teval-mlogloss:0.413661\n",
            "[250]\teval-mlogloss:0.365531\n",
            "[300]\teval-mlogloss:0.330821\n",
            "[350]\teval-mlogloss:0.305635\n",
            "[400]\teval-mlogloss:0.286502\n",
            "[450]\teval-mlogloss:0.271124\n",
            "[500]\teval-mlogloss:0.259352\n",
            "[550]\teval-mlogloss:0.249044\n",
            "[600]\teval-mlogloss:0.240794\n",
            "[650]\teval-mlogloss:0.233022\n",
            "[700]\teval-mlogloss:0.22598\n",
            "[750]\teval-mlogloss:0.219988\n",
            "[800]\teval-mlogloss:0.214407\n",
            "[850]\teval-mlogloss:0.209387\n",
            "[900]\teval-mlogloss:0.204976\n",
            "[950]\teval-mlogloss:0.200666\n",
            "[1000]\teval-mlogloss:0.197225\n",
            "[1050]\teval-mlogloss:0.193756\n",
            "[1100]\teval-mlogloss:0.190708\n",
            "[1150]\teval-mlogloss:0.187228\n",
            "[1200]\teval-mlogloss:0.184359\n",
            "[1250]\teval-mlogloss:0.181814\n",
            "[1300]\teval-mlogloss:0.179336\n",
            "[1350]\teval-mlogloss:0.176936\n",
            "[1400]\teval-mlogloss:0.174646\n",
            "[1450]\teval-mlogloss:0.17242\n",
            "[1500]\teval-mlogloss:0.170376\n",
            "[1550]\teval-mlogloss:0.168576\n",
            "[1600]\teval-mlogloss:0.166592\n",
            "[1650]\teval-mlogloss:0.164847\n",
            "[1700]\teval-mlogloss:0.163441\n",
            "[1750]\teval-mlogloss:0.161958\n",
            "[1800]\teval-mlogloss:0.1607\n",
            "[1850]\teval-mlogloss:0.159298\n",
            "[1900]\teval-mlogloss:0.158041\n",
            "[1950]\teval-mlogloss:0.15702\n",
            "[2000]\teval-mlogloss:0.15593\n",
            "[2050]\teval-mlogloss:0.154959\n",
            "[2100]\teval-mlogloss:0.153884\n",
            "[2150]\teval-mlogloss:0.152755\n",
            "[2200]\teval-mlogloss:0.15213\n",
            "[2250]\teval-mlogloss:0.151428\n",
            "[2300]\teval-mlogloss:0.151079\n",
            "[2350]\teval-mlogloss:0.150632\n",
            "[2400]\teval-mlogloss:0.150103\n",
            "[2450]\teval-mlogloss:0.149305\n",
            "[2500]\teval-mlogloss:0.148935\n",
            "[2550]\teval-mlogloss:0.148668\n",
            "[2600]\teval-mlogloss:0.148027\n",
            "[2650]\teval-mlogloss:0.147651\n",
            "[2700]\teval-mlogloss:0.14732\n",
            "[2750]\teval-mlogloss:0.146969\n",
            "[2800]\teval-mlogloss:0.146652\n",
            "[2850]\teval-mlogloss:0.146177\n",
            "[2900]\teval-mlogloss:0.14586\n",
            "[2950]\teval-mlogloss:0.145418\n",
            "[3000]\teval-mlogloss:0.145221\n",
            "[3050]\teval-mlogloss:0.144954\n",
            "[3100]\teval-mlogloss:0.144755\n",
            "[3150]\teval-mlogloss:0.144507\n",
            "[3200]\teval-mlogloss:0.144255\n",
            "[3250]\teval-mlogloss:0.144173\n",
            "[3300]\teval-mlogloss:0.143716\n",
            "[3350]\teval-mlogloss:0.143354\n",
            "[3400]\teval-mlogloss:0.143112\n",
            "[3450]\teval-mlogloss:0.142844\n",
            "[3500]\teval-mlogloss:0.14249\n",
            "[3550]\teval-mlogloss:0.14224\n",
            "[3600]\teval-mlogloss:0.142149\n",
            "[3650]\teval-mlogloss:0.141935\n",
            "[3700]\teval-mlogloss:0.141796\n",
            "[3750]\teval-mlogloss:0.141785\n",
            "[3800]\teval-mlogloss:0.141654\n",
            "[3850]\teval-mlogloss:0.141675\n",
            "[3900]\teval-mlogloss:0.141723\n",
            "[3950]\teval-mlogloss:0.141759\n",
            "Stopping. Best iteration:\n",
            "[3870]\teval-mlogloss:0.141604\n",
            "\n",
            "0.9465514304797341\n",
            "第 1 个Fold\n",
            "[0]\teval-mlogloss:1.09015\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.777874\n",
            "[100]\teval-mlogloss:0.603524\n",
            "[150]\teval-mlogloss:0.497029\n",
            "[200]\teval-mlogloss:0.426468\n",
            "[250]\teval-mlogloss:0.37779\n",
            "[300]\teval-mlogloss:0.342468\n",
            "[350]\teval-mlogloss:0.316725\n",
            "[400]\teval-mlogloss:0.296889\n",
            "[450]\teval-mlogloss:0.280666\n",
            "[500]\teval-mlogloss:0.267297\n",
            "[550]\teval-mlogloss:0.255598\n",
            "[600]\teval-mlogloss:0.245379\n",
            "[650]\teval-mlogloss:0.236675\n",
            "[700]\teval-mlogloss:0.229582\n",
            "[750]\teval-mlogloss:0.222697\n",
            "[800]\teval-mlogloss:0.215931\n",
            "[850]\teval-mlogloss:0.210361\n",
            "[900]\teval-mlogloss:0.205323\n",
            "[950]\teval-mlogloss:0.199992\n",
            "[1000]\teval-mlogloss:0.195193\n",
            "[1050]\teval-mlogloss:0.190849\n",
            "[1100]\teval-mlogloss:0.186925\n",
            "[1150]\teval-mlogloss:0.183132\n",
            "[1200]\teval-mlogloss:0.179492\n",
            "[1250]\teval-mlogloss:0.176412\n",
            "[1300]\teval-mlogloss:0.173057\n",
            "[1350]\teval-mlogloss:0.170282\n",
            "[1400]\teval-mlogloss:0.167489\n",
            "[1450]\teval-mlogloss:0.165034\n",
            "[1500]\teval-mlogloss:0.162434\n",
            "[1550]\teval-mlogloss:0.160181\n",
            "[1600]\teval-mlogloss:0.158011\n",
            "[1650]\teval-mlogloss:0.155715\n",
            "[1700]\teval-mlogloss:0.15398\n",
            "[1750]\teval-mlogloss:0.152154\n",
            "[1800]\teval-mlogloss:0.150237\n",
            "[1850]\teval-mlogloss:0.148392\n",
            "[1900]\teval-mlogloss:0.146831\n",
            "[1950]\teval-mlogloss:0.145139\n",
            "[2000]\teval-mlogloss:0.143832\n",
            "[2050]\teval-mlogloss:0.142603\n",
            "[2100]\teval-mlogloss:0.1413\n",
            "[2150]\teval-mlogloss:0.140182\n",
            "[2200]\teval-mlogloss:0.139017\n",
            "[2250]\teval-mlogloss:0.137866\n",
            "[2300]\teval-mlogloss:0.136911\n",
            "[2350]\teval-mlogloss:0.135944\n",
            "[2400]\teval-mlogloss:0.134991\n",
            "[2450]\teval-mlogloss:0.134141\n",
            "[2500]\teval-mlogloss:0.13305\n",
            "[2550]\teval-mlogloss:0.132355\n",
            "[2600]\teval-mlogloss:0.131666\n",
            "[2650]\teval-mlogloss:0.130715\n",
            "[2700]\teval-mlogloss:0.130398\n",
            "[2750]\teval-mlogloss:0.129726\n",
            "[2800]\teval-mlogloss:0.12915\n",
            "[2850]\teval-mlogloss:0.12859\n",
            "[2900]\teval-mlogloss:0.127832\n",
            "[2950]\teval-mlogloss:0.127437\n",
            "[3000]\teval-mlogloss:0.126836\n",
            "[3050]\teval-mlogloss:0.126488\n",
            "[3100]\teval-mlogloss:0.126091\n",
            "[3150]\teval-mlogloss:0.125632\n",
            "[3200]\teval-mlogloss:0.12512\n",
            "[3250]\teval-mlogloss:0.124684\n",
            "[3300]\teval-mlogloss:0.124203\n",
            "[3350]\teval-mlogloss:0.123923\n",
            "[3400]\teval-mlogloss:0.123685\n",
            "[3450]\teval-mlogloss:0.123191\n",
            "[3500]\teval-mlogloss:0.122696\n",
            "[3550]\teval-mlogloss:0.122447\n",
            "[3600]\teval-mlogloss:0.122061\n",
            "[3650]\teval-mlogloss:0.121668\n",
            "[3700]\teval-mlogloss:0.121447\n",
            "[3750]\teval-mlogloss:0.121088\n",
            "[3800]\teval-mlogloss:0.120789\n",
            "[3850]\teval-mlogloss:0.120581\n",
            "[3900]\teval-mlogloss:0.120347\n",
            "[3950]\teval-mlogloss:0.120072\n",
            "[4000]\teval-mlogloss:0.119981\n",
            "[4050]\teval-mlogloss:0.119742\n",
            "[4100]\teval-mlogloss:0.119553\n",
            "[4150]\teval-mlogloss:0.119513\n",
            "[4200]\teval-mlogloss:0.119375\n",
            "[4250]\teval-mlogloss:0.119297\n",
            "[4300]\teval-mlogloss:0.11923\n",
            "[4350]\teval-mlogloss:0.119107\n",
            "[4400]\teval-mlogloss:0.118943\n",
            "[4450]\teval-mlogloss:0.118876\n",
            "[4500]\teval-mlogloss:0.118691\n",
            "[4550]\teval-mlogloss:0.118453\n",
            "[4600]\teval-mlogloss:0.118284\n",
            "[4650]\teval-mlogloss:0.11818\n",
            "[4700]\teval-mlogloss:0.11809\n",
            "[4750]\teval-mlogloss:0.118017\n",
            "[4800]\teval-mlogloss:0.117888\n",
            "[4850]\teval-mlogloss:0.117856\n",
            "[4900]\teval-mlogloss:0.117811\n",
            "[4950]\teval-mlogloss:0.117708\n",
            "[4999]\teval-mlogloss:0.117664\n",
            "0.9617460130505292\n",
            "第 2 个Fold\n",
            "[0]\teval-mlogloss:1.08946\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.76311\n",
            "[100]\teval-mlogloss:0.585146\n",
            "[150]\teval-mlogloss:0.477205\n",
            "[200]\teval-mlogloss:0.408802\n",
            "[250]\teval-mlogloss:0.362543\n",
            "[300]\teval-mlogloss:0.330773\n",
            "[350]\teval-mlogloss:0.307189\n",
            "[400]\teval-mlogloss:0.288116\n",
            "[450]\teval-mlogloss:0.273479\n",
            "[500]\teval-mlogloss:0.261581\n",
            "[550]\teval-mlogloss:0.251172\n",
            "[600]\teval-mlogloss:0.242858\n",
            "[650]\teval-mlogloss:0.235496\n",
            "[700]\teval-mlogloss:0.228835\n",
            "[750]\teval-mlogloss:0.223139\n",
            "[800]\teval-mlogloss:0.2172\n",
            "[850]\teval-mlogloss:0.211931\n",
            "[900]\teval-mlogloss:0.207329\n",
            "[950]\teval-mlogloss:0.203247\n",
            "[1000]\teval-mlogloss:0.199167\n",
            "[1050]\teval-mlogloss:0.195004\n",
            "[1100]\teval-mlogloss:0.191823\n",
            "[1150]\teval-mlogloss:0.188653\n",
            "[1200]\teval-mlogloss:0.18577\n",
            "[1250]\teval-mlogloss:0.18296\n",
            "[1300]\teval-mlogloss:0.180368\n",
            "[1350]\teval-mlogloss:0.177985\n",
            "[1400]\teval-mlogloss:0.175798\n",
            "[1450]\teval-mlogloss:0.174012\n",
            "[1500]\teval-mlogloss:0.171918\n",
            "[1550]\teval-mlogloss:0.170407\n",
            "[1600]\teval-mlogloss:0.168857\n",
            "[1650]\teval-mlogloss:0.167297\n",
            "[1700]\teval-mlogloss:0.165455\n",
            "[1750]\teval-mlogloss:0.163919\n",
            "[1800]\teval-mlogloss:0.162408\n",
            "[1850]\teval-mlogloss:0.161125\n",
            "[1900]\teval-mlogloss:0.159959\n",
            "[1950]\teval-mlogloss:0.158825\n",
            "[2000]\teval-mlogloss:0.15797\n",
            "[2050]\teval-mlogloss:0.156805\n",
            "[2100]\teval-mlogloss:0.156116\n",
            "[2150]\teval-mlogloss:0.155489\n",
            "[2200]\teval-mlogloss:0.154763\n",
            "[2250]\teval-mlogloss:0.154043\n",
            "[2300]\teval-mlogloss:0.153113\n",
            "[2350]\teval-mlogloss:0.152434\n",
            "[2400]\teval-mlogloss:0.151997\n",
            "[2450]\teval-mlogloss:0.151628\n",
            "[2500]\teval-mlogloss:0.151058\n",
            "[2550]\teval-mlogloss:0.150406\n",
            "[2600]\teval-mlogloss:0.150044\n",
            "[2650]\teval-mlogloss:0.149731\n",
            "[2700]\teval-mlogloss:0.149121\n",
            "[2750]\teval-mlogloss:0.148976\n",
            "[2800]\teval-mlogloss:0.14866\n",
            "[2850]\teval-mlogloss:0.148339\n",
            "[2900]\teval-mlogloss:0.147811\n",
            "[2950]\teval-mlogloss:0.14755\n",
            "[3000]\teval-mlogloss:0.147206\n",
            "[3050]\teval-mlogloss:0.146893\n",
            "[3100]\teval-mlogloss:0.146572\n",
            "[3150]\teval-mlogloss:0.146243\n",
            "[3200]\teval-mlogloss:0.146002\n",
            "[3250]\teval-mlogloss:0.145866\n",
            "[3300]\teval-mlogloss:0.145638\n",
            "[3350]\teval-mlogloss:0.145486\n",
            "[3400]\teval-mlogloss:0.145412\n",
            "[3450]\teval-mlogloss:0.145323\n",
            "[3500]\teval-mlogloss:0.14512\n",
            "[3550]\teval-mlogloss:0.144986\n",
            "[3600]\teval-mlogloss:0.144767\n",
            "[3650]\teval-mlogloss:0.144756\n",
            "[3700]\teval-mlogloss:0.144712\n",
            "[3750]\teval-mlogloss:0.144673\n",
            "[3800]\teval-mlogloss:0.144515\n",
            "[3850]\teval-mlogloss:0.144351\n",
            "[3900]\teval-mlogloss:0.144251\n",
            "[3950]\teval-mlogloss:0.144198\n",
            "[4000]\teval-mlogloss:0.144218\n",
            "[4050]\teval-mlogloss:0.1443\n",
            "Stopping. Best iteration:\n",
            "[3985]\teval-mlogloss:0.144121\n",
            "\n",
            "0.9541306121835641\n",
            "第 3 个Fold\n",
            "[0]\teval-mlogloss:1.08986\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.775151\n",
            "[100]\teval-mlogloss:0.600796\n",
            "[150]\teval-mlogloss:0.491755\n",
            "[200]\teval-mlogloss:0.420256\n",
            "[250]\teval-mlogloss:0.370906\n",
            "[300]\teval-mlogloss:0.33499\n",
            "[350]\teval-mlogloss:0.308315\n",
            "[400]\teval-mlogloss:0.28702\n",
            "[450]\teval-mlogloss:0.270385\n",
            "[500]\teval-mlogloss:0.257354\n",
            "[550]\teval-mlogloss:0.24601\n",
            "[600]\teval-mlogloss:0.235879\n",
            "[650]\teval-mlogloss:0.2279\n",
            "[700]\teval-mlogloss:0.220394\n",
            "[750]\teval-mlogloss:0.21329\n",
            "[800]\teval-mlogloss:0.207523\n",
            "[850]\teval-mlogloss:0.202335\n",
            "[900]\teval-mlogloss:0.197423\n",
            "[950]\teval-mlogloss:0.19274\n",
            "[1000]\teval-mlogloss:0.188308\n",
            "[1050]\teval-mlogloss:0.184115\n",
            "[1100]\teval-mlogloss:0.180266\n",
            "[1150]\teval-mlogloss:0.176552\n",
            "[1200]\teval-mlogloss:0.173198\n",
            "[1250]\teval-mlogloss:0.169951\n",
            "[1300]\teval-mlogloss:0.167046\n",
            "[1350]\teval-mlogloss:0.164457\n",
            "[1400]\teval-mlogloss:0.161873\n",
            "[1450]\teval-mlogloss:0.159307\n",
            "[1500]\teval-mlogloss:0.156962\n",
            "[1550]\teval-mlogloss:0.154837\n",
            "[1600]\teval-mlogloss:0.152778\n",
            "[1650]\teval-mlogloss:0.150583\n",
            "[1700]\teval-mlogloss:0.14878\n",
            "[1750]\teval-mlogloss:0.147203\n",
            "[1800]\teval-mlogloss:0.145501\n",
            "[1850]\teval-mlogloss:0.143938\n",
            "[1900]\teval-mlogloss:0.142498\n",
            "[1950]\teval-mlogloss:0.141139\n",
            "[2000]\teval-mlogloss:0.139892\n",
            "[2050]\teval-mlogloss:0.138551\n",
            "[2100]\teval-mlogloss:0.13732\n",
            "[2150]\teval-mlogloss:0.136414\n",
            "[2200]\teval-mlogloss:0.135326\n",
            "[2250]\teval-mlogloss:0.134439\n",
            "[2300]\teval-mlogloss:0.13313\n",
            "[2350]\teval-mlogloss:0.132393\n",
            "[2400]\teval-mlogloss:0.131421\n",
            "[2450]\teval-mlogloss:0.130712\n",
            "[2500]\teval-mlogloss:0.13011\n",
            "[2550]\teval-mlogloss:0.129422\n",
            "[2600]\teval-mlogloss:0.128796\n",
            "[2650]\teval-mlogloss:0.128179\n",
            "[2700]\teval-mlogloss:0.127389\n",
            "[2750]\teval-mlogloss:0.126862\n",
            "[2800]\teval-mlogloss:0.126297\n",
            "[2850]\teval-mlogloss:0.125892\n",
            "[2900]\teval-mlogloss:0.125252\n",
            "[2950]\teval-mlogloss:0.124839\n",
            "[3000]\teval-mlogloss:0.124435\n",
            "[3050]\teval-mlogloss:0.124051\n",
            "[3100]\teval-mlogloss:0.12352\n",
            "[3150]\teval-mlogloss:0.122987\n",
            "[3200]\teval-mlogloss:0.122536\n",
            "[3250]\teval-mlogloss:0.122048\n",
            "[3300]\teval-mlogloss:0.121799\n",
            "[3350]\teval-mlogloss:0.121604\n",
            "[3400]\teval-mlogloss:0.121276\n",
            "[3450]\teval-mlogloss:0.121155\n",
            "[3500]\teval-mlogloss:0.120853\n",
            "[3550]\teval-mlogloss:0.120642\n",
            "[3600]\teval-mlogloss:0.120535\n",
            "[3650]\teval-mlogloss:0.120313\n",
            "[3700]\teval-mlogloss:0.120046\n",
            "[3750]\teval-mlogloss:0.119913\n",
            "[3800]\teval-mlogloss:0.119801\n",
            "[3850]\teval-mlogloss:0.11952\n",
            "[3900]\teval-mlogloss:0.119485\n",
            "[3950]\teval-mlogloss:0.119298\n",
            "[4000]\teval-mlogloss:0.119075\n",
            "[4050]\teval-mlogloss:0.118943\n",
            "[4100]\teval-mlogloss:0.11894\n",
            "[4150]\teval-mlogloss:0.118794\n",
            "[4200]\teval-mlogloss:0.118564\n",
            "[4250]\teval-mlogloss:0.118657\n",
            "[4300]\teval-mlogloss:0.118577\n",
            "Stopping. Best iteration:\n",
            "[4213]\teval-mlogloss:0.118507\n",
            "\n",
            "0.9479152058001183\n",
            "第 4 个Fold\n",
            "[0]\teval-mlogloss:1.08989\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.770728\n",
            "[100]\teval-mlogloss:0.597184\n",
            "[150]\teval-mlogloss:0.489919\n",
            "[200]\teval-mlogloss:0.421941\n",
            "[250]\teval-mlogloss:0.375256\n",
            "[300]\teval-mlogloss:0.342645\n",
            "[350]\teval-mlogloss:0.319156\n",
            "[400]\teval-mlogloss:0.300614\n",
            "[450]\teval-mlogloss:0.286533\n",
            "[500]\teval-mlogloss:0.273995\n",
            "[550]\teval-mlogloss:0.263582\n",
            "[600]\teval-mlogloss:0.254832\n",
            "[650]\teval-mlogloss:0.24701\n",
            "[700]\teval-mlogloss:0.240158\n",
            "[750]\teval-mlogloss:0.233742\n",
            "[800]\teval-mlogloss:0.228136\n",
            "[850]\teval-mlogloss:0.22254\n",
            "[900]\teval-mlogloss:0.21783\n",
            "[950]\teval-mlogloss:0.212689\n",
            "[1000]\teval-mlogloss:0.208433\n",
            "[1050]\teval-mlogloss:0.204772\n",
            "[1100]\teval-mlogloss:0.20122\n",
            "[1150]\teval-mlogloss:0.197885\n",
            "[1200]\teval-mlogloss:0.194639\n",
            "[1250]\teval-mlogloss:0.191759\n",
            "[1300]\teval-mlogloss:0.188619\n",
            "[1350]\teval-mlogloss:0.185688\n",
            "[1400]\teval-mlogloss:0.18326\n",
            "[1450]\teval-mlogloss:0.180938\n",
            "[1500]\teval-mlogloss:0.178724\n",
            "[1550]\teval-mlogloss:0.176638\n",
            "[1600]\teval-mlogloss:0.174762\n",
            "[1650]\teval-mlogloss:0.173081\n",
            "[1700]\teval-mlogloss:0.171174\n",
            "[1750]\teval-mlogloss:0.169469\n",
            "[1800]\teval-mlogloss:0.168096\n",
            "[1850]\teval-mlogloss:0.166719\n",
            "[1900]\teval-mlogloss:0.165345\n",
            "[1950]\teval-mlogloss:0.163904\n",
            "[2000]\teval-mlogloss:0.162771\n",
            "[2050]\teval-mlogloss:0.161628\n",
            "[2100]\teval-mlogloss:0.160472\n",
            "[2150]\teval-mlogloss:0.159485\n",
            "[2200]\teval-mlogloss:0.158345\n",
            "[2250]\teval-mlogloss:0.157478\n",
            "[2300]\teval-mlogloss:0.156369\n",
            "[2350]\teval-mlogloss:0.155714\n",
            "[2400]\teval-mlogloss:0.15516\n",
            "[2450]\teval-mlogloss:0.154424\n",
            "[2500]\teval-mlogloss:0.153624\n",
            "[2550]\teval-mlogloss:0.152853\n",
            "[2600]\teval-mlogloss:0.152384\n",
            "[2650]\teval-mlogloss:0.151712\n",
            "[2700]\teval-mlogloss:0.151264\n",
            "[2750]\teval-mlogloss:0.15083\n",
            "[2800]\teval-mlogloss:0.150435\n",
            "[2850]\teval-mlogloss:0.149935\n",
            "[2900]\teval-mlogloss:0.149366\n",
            "[2950]\teval-mlogloss:0.149037\n",
            "[3000]\teval-mlogloss:0.148649\n",
            "[3050]\teval-mlogloss:0.148342\n",
            "[3100]\teval-mlogloss:0.148063\n",
            "[3150]\teval-mlogloss:0.147564\n",
            "[3200]\teval-mlogloss:0.147054\n",
            "[3250]\teval-mlogloss:0.146791\n",
            "[3300]\teval-mlogloss:0.146271\n",
            "[3350]\teval-mlogloss:0.146043\n",
            "[3400]\teval-mlogloss:0.145945\n",
            "[3450]\teval-mlogloss:0.145646\n",
            "[3500]\teval-mlogloss:0.145565\n",
            "[3550]\teval-mlogloss:0.145205\n",
            "[3600]\teval-mlogloss:0.145046\n",
            "[3650]\teval-mlogloss:0.14485\n",
            "[3700]\teval-mlogloss:0.144831\n",
            "[3750]\teval-mlogloss:0.144674\n",
            "[3800]\teval-mlogloss:0.144512\n",
            "[3850]\teval-mlogloss:0.144495\n",
            "[3900]\teval-mlogloss:0.144514\n",
            "[3950]\teval-mlogloss:0.144391\n",
            "[4000]\teval-mlogloss:0.144202\n",
            "[4050]\teval-mlogloss:0.144066\n",
            "[4100]\teval-mlogloss:0.144035\n",
            "[4150]\teval-mlogloss:0.144092\n",
            "Stopping. Best iteration:\n",
            "[4062]\teval-mlogloss:0.143972\n",
            "\n",
            "0.9556225145642886\n",
            "第 5 个Fold\n",
            "[0]\teval-mlogloss:1.09017\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.774035\n",
            "[100]\teval-mlogloss:0.598793\n",
            "[150]\teval-mlogloss:0.49205\n",
            "[200]\teval-mlogloss:0.42252\n",
            "[250]\teval-mlogloss:0.373015\n",
            "[300]\teval-mlogloss:0.33838\n",
            "[350]\teval-mlogloss:0.312548\n",
            "[400]\teval-mlogloss:0.29285\n",
            "[450]\teval-mlogloss:0.276282\n",
            "[500]\teval-mlogloss:0.263474\n",
            "[550]\teval-mlogloss:0.252125\n",
            "[600]\teval-mlogloss:0.241582\n",
            "[650]\teval-mlogloss:0.233256\n",
            "[700]\teval-mlogloss:0.225752\n",
            "[750]\teval-mlogloss:0.219165\n",
            "[800]\teval-mlogloss:0.21315\n",
            "[850]\teval-mlogloss:0.207826\n",
            "[900]\teval-mlogloss:0.202739\n",
            "[950]\teval-mlogloss:0.197516\n",
            "[1000]\teval-mlogloss:0.193189\n",
            "[1050]\teval-mlogloss:0.189005\n",
            "[1100]\teval-mlogloss:0.185325\n",
            "[1150]\teval-mlogloss:0.181531\n",
            "[1200]\teval-mlogloss:0.178353\n",
            "[1250]\teval-mlogloss:0.175175\n",
            "[1300]\teval-mlogloss:0.17218\n",
            "[1350]\teval-mlogloss:0.169503\n",
            "[1400]\teval-mlogloss:0.166918\n",
            "[1450]\teval-mlogloss:0.164126\n",
            "[1500]\teval-mlogloss:0.161464\n",
            "[1550]\teval-mlogloss:0.15917\n",
            "[1600]\teval-mlogloss:0.157022\n",
            "[1650]\teval-mlogloss:0.154952\n",
            "[1700]\teval-mlogloss:0.153084\n",
            "[1750]\teval-mlogloss:0.151513\n",
            "[1800]\teval-mlogloss:0.14969\n",
            "[1850]\teval-mlogloss:0.148165\n",
            "[1900]\teval-mlogloss:0.146638\n",
            "[1950]\teval-mlogloss:0.14505\n",
            "[2000]\teval-mlogloss:0.143851\n",
            "[2050]\teval-mlogloss:0.142384\n",
            "[2100]\teval-mlogloss:0.141436\n",
            "[2150]\teval-mlogloss:0.140164\n",
            "[2200]\teval-mlogloss:0.139207\n",
            "[2250]\teval-mlogloss:0.137902\n",
            "[2300]\teval-mlogloss:0.13678\n",
            "[2350]\teval-mlogloss:0.135962\n",
            "[2400]\teval-mlogloss:0.134931\n",
            "[2450]\teval-mlogloss:0.133864\n",
            "[2500]\teval-mlogloss:0.133488\n",
            "[2550]\teval-mlogloss:0.13264\n",
            "[2600]\teval-mlogloss:0.131814\n",
            "[2650]\teval-mlogloss:0.130538\n",
            "[2700]\teval-mlogloss:0.129883\n",
            "[2750]\teval-mlogloss:0.129299\n",
            "[2800]\teval-mlogloss:0.128491\n",
            "[2850]\teval-mlogloss:0.127869\n",
            "[2900]\teval-mlogloss:0.127114\n",
            "[2950]\teval-mlogloss:0.126552\n",
            "[3000]\teval-mlogloss:0.125902\n",
            "[3050]\teval-mlogloss:0.125299\n",
            "[3100]\teval-mlogloss:0.124731\n",
            "[3150]\teval-mlogloss:0.124426\n",
            "[3200]\teval-mlogloss:0.123863\n",
            "[3250]\teval-mlogloss:0.123514\n",
            "[3300]\teval-mlogloss:0.123093\n",
            "[3350]\teval-mlogloss:0.122766\n",
            "[3400]\teval-mlogloss:0.122255\n",
            "[3450]\teval-mlogloss:0.121797\n",
            "[3500]\teval-mlogloss:0.121399\n",
            "[3550]\teval-mlogloss:0.120995\n",
            "[3600]\teval-mlogloss:0.120711\n",
            "[3650]\teval-mlogloss:0.120239\n",
            "[3700]\teval-mlogloss:0.119956\n",
            "[3750]\teval-mlogloss:0.119741\n",
            "[3800]\teval-mlogloss:0.119489\n",
            "[3850]\teval-mlogloss:0.119006\n",
            "[3900]\teval-mlogloss:0.118749\n",
            "[3950]\teval-mlogloss:0.118626\n",
            "[4000]\teval-mlogloss:0.118486\n",
            "[4050]\teval-mlogloss:0.118218\n",
            "[4100]\teval-mlogloss:0.11808\n",
            "[4150]\teval-mlogloss:0.117752\n",
            "[4200]\teval-mlogloss:0.117312\n",
            "[4250]\teval-mlogloss:0.117034\n",
            "[4300]\teval-mlogloss:0.116898\n",
            "[4350]\teval-mlogloss:0.116692\n",
            "[4400]\teval-mlogloss:0.116482\n",
            "[4450]\teval-mlogloss:0.116335\n",
            "[4500]\teval-mlogloss:0.116057\n",
            "[4550]\teval-mlogloss:0.115838\n",
            "[4600]\teval-mlogloss:0.115655\n",
            "[4650]\teval-mlogloss:0.115445\n",
            "[4700]\teval-mlogloss:0.115293\n",
            "[4750]\teval-mlogloss:0.115194\n",
            "[4800]\teval-mlogloss:0.115018\n",
            "[4850]\teval-mlogloss:0.114929\n",
            "[4900]\teval-mlogloss:0.114736\n",
            "[4950]\teval-mlogloss:0.11462\n",
            "[4999]\teval-mlogloss:0.114679\n",
            "0.9602474248699161\n",
            "第 6 个Fold\n",
            "[0]\teval-mlogloss:1.09021\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.788695\n",
            "[100]\teval-mlogloss:0.624688\n",
            "[150]\teval-mlogloss:0.523848\n",
            "[200]\teval-mlogloss:0.456766\n",
            "[250]\teval-mlogloss:0.408784\n",
            "[300]\teval-mlogloss:0.374722\n",
            "[350]\teval-mlogloss:0.348351\n",
            "[400]\teval-mlogloss:0.32757\n",
            "[450]\teval-mlogloss:0.311012\n",
            "[500]\teval-mlogloss:0.297964\n",
            "[550]\teval-mlogloss:0.285798\n",
            "[600]\teval-mlogloss:0.27598\n",
            "[650]\teval-mlogloss:0.26675\n",
            "[700]\teval-mlogloss:0.259535\n",
            "[750]\teval-mlogloss:0.252144\n",
            "[800]\teval-mlogloss:0.245473\n",
            "[850]\teval-mlogloss:0.239362\n",
            "[900]\teval-mlogloss:0.233829\n",
            "[950]\teval-mlogloss:0.229081\n",
            "[1000]\teval-mlogloss:0.22487\n",
            "[1050]\teval-mlogloss:0.220096\n",
            "[1100]\teval-mlogloss:0.216142\n",
            "[1150]\teval-mlogloss:0.212417\n",
            "[1200]\teval-mlogloss:0.208543\n",
            "[1250]\teval-mlogloss:0.20472\n",
            "[1300]\teval-mlogloss:0.20139\n",
            "[1350]\teval-mlogloss:0.198882\n",
            "[1400]\teval-mlogloss:0.196339\n",
            "[1450]\teval-mlogloss:0.193764\n",
            "[1500]\teval-mlogloss:0.191218\n",
            "[1550]\teval-mlogloss:0.189073\n",
            "[1600]\teval-mlogloss:0.186932\n",
            "[1650]\teval-mlogloss:0.18475\n",
            "[1700]\teval-mlogloss:0.183173\n",
            "[1750]\teval-mlogloss:0.181314\n",
            "[1800]\teval-mlogloss:0.179628\n",
            "[1850]\teval-mlogloss:0.178293\n",
            "[1900]\teval-mlogloss:0.176777\n",
            "[1950]\teval-mlogloss:0.175463\n",
            "[2000]\teval-mlogloss:0.173961\n",
            "[2050]\teval-mlogloss:0.172833\n",
            "[2100]\teval-mlogloss:0.171798\n",
            "[2150]\teval-mlogloss:0.170818\n",
            "[2200]\teval-mlogloss:0.16973\n",
            "[2250]\teval-mlogloss:0.168859\n",
            "[2300]\teval-mlogloss:0.1681\n",
            "[2350]\teval-mlogloss:0.166924\n",
            "[2400]\teval-mlogloss:0.166127\n",
            "[2450]\teval-mlogloss:0.165187\n",
            "[2500]\teval-mlogloss:0.164558\n",
            "[2550]\teval-mlogloss:0.163695\n",
            "[2600]\teval-mlogloss:0.163168\n",
            "[2650]\teval-mlogloss:0.162453\n",
            "[2700]\teval-mlogloss:0.161742\n",
            "[2750]\teval-mlogloss:0.161204\n",
            "[2800]\teval-mlogloss:0.160801\n",
            "[2850]\teval-mlogloss:0.16024\n",
            "[2900]\teval-mlogloss:0.159727\n",
            "[2950]\teval-mlogloss:0.159296\n",
            "[3000]\teval-mlogloss:0.158633\n",
            "[3050]\teval-mlogloss:0.15824\n",
            "[3100]\teval-mlogloss:0.157921\n",
            "[3150]\teval-mlogloss:0.157543\n",
            "[3200]\teval-mlogloss:0.156962\n",
            "[3250]\teval-mlogloss:0.156561\n",
            "[3300]\teval-mlogloss:0.156239\n",
            "[3350]\teval-mlogloss:0.155906\n",
            "[3400]\teval-mlogloss:0.155644\n",
            "[3450]\teval-mlogloss:0.15541\n",
            "[3500]\teval-mlogloss:0.155228\n",
            "[3550]\teval-mlogloss:0.15472\n",
            "[3600]\teval-mlogloss:0.154443\n",
            "[3650]\teval-mlogloss:0.154223\n",
            "[3700]\teval-mlogloss:0.153906\n",
            "[3750]\teval-mlogloss:0.153707\n",
            "[3800]\teval-mlogloss:0.153491\n",
            "[3850]\teval-mlogloss:0.153585\n",
            "[3900]\teval-mlogloss:0.153338\n",
            "[3950]\teval-mlogloss:0.153139\n",
            "[4000]\teval-mlogloss:0.152662\n",
            "[4050]\teval-mlogloss:0.152384\n",
            "[4100]\teval-mlogloss:0.152397\n",
            "[4150]\teval-mlogloss:0.152457\n",
            "[4200]\teval-mlogloss:0.152551\n",
            "Stopping. Best iteration:\n",
            "[4118]\teval-mlogloss:0.152315\n",
            "\n",
            "0.9432583339289834\n",
            "第 7 个Fold\n",
            "[0]\teval-mlogloss:1.09021\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.782611\n",
            "[100]\teval-mlogloss:0.617073\n",
            "[150]\teval-mlogloss:0.516486\n",
            "[200]\teval-mlogloss:0.450222\n",
            "[250]\teval-mlogloss:0.404092\n",
            "[300]\teval-mlogloss:0.370515\n",
            "[350]\teval-mlogloss:0.34451\n",
            "[400]\teval-mlogloss:0.324233\n",
            "[450]\teval-mlogloss:0.308094\n",
            "[500]\teval-mlogloss:0.294898\n",
            "[550]\teval-mlogloss:0.284337\n",
            "[600]\teval-mlogloss:0.274747\n",
            "[650]\teval-mlogloss:0.266954\n",
            "[700]\teval-mlogloss:0.25989\n",
            "[750]\teval-mlogloss:0.253344\n",
            "[800]\teval-mlogloss:0.24736\n",
            "[850]\teval-mlogloss:0.241434\n",
            "[900]\teval-mlogloss:0.236478\n",
            "[950]\teval-mlogloss:0.23156\n",
            "[1000]\teval-mlogloss:0.226884\n",
            "[1050]\teval-mlogloss:0.222388\n",
            "[1100]\teval-mlogloss:0.2182\n",
            "[1150]\teval-mlogloss:0.214754\n",
            "[1200]\teval-mlogloss:0.211785\n",
            "[1250]\teval-mlogloss:0.209108\n",
            "[1300]\teval-mlogloss:0.20601\n",
            "[1350]\teval-mlogloss:0.203485\n",
            "[1400]\teval-mlogloss:0.20112\n",
            "[1450]\teval-mlogloss:0.198617\n",
            "[1500]\teval-mlogloss:0.196357\n",
            "[1550]\teval-mlogloss:0.194569\n",
            "[1600]\teval-mlogloss:0.192349\n",
            "[1650]\teval-mlogloss:0.190234\n",
            "[1700]\teval-mlogloss:0.188501\n",
            "[1750]\teval-mlogloss:0.187169\n",
            "[1800]\teval-mlogloss:0.185323\n",
            "[1850]\teval-mlogloss:0.18356\n",
            "[1900]\teval-mlogloss:0.182578\n",
            "[1950]\teval-mlogloss:0.180977\n",
            "[2000]\teval-mlogloss:0.179814\n",
            "[2050]\teval-mlogloss:0.178415\n",
            "[2100]\teval-mlogloss:0.177247\n",
            "[2150]\teval-mlogloss:0.176257\n",
            "[2200]\teval-mlogloss:0.175201\n",
            "[2250]\teval-mlogloss:0.174402\n",
            "[2300]\teval-mlogloss:0.173435\n",
            "[2350]\teval-mlogloss:0.172786\n",
            "[2400]\teval-mlogloss:0.172035\n",
            "[2450]\teval-mlogloss:0.171592\n",
            "[2500]\teval-mlogloss:0.170935\n",
            "[2550]\teval-mlogloss:0.170108\n",
            "[2600]\teval-mlogloss:0.169507\n",
            "[2650]\teval-mlogloss:0.169075\n",
            "[2700]\teval-mlogloss:0.168374\n",
            "[2750]\teval-mlogloss:0.167911\n",
            "[2800]\teval-mlogloss:0.167451\n",
            "[2850]\teval-mlogloss:0.167084\n",
            "[2900]\teval-mlogloss:0.166756\n",
            "[2950]\teval-mlogloss:0.16648\n",
            "[3000]\teval-mlogloss:0.16605\n",
            "[3050]\teval-mlogloss:0.165696\n",
            "[3100]\teval-mlogloss:0.165496\n",
            "[3150]\teval-mlogloss:0.165293\n",
            "[3200]\teval-mlogloss:0.16499\n",
            "[3250]\teval-mlogloss:0.164603\n",
            "[3300]\teval-mlogloss:0.164332\n",
            "[3350]\teval-mlogloss:0.164143\n",
            "[3400]\teval-mlogloss:0.163952\n",
            "[3450]\teval-mlogloss:0.163545\n",
            "[3500]\teval-mlogloss:0.163365\n",
            "[3550]\teval-mlogloss:0.163116\n",
            "[3600]\teval-mlogloss:0.163092\n",
            "[3650]\teval-mlogloss:0.163044\n",
            "[3700]\teval-mlogloss:0.162814\n",
            "[3750]\teval-mlogloss:0.162755\n",
            "[3800]\teval-mlogloss:0.162716\n",
            "[3850]\teval-mlogloss:0.162598\n",
            "[3900]\teval-mlogloss:0.162488\n",
            "[3950]\teval-mlogloss:0.162316\n",
            "[4000]\teval-mlogloss:0.162191\n",
            "[4050]\teval-mlogloss:0.162104\n",
            "[4100]\teval-mlogloss:0.161936\n",
            "[4150]\teval-mlogloss:0.161789\n",
            "[4200]\teval-mlogloss:0.161697\n",
            "[4250]\teval-mlogloss:0.161683\n",
            "Stopping. Best iteration:\n",
            "[4188]\teval-mlogloss:0.16159\n",
            "\n",
            "0.9464374366511006\n",
            "第 8 个Fold\n",
            "[0]\teval-mlogloss:1.08964\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.767753\n",
            "[100]\teval-mlogloss:0.590458\n",
            "[150]\teval-mlogloss:0.481763\n",
            "[200]\teval-mlogloss:0.410145\n",
            "[250]\teval-mlogloss:0.360713\n",
            "[300]\teval-mlogloss:0.32502\n",
            "[350]\teval-mlogloss:0.298755\n",
            "[400]\teval-mlogloss:0.278036\n",
            "[450]\teval-mlogloss:0.261518\n",
            "[500]\teval-mlogloss:0.248249\n",
            "[550]\teval-mlogloss:0.236273\n",
            "[600]\teval-mlogloss:0.226655\n",
            "[650]\teval-mlogloss:0.21847\n",
            "[700]\teval-mlogloss:0.210541\n",
            "[750]\teval-mlogloss:0.203627\n",
            "[800]\teval-mlogloss:0.197073\n",
            "[850]\teval-mlogloss:0.191378\n",
            "[900]\teval-mlogloss:0.186353\n",
            "[950]\teval-mlogloss:0.181613\n",
            "[1000]\teval-mlogloss:0.177229\n",
            "[1050]\teval-mlogloss:0.173226\n",
            "[1100]\teval-mlogloss:0.169452\n",
            "[1150]\teval-mlogloss:0.165672\n",
            "[1200]\teval-mlogloss:0.162518\n",
            "[1250]\teval-mlogloss:0.159348\n",
            "[1300]\teval-mlogloss:0.156107\n",
            "[1350]\teval-mlogloss:0.153233\n",
            "[1400]\teval-mlogloss:0.150838\n",
            "[1450]\teval-mlogloss:0.148602\n",
            "[1500]\teval-mlogloss:0.146538\n",
            "[1550]\teval-mlogloss:0.144564\n",
            "[1600]\teval-mlogloss:0.142236\n",
            "[1650]\teval-mlogloss:0.140214\n",
            "[1700]\teval-mlogloss:0.138523\n",
            "[1750]\teval-mlogloss:0.136758\n",
            "[1800]\teval-mlogloss:0.135079\n",
            "[1850]\teval-mlogloss:0.133397\n",
            "[1900]\teval-mlogloss:0.131942\n",
            "[1950]\teval-mlogloss:0.130669\n",
            "[2000]\teval-mlogloss:0.129364\n",
            "[2050]\teval-mlogloss:0.127929\n",
            "[2100]\teval-mlogloss:0.126891\n",
            "[2150]\teval-mlogloss:0.125781\n",
            "[2200]\teval-mlogloss:0.124492\n",
            "[2250]\teval-mlogloss:0.123521\n",
            "[2300]\teval-mlogloss:0.122817\n",
            "[2350]\teval-mlogloss:0.12177\n",
            "[2400]\teval-mlogloss:0.121188\n",
            "[2450]\teval-mlogloss:0.120336\n",
            "[2500]\teval-mlogloss:0.119679\n",
            "[2550]\teval-mlogloss:0.119074\n",
            "[2600]\teval-mlogloss:0.118431\n",
            "[2650]\teval-mlogloss:0.117669\n",
            "[2700]\teval-mlogloss:0.116878\n",
            "[2750]\teval-mlogloss:0.116249\n",
            "[2800]\teval-mlogloss:0.115631\n",
            "[2850]\teval-mlogloss:0.11507\n",
            "[2900]\teval-mlogloss:0.114563\n",
            "[2950]\teval-mlogloss:0.114244\n",
            "[3000]\teval-mlogloss:0.113687\n",
            "[3050]\teval-mlogloss:0.113328\n",
            "[3100]\teval-mlogloss:0.112756\n",
            "[3150]\teval-mlogloss:0.112331\n",
            "[3200]\teval-mlogloss:0.111942\n",
            "[3250]\teval-mlogloss:0.111556\n",
            "[3300]\teval-mlogloss:0.111338\n",
            "[3350]\teval-mlogloss:0.111032\n",
            "[3400]\teval-mlogloss:0.110709\n",
            "[3450]\teval-mlogloss:0.11054\n",
            "[3500]\teval-mlogloss:0.110349\n",
            "[3550]\teval-mlogloss:0.109864\n",
            "[3600]\teval-mlogloss:0.109601\n",
            "[3650]\teval-mlogloss:0.109093\n",
            "[3700]\teval-mlogloss:0.108879\n",
            "[3750]\teval-mlogloss:0.10858\n",
            "[3800]\teval-mlogloss:0.108336\n",
            "[3850]\teval-mlogloss:0.108084\n",
            "[3900]\teval-mlogloss:0.107853\n",
            "[3950]\teval-mlogloss:0.107619\n",
            "[4000]\teval-mlogloss:0.107586\n",
            "[4050]\teval-mlogloss:0.107455\n",
            "[4100]\teval-mlogloss:0.107314\n",
            "[4150]\teval-mlogloss:0.107081\n",
            "[4200]\teval-mlogloss:0.107115\n",
            "[4250]\teval-mlogloss:0.106917\n",
            "[4300]\teval-mlogloss:0.106718\n",
            "[4350]\teval-mlogloss:0.106497\n",
            "[4400]\teval-mlogloss:0.106321\n",
            "[4450]\teval-mlogloss:0.106236\n",
            "[4500]\teval-mlogloss:0.106194\n",
            "[4550]\teval-mlogloss:0.106113\n",
            "[4600]\teval-mlogloss:0.105979\n",
            "[4650]\teval-mlogloss:0.10572\n",
            "[4700]\teval-mlogloss:0.105581\n",
            "[4750]\teval-mlogloss:0.105389\n",
            "[4800]\teval-mlogloss:0.10532\n",
            "[4850]\teval-mlogloss:0.105128\n",
            "[4900]\teval-mlogloss:0.105098\n",
            "[4950]\teval-mlogloss:0.104963\n",
            "[4999]\teval-mlogloss:0.104822\n",
            "0.9587607599598454\n",
            "第 9 个Fold\n",
            "[0]\teval-mlogloss:1.08985\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.771156\n",
            "[100]\teval-mlogloss:0.597891\n",
            "[150]\teval-mlogloss:0.491105\n",
            "[200]\teval-mlogloss:0.422763\n",
            "[250]\teval-mlogloss:0.376353\n",
            "[300]\teval-mlogloss:0.343339\n",
            "[350]\teval-mlogloss:0.31769\n",
            "[400]\teval-mlogloss:0.298179\n",
            "[450]\teval-mlogloss:0.283019\n",
            "[500]\teval-mlogloss:0.270861\n",
            "[550]\teval-mlogloss:0.261239\n",
            "[600]\teval-mlogloss:0.252255\n",
            "[650]\teval-mlogloss:0.2445\n",
            "[700]\teval-mlogloss:0.238225\n",
            "[750]\teval-mlogloss:0.232665\n",
            "[800]\teval-mlogloss:0.227527\n",
            "[850]\teval-mlogloss:0.222215\n",
            "[900]\teval-mlogloss:0.217481\n",
            "[950]\teval-mlogloss:0.21351\n",
            "[1000]\teval-mlogloss:0.20967\n",
            "[1050]\teval-mlogloss:0.206435\n",
            "[1100]\teval-mlogloss:0.20297\n",
            "[1150]\teval-mlogloss:0.200067\n",
            "[1200]\teval-mlogloss:0.197287\n",
            "[1250]\teval-mlogloss:0.194285\n",
            "[1300]\teval-mlogloss:0.191868\n",
            "[1350]\teval-mlogloss:0.189416\n",
            "[1400]\teval-mlogloss:0.186837\n",
            "[1450]\teval-mlogloss:0.184715\n",
            "[1500]\teval-mlogloss:0.182839\n",
            "[1550]\teval-mlogloss:0.180963\n",
            "[1600]\teval-mlogloss:0.179149\n",
            "[1650]\teval-mlogloss:0.177733\n",
            "[1700]\teval-mlogloss:0.176192\n",
            "[1750]\teval-mlogloss:0.174556\n",
            "[1800]\teval-mlogloss:0.173201\n",
            "[1850]\teval-mlogloss:0.171933\n",
            "[1900]\teval-mlogloss:0.170946\n",
            "[1950]\teval-mlogloss:0.170058\n",
            "[2000]\teval-mlogloss:0.168833\n",
            "[2050]\teval-mlogloss:0.167926\n",
            "[2100]\teval-mlogloss:0.167053\n",
            "[2150]\teval-mlogloss:0.166182\n",
            "[2200]\teval-mlogloss:0.165248\n",
            "[2250]\teval-mlogloss:0.164337\n",
            "[2300]\teval-mlogloss:0.163593\n",
            "[2350]\teval-mlogloss:0.162924\n",
            "[2400]\teval-mlogloss:0.162434\n",
            "[2450]\teval-mlogloss:0.161745\n",
            "[2500]\teval-mlogloss:0.161421\n",
            "[2550]\teval-mlogloss:0.16091\n",
            "[2600]\teval-mlogloss:0.160591\n",
            "[2650]\teval-mlogloss:0.160276\n",
            "[2700]\teval-mlogloss:0.159998\n",
            "[2750]\teval-mlogloss:0.159737\n",
            "[2800]\teval-mlogloss:0.159345\n",
            "[2850]\teval-mlogloss:0.159254\n",
            "[2900]\teval-mlogloss:0.158969\n",
            "[2950]\teval-mlogloss:0.158555\n",
            "[3000]\teval-mlogloss:0.158294\n",
            "[3050]\teval-mlogloss:0.157933\n",
            "[3100]\teval-mlogloss:0.157734\n",
            "[3150]\teval-mlogloss:0.157809\n",
            "[3200]\teval-mlogloss:0.157618\n",
            "[3250]\teval-mlogloss:0.157465\n",
            "[3300]\teval-mlogloss:0.157477\n",
            "[3350]\teval-mlogloss:0.157393\n",
            "[3400]\teval-mlogloss:0.157336\n",
            "[3450]\teval-mlogloss:0.157062\n",
            "[3500]\teval-mlogloss:0.157037\n",
            "[3550]\teval-mlogloss:0.157097\n",
            "[3600]\teval-mlogloss:0.157114\n",
            "Stopping. Best iteration:\n",
            "[3523]\teval-mlogloss:0.156944\n",
            "\n",
            "0.943308616778895\n",
            "第 10 个Fold\n",
            "[0]\teval-mlogloss:1.09024\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.785358\n",
            "[100]\teval-mlogloss:0.619688\n",
            "[150]\teval-mlogloss:0.518852\n",
            "[200]\teval-mlogloss:0.452778\n",
            "[250]\teval-mlogloss:0.406355\n",
            "[300]\teval-mlogloss:0.373993\n",
            "[350]\teval-mlogloss:0.348446\n",
            "[400]\teval-mlogloss:0.329017\n",
            "[450]\teval-mlogloss:0.313459\n",
            "[500]\teval-mlogloss:0.300512\n",
            "[550]\teval-mlogloss:0.289331\n",
            "[600]\teval-mlogloss:0.279827\n",
            "[650]\teval-mlogloss:0.271539\n",
            "[700]\teval-mlogloss:0.263369\n",
            "[750]\teval-mlogloss:0.256831\n",
            "[800]\teval-mlogloss:0.250394\n",
            "[850]\teval-mlogloss:0.245028\n",
            "[900]\teval-mlogloss:0.239327\n",
            "[950]\teval-mlogloss:0.234226\n",
            "[1000]\teval-mlogloss:0.230386\n",
            "[1050]\teval-mlogloss:0.226459\n",
            "[1100]\teval-mlogloss:0.221897\n",
            "[1150]\teval-mlogloss:0.218575\n",
            "[1200]\teval-mlogloss:0.214988\n",
            "[1250]\teval-mlogloss:0.211932\n",
            "[1300]\teval-mlogloss:0.208806\n",
            "[1350]\teval-mlogloss:0.205846\n",
            "[1400]\teval-mlogloss:0.203553\n",
            "[1450]\teval-mlogloss:0.200928\n",
            "[1500]\teval-mlogloss:0.198749\n",
            "[1550]\teval-mlogloss:0.196491\n",
            "[1600]\teval-mlogloss:0.194105\n",
            "[1650]\teval-mlogloss:0.192118\n",
            "[1700]\teval-mlogloss:0.190409\n",
            "[1750]\teval-mlogloss:0.188511\n",
            "[1800]\teval-mlogloss:0.186694\n",
            "[1850]\teval-mlogloss:0.185045\n",
            "[1900]\teval-mlogloss:0.183338\n",
            "[1950]\teval-mlogloss:0.182217\n",
            "[2000]\teval-mlogloss:0.180801\n",
            "[2050]\teval-mlogloss:0.179322\n",
            "[2100]\teval-mlogloss:0.177975\n",
            "[2150]\teval-mlogloss:0.176878\n",
            "[2200]\teval-mlogloss:0.175909\n",
            "[2250]\teval-mlogloss:0.174881\n",
            "[2300]\teval-mlogloss:0.173726\n",
            "[2350]\teval-mlogloss:0.172717\n",
            "[2400]\teval-mlogloss:0.171546\n",
            "[2450]\teval-mlogloss:0.170689\n",
            "[2500]\teval-mlogloss:0.169983\n",
            "[2550]\teval-mlogloss:0.169041\n",
            "[2600]\teval-mlogloss:0.168177\n",
            "[2650]\teval-mlogloss:0.167367\n",
            "[2700]\teval-mlogloss:0.166868\n",
            "[2750]\teval-mlogloss:0.166044\n",
            "[2800]\teval-mlogloss:0.165377\n",
            "[2850]\teval-mlogloss:0.164784\n",
            "[2900]\teval-mlogloss:0.164313\n",
            "[2950]\teval-mlogloss:0.163816\n",
            "[3000]\teval-mlogloss:0.163101\n",
            "[3050]\teval-mlogloss:0.162553\n",
            "[3100]\teval-mlogloss:0.162106\n",
            "[3150]\teval-mlogloss:0.161642\n",
            "[3200]\teval-mlogloss:0.161188\n",
            "[3250]\teval-mlogloss:0.160864\n",
            "[3300]\teval-mlogloss:0.16062\n",
            "[3350]\teval-mlogloss:0.160306\n",
            "[3400]\teval-mlogloss:0.160071\n",
            "[3450]\teval-mlogloss:0.159833\n",
            "[3500]\teval-mlogloss:0.159395\n",
            "[3550]\teval-mlogloss:0.158967\n",
            "[3600]\teval-mlogloss:0.15862\n",
            "[3650]\teval-mlogloss:0.158534\n",
            "[3700]\teval-mlogloss:0.158177\n",
            "[3750]\teval-mlogloss:0.157904\n",
            "[3800]\teval-mlogloss:0.157588\n",
            "[3850]\teval-mlogloss:0.15719\n",
            "[3900]\teval-mlogloss:0.157043\n",
            "[3950]\teval-mlogloss:0.156784\n",
            "[4000]\teval-mlogloss:0.156631\n",
            "[4050]\teval-mlogloss:0.156378\n",
            "[4100]\teval-mlogloss:0.156358\n",
            "[4150]\teval-mlogloss:0.156159\n",
            "[4200]\teval-mlogloss:0.156122\n",
            "[4250]\teval-mlogloss:0.156063\n",
            "[4300]\teval-mlogloss:0.155913\n",
            "[4350]\teval-mlogloss:0.15575\n",
            "[4400]\teval-mlogloss:0.155512\n",
            "[4450]\teval-mlogloss:0.15546\n",
            "[4500]\teval-mlogloss:0.155398\n",
            "[4550]\teval-mlogloss:0.155364\n",
            "[4600]\teval-mlogloss:0.15531\n",
            "Stopping. Best iteration:\n",
            "[4524]\teval-mlogloss:0.155289\n",
            "\n",
            "0.9338474025974026\n",
            "第 11 个Fold\n",
            "[0]\teval-mlogloss:1.08978\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.778527\n",
            "[100]\teval-mlogloss:0.60584\n",
            "[150]\teval-mlogloss:0.499269\n",
            "[200]\teval-mlogloss:0.429004\n",
            "[250]\teval-mlogloss:0.378605\n",
            "[300]\teval-mlogloss:0.343541\n",
            "[350]\teval-mlogloss:0.317636\n",
            "[400]\teval-mlogloss:0.296956\n",
            "[450]\teval-mlogloss:0.280289\n",
            "[500]\teval-mlogloss:0.266793\n",
            "[550]\teval-mlogloss:0.25546\n",
            "[600]\teval-mlogloss:0.2465\n",
            "[650]\teval-mlogloss:0.238317\n",
            "[700]\teval-mlogloss:0.230582\n",
            "[750]\teval-mlogloss:0.223798\n",
            "[800]\teval-mlogloss:0.217678\n",
            "[850]\teval-mlogloss:0.212261\n",
            "[900]\teval-mlogloss:0.206993\n",
            "[950]\teval-mlogloss:0.202234\n",
            "[1000]\teval-mlogloss:0.198196\n",
            "[1050]\teval-mlogloss:0.194027\n",
            "[1100]\teval-mlogloss:0.190581\n",
            "[1150]\teval-mlogloss:0.18711\n",
            "[1200]\teval-mlogloss:0.18398\n",
            "[1250]\teval-mlogloss:0.180934\n",
            "[1300]\teval-mlogloss:0.178271\n",
            "[1350]\teval-mlogloss:0.175432\n",
            "[1400]\teval-mlogloss:0.17309\n",
            "[1450]\teval-mlogloss:0.170745\n",
            "[1500]\teval-mlogloss:0.168919\n",
            "[1550]\teval-mlogloss:0.166766\n",
            "[1600]\teval-mlogloss:0.164816\n",
            "[1650]\teval-mlogloss:0.162793\n",
            "[1700]\teval-mlogloss:0.161014\n",
            "[1750]\teval-mlogloss:0.159468\n",
            "[1800]\teval-mlogloss:0.157731\n",
            "[1850]\teval-mlogloss:0.156362\n",
            "[1900]\teval-mlogloss:0.155022\n",
            "[1950]\teval-mlogloss:0.153529\n",
            "[2000]\teval-mlogloss:0.152574\n",
            "[2050]\teval-mlogloss:0.151371\n",
            "[2100]\teval-mlogloss:0.150355\n",
            "[2150]\teval-mlogloss:0.14922\n",
            "[2200]\teval-mlogloss:0.147967\n",
            "[2250]\teval-mlogloss:0.147116\n",
            "[2300]\teval-mlogloss:0.146054\n",
            "[2350]\teval-mlogloss:0.145354\n",
            "[2400]\teval-mlogloss:0.144503\n",
            "[2450]\teval-mlogloss:0.14391\n",
            "[2500]\teval-mlogloss:0.143615\n",
            "[2550]\teval-mlogloss:0.143012\n",
            "[2600]\teval-mlogloss:0.142407\n",
            "[2650]\teval-mlogloss:0.141763\n",
            "[2700]\teval-mlogloss:0.141254\n",
            "[2750]\teval-mlogloss:0.140457\n",
            "[2800]\teval-mlogloss:0.139812\n",
            "[2850]\teval-mlogloss:0.139111\n",
            "[2900]\teval-mlogloss:0.138638\n",
            "[2950]\teval-mlogloss:0.138296\n",
            "[3000]\teval-mlogloss:0.137787\n",
            "[3050]\teval-mlogloss:0.137546\n",
            "[3100]\teval-mlogloss:0.137211\n",
            "[3150]\teval-mlogloss:0.136907\n",
            "[3200]\teval-mlogloss:0.136361\n",
            "[3250]\teval-mlogloss:0.136303\n",
            "[3300]\teval-mlogloss:0.135893\n",
            "[3350]\teval-mlogloss:0.135773\n",
            "[3400]\teval-mlogloss:0.135551\n",
            "[3450]\teval-mlogloss:0.135267\n",
            "[3500]\teval-mlogloss:0.13502\n",
            "[3550]\teval-mlogloss:0.134797\n",
            "[3600]\teval-mlogloss:0.134331\n",
            "[3650]\teval-mlogloss:0.134116\n",
            "[3700]\teval-mlogloss:0.13385\n",
            "[3750]\teval-mlogloss:0.133635\n",
            "[3800]\teval-mlogloss:0.133512\n",
            "[3850]\teval-mlogloss:0.133393\n",
            "[3900]\teval-mlogloss:0.133225\n",
            "[3950]\teval-mlogloss:0.13303\n",
            "[4000]\teval-mlogloss:0.132679\n",
            "[4050]\teval-mlogloss:0.132447\n",
            "[4100]\teval-mlogloss:0.132465\n",
            "[4150]\teval-mlogloss:0.132404\n",
            "Stopping. Best iteration:\n",
            "[4067]\teval-mlogloss:0.132355\n",
            "\n",
            "0.9496565413916337\n",
            "第 12 个Fold\n",
            "[0]\teval-mlogloss:1.09006\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.77809\n",
            "[100]\teval-mlogloss:0.604106\n",
            "[150]\teval-mlogloss:0.497426\n",
            "[200]\teval-mlogloss:0.4268\n",
            "[250]\teval-mlogloss:0.377727\n",
            "[300]\teval-mlogloss:0.343006\n",
            "[350]\teval-mlogloss:0.317395\n",
            "[400]\teval-mlogloss:0.297205\n",
            "[450]\teval-mlogloss:0.280743\n",
            "[500]\teval-mlogloss:0.266898\n",
            "[550]\teval-mlogloss:0.256129\n",
            "[600]\teval-mlogloss:0.246498\n",
            "[650]\teval-mlogloss:0.238384\n",
            "[700]\teval-mlogloss:0.2309\n",
            "[750]\teval-mlogloss:0.224039\n",
            "[800]\teval-mlogloss:0.217309\n",
            "[850]\teval-mlogloss:0.211888\n",
            "[900]\teval-mlogloss:0.206423\n",
            "[950]\teval-mlogloss:0.201309\n",
            "[1000]\teval-mlogloss:0.197102\n",
            "[1050]\teval-mlogloss:0.193312\n",
            "[1100]\teval-mlogloss:0.188952\n",
            "[1150]\teval-mlogloss:0.185237\n",
            "[1200]\teval-mlogloss:0.182028\n",
            "[1250]\teval-mlogloss:0.178967\n",
            "[1300]\teval-mlogloss:0.176013\n",
            "[1350]\teval-mlogloss:0.173239\n",
            "[1400]\teval-mlogloss:0.17055\n",
            "[1450]\teval-mlogloss:0.167853\n",
            "[1500]\teval-mlogloss:0.165675\n",
            "[1550]\teval-mlogloss:0.163281\n",
            "[1600]\teval-mlogloss:0.161258\n",
            "[1650]\teval-mlogloss:0.159256\n",
            "[1700]\teval-mlogloss:0.157123\n",
            "[1750]\teval-mlogloss:0.155689\n",
            "[1800]\teval-mlogloss:0.154167\n",
            "[1850]\teval-mlogloss:0.152598\n",
            "[1900]\teval-mlogloss:0.151334\n",
            "[1950]\teval-mlogloss:0.149914\n",
            "[2000]\teval-mlogloss:0.148506\n",
            "[2050]\teval-mlogloss:0.147148\n",
            "[2100]\teval-mlogloss:0.146102\n",
            "[2150]\teval-mlogloss:0.14515\n",
            "[2200]\teval-mlogloss:0.143887\n",
            "[2250]\teval-mlogloss:0.142762\n",
            "[2300]\teval-mlogloss:0.142002\n",
            "[2350]\teval-mlogloss:0.141196\n",
            "[2400]\teval-mlogloss:0.140262\n",
            "[2450]\teval-mlogloss:0.139491\n",
            "[2500]\teval-mlogloss:0.138722\n",
            "[2550]\teval-mlogloss:0.138041\n",
            "[2600]\teval-mlogloss:0.137165\n",
            "[2650]\teval-mlogloss:0.136448\n",
            "[2700]\teval-mlogloss:0.136027\n",
            "[2750]\teval-mlogloss:0.135554\n",
            "[2800]\teval-mlogloss:0.135125\n",
            "[2850]\teval-mlogloss:0.1345\n",
            "[2900]\teval-mlogloss:0.134012\n",
            "[2950]\teval-mlogloss:0.133371\n",
            "[3000]\teval-mlogloss:0.1328\n",
            "[3050]\teval-mlogloss:0.132438\n",
            "[3100]\teval-mlogloss:0.13205\n",
            "[3150]\teval-mlogloss:0.131533\n",
            "[3200]\teval-mlogloss:0.131149\n",
            "[3250]\teval-mlogloss:0.130713\n",
            "[3300]\teval-mlogloss:0.130222\n",
            "[3350]\teval-mlogloss:0.129957\n",
            "[3400]\teval-mlogloss:0.129755\n",
            "[3450]\teval-mlogloss:0.129692\n",
            "[3500]\teval-mlogloss:0.129727\n",
            "[3550]\teval-mlogloss:0.129525\n",
            "[3600]\teval-mlogloss:0.129207\n",
            "[3650]\teval-mlogloss:0.128856\n",
            "[3700]\teval-mlogloss:0.128647\n",
            "[3750]\teval-mlogloss:0.128464\n",
            "[3800]\teval-mlogloss:0.128196\n",
            "[3850]\teval-mlogloss:0.128032\n",
            "[3900]\teval-mlogloss:0.12791\n",
            "[3950]\teval-mlogloss:0.127785\n",
            "[4000]\teval-mlogloss:0.12781\n",
            "[4050]\teval-mlogloss:0.12765\n",
            "[4100]\teval-mlogloss:0.127569\n",
            "[4150]\teval-mlogloss:0.127345\n",
            "[4200]\teval-mlogloss:0.127294\n",
            "[4250]\teval-mlogloss:0.127132\n",
            "[4300]\teval-mlogloss:0.127154\n",
            "[4350]\teval-mlogloss:0.126971\n",
            "[4400]\teval-mlogloss:0.126759\n",
            "[4450]\teval-mlogloss:0.126831\n",
            "[4500]\teval-mlogloss:0.126788\n",
            "Stopping. Best iteration:\n",
            "[4403]\teval-mlogloss:0.126745\n",
            "\n",
            "0.9448788852501773\n",
            "第 13 个Fold\n",
            "[0]\teval-mlogloss:1.08953\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.75922\n",
            "[100]\teval-mlogloss:0.579237\n",
            "[150]\teval-mlogloss:0.469767\n",
            "[200]\teval-mlogloss:0.400656\n",
            "[250]\teval-mlogloss:0.353085\n",
            "[300]\teval-mlogloss:0.319034\n",
            "[350]\teval-mlogloss:0.29485\n",
            "[400]\teval-mlogloss:0.275332\n",
            "[450]\teval-mlogloss:0.259262\n",
            "[500]\teval-mlogloss:0.246874\n",
            "[550]\teval-mlogloss:0.236099\n",
            "[600]\teval-mlogloss:0.226432\n",
            "[650]\teval-mlogloss:0.218485\n",
            "[700]\teval-mlogloss:0.211823\n",
            "[750]\teval-mlogloss:0.205795\n",
            "[800]\teval-mlogloss:0.200334\n",
            "[850]\teval-mlogloss:0.195234\n",
            "[900]\teval-mlogloss:0.190442\n",
            "[950]\teval-mlogloss:0.186504\n",
            "[1000]\teval-mlogloss:0.182094\n",
            "[1050]\teval-mlogloss:0.178163\n",
            "[1100]\teval-mlogloss:0.174844\n",
            "[1150]\teval-mlogloss:0.171599\n",
            "[1200]\teval-mlogloss:0.169001\n",
            "[1250]\teval-mlogloss:0.166485\n",
            "[1300]\teval-mlogloss:0.164046\n",
            "[1350]\teval-mlogloss:0.161989\n",
            "[1400]\teval-mlogloss:0.159543\n",
            "[1450]\teval-mlogloss:0.157535\n",
            "[1500]\teval-mlogloss:0.155458\n",
            "[1550]\teval-mlogloss:0.153927\n",
            "[1600]\teval-mlogloss:0.152577\n",
            "[1650]\teval-mlogloss:0.151366\n",
            "[1700]\teval-mlogloss:0.14982\n",
            "[1750]\teval-mlogloss:0.148244\n",
            "[1800]\teval-mlogloss:0.14675\n",
            "[1850]\teval-mlogloss:0.145478\n",
            "[1900]\teval-mlogloss:0.144237\n",
            "[1950]\teval-mlogloss:0.143164\n",
            "[2000]\teval-mlogloss:0.142269\n",
            "[2050]\teval-mlogloss:0.141491\n",
            "[2100]\teval-mlogloss:0.140571\n",
            "[2150]\teval-mlogloss:0.139719\n",
            "[2200]\teval-mlogloss:0.139069\n",
            "[2250]\teval-mlogloss:0.138082\n",
            "[2300]\teval-mlogloss:0.137235\n",
            "[2350]\teval-mlogloss:0.136256\n",
            "[2400]\teval-mlogloss:0.135645\n",
            "[2450]\teval-mlogloss:0.135048\n",
            "[2500]\teval-mlogloss:0.134467\n",
            "[2550]\teval-mlogloss:0.134071\n",
            "[2600]\teval-mlogloss:0.133777\n",
            "[2650]\teval-mlogloss:0.133111\n",
            "[2700]\teval-mlogloss:0.132711\n",
            "[2750]\teval-mlogloss:0.132421\n",
            "[2800]\teval-mlogloss:0.131934\n",
            "[2850]\teval-mlogloss:0.131563\n",
            "[2900]\teval-mlogloss:0.131124\n",
            "[2950]\teval-mlogloss:0.130797\n",
            "[3000]\teval-mlogloss:0.130444\n",
            "[3050]\teval-mlogloss:0.129855\n",
            "[3100]\teval-mlogloss:0.129717\n",
            "[3150]\teval-mlogloss:0.129517\n",
            "[3200]\teval-mlogloss:0.129198\n",
            "[3250]\teval-mlogloss:0.129091\n",
            "[3300]\teval-mlogloss:0.129014\n",
            "[3350]\teval-mlogloss:0.128844\n",
            "[3400]\teval-mlogloss:0.128792\n",
            "[3450]\teval-mlogloss:0.128491\n",
            "[3500]\teval-mlogloss:0.128227\n",
            "[3550]\teval-mlogloss:0.127948\n",
            "[3600]\teval-mlogloss:0.12778\n",
            "[3650]\teval-mlogloss:0.127791\n",
            "[3700]\teval-mlogloss:0.12768\n",
            "[3750]\teval-mlogloss:0.127572\n",
            "[3800]\teval-mlogloss:0.127349\n",
            "[3850]\teval-mlogloss:0.127358\n",
            "[3900]\teval-mlogloss:0.127286\n",
            "[3950]\teval-mlogloss:0.127156\n",
            "[4000]\teval-mlogloss:0.127025\n",
            "[4050]\teval-mlogloss:0.127014\n",
            "[4100]\teval-mlogloss:0.126655\n",
            "[4150]\teval-mlogloss:0.126657\n",
            "[4200]\teval-mlogloss:0.126603\n",
            "[4250]\teval-mlogloss:0.126679\n",
            "Stopping. Best iteration:\n",
            "[4197]\teval-mlogloss:0.126576\n",
            "\n",
            "0.9601955151032299\n",
            "第 14 个Fold\n",
            "[0]\teval-mlogloss:1.09036\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.784295\n",
            "[100]\teval-mlogloss:0.615057\n",
            "[150]\teval-mlogloss:0.51067\n",
            "[200]\teval-mlogloss:0.442949\n",
            "[250]\teval-mlogloss:0.394948\n",
            "[300]\teval-mlogloss:0.360379\n",
            "[350]\teval-mlogloss:0.334764\n",
            "[400]\teval-mlogloss:0.314698\n",
            "[450]\teval-mlogloss:0.297857\n",
            "[500]\teval-mlogloss:0.283754\n",
            "[550]\teval-mlogloss:0.271194\n",
            "[600]\teval-mlogloss:0.260641\n",
            "[650]\teval-mlogloss:0.251139\n",
            "[700]\teval-mlogloss:0.243407\n",
            "[750]\teval-mlogloss:0.236725\n",
            "[800]\teval-mlogloss:0.230308\n",
            "[850]\teval-mlogloss:0.223528\n",
            "[900]\teval-mlogloss:0.217997\n",
            "[950]\teval-mlogloss:0.212888\n",
            "[1000]\teval-mlogloss:0.207917\n",
            "[1050]\teval-mlogloss:0.20296\n",
            "[1100]\teval-mlogloss:0.198831\n",
            "[1150]\teval-mlogloss:0.194795\n",
            "[1200]\teval-mlogloss:0.191013\n",
            "[1250]\teval-mlogloss:0.18766\n",
            "[1300]\teval-mlogloss:0.184738\n",
            "[1350]\teval-mlogloss:0.181614\n",
            "[1400]\teval-mlogloss:0.179014\n",
            "[1450]\teval-mlogloss:0.176551\n",
            "[1500]\teval-mlogloss:0.174075\n",
            "[1550]\teval-mlogloss:0.17192\n",
            "[1600]\teval-mlogloss:0.16963\n",
            "[1650]\teval-mlogloss:0.16755\n",
            "[1700]\teval-mlogloss:0.165297\n",
            "[1750]\teval-mlogloss:0.163311\n",
            "[1800]\teval-mlogloss:0.161384\n",
            "[1850]\teval-mlogloss:0.159403\n",
            "[1900]\teval-mlogloss:0.158211\n",
            "[1950]\teval-mlogloss:0.15669\n",
            "[2000]\teval-mlogloss:0.155157\n",
            "[2050]\teval-mlogloss:0.153509\n",
            "[2100]\teval-mlogloss:0.152155\n",
            "[2150]\teval-mlogloss:0.150701\n",
            "[2200]\teval-mlogloss:0.14938\n",
            "[2250]\teval-mlogloss:0.148454\n",
            "[2300]\teval-mlogloss:0.147275\n",
            "[2350]\teval-mlogloss:0.146302\n",
            "[2400]\teval-mlogloss:0.145107\n",
            "[2450]\teval-mlogloss:0.144366\n",
            "[2500]\teval-mlogloss:0.143312\n",
            "[2550]\teval-mlogloss:0.142328\n",
            "[2600]\teval-mlogloss:0.141492\n",
            "[2650]\teval-mlogloss:0.140789\n",
            "[2700]\teval-mlogloss:0.140327\n",
            "[2750]\teval-mlogloss:0.139544\n",
            "[2800]\teval-mlogloss:0.138867\n",
            "[2850]\teval-mlogloss:0.138066\n",
            "[2900]\teval-mlogloss:0.137479\n",
            "[2950]\teval-mlogloss:0.137025\n",
            "[3000]\teval-mlogloss:0.136363\n",
            "[3050]\teval-mlogloss:0.135628\n",
            "[3100]\teval-mlogloss:0.135159\n",
            "[3150]\teval-mlogloss:0.134474\n",
            "[3200]\teval-mlogloss:0.13398\n",
            "[3250]\teval-mlogloss:0.133523\n",
            "[3300]\teval-mlogloss:0.133206\n",
            "[3350]\teval-mlogloss:0.132827\n",
            "[3400]\teval-mlogloss:0.132511\n",
            "[3450]\teval-mlogloss:0.13206\n",
            "[3500]\teval-mlogloss:0.131481\n",
            "[3550]\teval-mlogloss:0.13119\n",
            "[3600]\teval-mlogloss:0.130858\n",
            "[3650]\teval-mlogloss:0.130532\n",
            "[3700]\teval-mlogloss:0.130262\n",
            "[3750]\teval-mlogloss:0.129937\n",
            "[3800]\teval-mlogloss:0.129813\n",
            "[3850]\teval-mlogloss:0.129546\n",
            "[3900]\teval-mlogloss:0.129411\n",
            "[3950]\teval-mlogloss:0.129114\n",
            "[4000]\teval-mlogloss:0.128822\n",
            "[4050]\teval-mlogloss:0.128674\n",
            "[4100]\teval-mlogloss:0.12836\n",
            "[4150]\teval-mlogloss:0.128235\n",
            "[4200]\teval-mlogloss:0.127925\n",
            "[4250]\teval-mlogloss:0.127658\n",
            "[4300]\teval-mlogloss:0.127584\n",
            "[4350]\teval-mlogloss:0.127395\n",
            "[4400]\teval-mlogloss:0.127264\n",
            "[4450]\teval-mlogloss:0.127087\n",
            "[4500]\teval-mlogloss:0.126905\n",
            "[4550]\teval-mlogloss:0.126745\n",
            "[4600]\teval-mlogloss:0.126591\n",
            "[4650]\teval-mlogloss:0.126496\n",
            "[4700]\teval-mlogloss:0.126481\n",
            "[4750]\teval-mlogloss:0.126447\n",
            "[4800]\teval-mlogloss:0.126275\n",
            "[4850]\teval-mlogloss:0.126129\n",
            "[4900]\teval-mlogloss:0.126006\n",
            "[4950]\teval-mlogloss:0.125805\n",
            "[4999]\teval-mlogloss:0.125641\n",
            "0.9539662484980926\n",
            "第 15 个Fold\n",
            "[0]\teval-mlogloss:1.08974\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.779106\n",
            "[100]\teval-mlogloss:0.608591\n",
            "[150]\teval-mlogloss:0.504609\n",
            "[200]\teval-mlogloss:0.438164\n",
            "[250]\teval-mlogloss:0.391062\n",
            "[300]\teval-mlogloss:0.358524\n",
            "[350]\teval-mlogloss:0.332994\n",
            "[400]\teval-mlogloss:0.314396\n",
            "[450]\teval-mlogloss:0.298489\n",
            "[500]\teval-mlogloss:0.285831\n",
            "[550]\teval-mlogloss:0.275136\n",
            "[600]\teval-mlogloss:0.266307\n",
            "[650]\teval-mlogloss:0.257903\n",
            "[700]\teval-mlogloss:0.250891\n",
            "[750]\teval-mlogloss:0.244806\n",
            "[800]\teval-mlogloss:0.238938\n",
            "[850]\teval-mlogloss:0.233643\n",
            "[900]\teval-mlogloss:0.228854\n",
            "[950]\teval-mlogloss:0.224402\n",
            "[1000]\teval-mlogloss:0.220498\n",
            "[1050]\teval-mlogloss:0.216503\n",
            "[1100]\teval-mlogloss:0.212968\n",
            "[1150]\teval-mlogloss:0.209482\n",
            "[1200]\teval-mlogloss:0.206183\n",
            "[1250]\teval-mlogloss:0.203178\n",
            "[1300]\teval-mlogloss:0.200386\n",
            "[1350]\teval-mlogloss:0.197867\n",
            "[1400]\teval-mlogloss:0.195335\n",
            "[1450]\teval-mlogloss:0.192943\n",
            "[1500]\teval-mlogloss:0.190741\n",
            "[1550]\teval-mlogloss:0.188629\n",
            "[1600]\teval-mlogloss:0.186607\n",
            "[1650]\teval-mlogloss:0.185044\n",
            "[1700]\teval-mlogloss:0.183476\n",
            "[1750]\teval-mlogloss:0.181813\n",
            "[1800]\teval-mlogloss:0.179839\n",
            "[1850]\teval-mlogloss:0.178574\n",
            "[1900]\teval-mlogloss:0.177273\n",
            "[1950]\teval-mlogloss:0.176173\n",
            "[2000]\teval-mlogloss:0.174955\n",
            "[2050]\teval-mlogloss:0.173627\n",
            "[2100]\teval-mlogloss:0.172707\n",
            "[2150]\teval-mlogloss:0.171601\n",
            "[2200]\teval-mlogloss:0.170842\n",
            "[2250]\teval-mlogloss:0.170031\n",
            "[2300]\teval-mlogloss:0.169455\n",
            "[2350]\teval-mlogloss:0.168661\n",
            "[2400]\teval-mlogloss:0.167998\n",
            "[2450]\teval-mlogloss:0.167382\n",
            "[2500]\teval-mlogloss:0.166903\n",
            "[2550]\teval-mlogloss:0.166256\n",
            "[2600]\teval-mlogloss:0.165841\n",
            "[2650]\teval-mlogloss:0.165372\n",
            "[2700]\teval-mlogloss:0.164863\n",
            "[2750]\teval-mlogloss:0.164329\n",
            "[2800]\teval-mlogloss:0.163904\n",
            "[2850]\teval-mlogloss:0.163569\n",
            "[2900]\teval-mlogloss:0.162986\n",
            "[2950]\teval-mlogloss:0.162668\n",
            "[3000]\teval-mlogloss:0.162238\n",
            "[3050]\teval-mlogloss:0.161935\n",
            "[3100]\teval-mlogloss:0.161838\n",
            "[3150]\teval-mlogloss:0.161274\n",
            "[3200]\teval-mlogloss:0.161054\n",
            "[3250]\teval-mlogloss:0.160993\n",
            "[3300]\teval-mlogloss:0.16081\n",
            "[3350]\teval-mlogloss:0.160423\n",
            "[3400]\teval-mlogloss:0.160181\n",
            "[3450]\teval-mlogloss:0.160228\n",
            "[3500]\teval-mlogloss:0.159926\n",
            "[3550]\teval-mlogloss:0.159825\n",
            "[3600]\teval-mlogloss:0.159733\n",
            "[3650]\teval-mlogloss:0.159576\n",
            "[3700]\teval-mlogloss:0.159349\n",
            "[3750]\teval-mlogloss:0.159285\n",
            "[3800]\teval-mlogloss:0.159126\n",
            "[3850]\teval-mlogloss:0.159388\n",
            "Stopping. Best iteration:\n",
            "[3786]\teval-mlogloss:0.159028\n",
            "\n",
            "0.939043390800915\n",
            "第 16 个Fold\n",
            "[0]\teval-mlogloss:1.08997\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.777907\n",
            "[100]\teval-mlogloss:0.605707\n",
            "[150]\teval-mlogloss:0.501062\n",
            "[200]\teval-mlogloss:0.431479\n",
            "[250]\teval-mlogloss:0.383033\n",
            "[300]\teval-mlogloss:0.348688\n",
            "[350]\teval-mlogloss:0.321599\n",
            "[400]\teval-mlogloss:0.301039\n",
            "[450]\teval-mlogloss:0.284641\n",
            "[500]\teval-mlogloss:0.270788\n",
            "[550]\teval-mlogloss:0.258521\n",
            "[600]\teval-mlogloss:0.248862\n",
            "[650]\teval-mlogloss:0.240168\n",
            "[700]\teval-mlogloss:0.232629\n",
            "[750]\teval-mlogloss:0.225641\n",
            "[800]\teval-mlogloss:0.219325\n",
            "[850]\teval-mlogloss:0.213302\n",
            "[900]\teval-mlogloss:0.208598\n",
            "[950]\teval-mlogloss:0.203986\n",
            "[1000]\teval-mlogloss:0.199155\n",
            "[1050]\teval-mlogloss:0.195352\n",
            "[1100]\teval-mlogloss:0.191757\n",
            "[1150]\teval-mlogloss:0.188082\n",
            "[1200]\teval-mlogloss:0.185023\n",
            "[1250]\teval-mlogloss:0.182082\n",
            "[1300]\teval-mlogloss:0.179399\n",
            "[1350]\teval-mlogloss:0.176989\n",
            "[1400]\teval-mlogloss:0.174366\n",
            "[1450]\teval-mlogloss:0.172127\n",
            "[1500]\teval-mlogloss:0.170248\n",
            "[1550]\teval-mlogloss:0.16793\n",
            "[1600]\teval-mlogloss:0.165952\n",
            "[1650]\teval-mlogloss:0.164195\n",
            "[1700]\teval-mlogloss:0.162878\n",
            "[1750]\teval-mlogloss:0.161257\n",
            "[1800]\teval-mlogloss:0.159549\n",
            "[1850]\teval-mlogloss:0.158153\n",
            "[1900]\teval-mlogloss:0.156806\n",
            "[1950]\teval-mlogloss:0.155798\n",
            "[2000]\teval-mlogloss:0.154775\n",
            "[2050]\teval-mlogloss:0.154014\n",
            "[2100]\teval-mlogloss:0.152835\n",
            "[2150]\teval-mlogloss:0.151943\n",
            "[2200]\teval-mlogloss:0.150778\n",
            "[2250]\teval-mlogloss:0.149715\n",
            "[2300]\teval-mlogloss:0.148928\n",
            "[2350]\teval-mlogloss:0.148261\n",
            "[2400]\teval-mlogloss:0.14781\n",
            "[2450]\teval-mlogloss:0.147306\n",
            "[2500]\teval-mlogloss:0.146633\n",
            "[2550]\teval-mlogloss:0.145994\n",
            "[2600]\teval-mlogloss:0.145328\n",
            "[2650]\teval-mlogloss:0.144777\n",
            "[2700]\teval-mlogloss:0.144422\n",
            "[2750]\teval-mlogloss:0.143794\n",
            "[2800]\teval-mlogloss:0.143464\n",
            "[2850]\teval-mlogloss:0.143034\n",
            "[2900]\teval-mlogloss:0.142813\n",
            "[2950]\teval-mlogloss:0.142315\n",
            "[3000]\teval-mlogloss:0.141872\n",
            "[3050]\teval-mlogloss:0.141703\n",
            "[3100]\teval-mlogloss:0.141458\n",
            "[3150]\teval-mlogloss:0.141216\n",
            "[3200]\teval-mlogloss:0.140942\n",
            "[3250]\teval-mlogloss:0.140656\n",
            "[3300]\teval-mlogloss:0.140337\n",
            "[3350]\teval-mlogloss:0.140238\n",
            "[3400]\teval-mlogloss:0.14011\n",
            "[3450]\teval-mlogloss:0.139918\n",
            "[3500]\teval-mlogloss:0.139682\n",
            "[3550]\teval-mlogloss:0.139631\n",
            "[3600]\teval-mlogloss:0.139517\n",
            "[3650]\teval-mlogloss:0.139305\n",
            "[3700]\teval-mlogloss:0.139098\n",
            "[3750]\teval-mlogloss:0.139017\n",
            "[3800]\teval-mlogloss:0.139025\n",
            "Stopping. Best iteration:\n",
            "[3722]\teval-mlogloss:0.138936\n",
            "\n",
            "0.9478968541225304\n",
            "第 17 个Fold\n",
            "[0]\teval-mlogloss:1.09027\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.784994\n",
            "[100]\teval-mlogloss:0.618711\n",
            "[150]\teval-mlogloss:0.5159\n",
            "[200]\teval-mlogloss:0.449442\n",
            "[250]\teval-mlogloss:0.403887\n",
            "[300]\teval-mlogloss:0.370487\n",
            "[350]\teval-mlogloss:0.345287\n",
            "[400]\teval-mlogloss:0.325549\n",
            "[450]\teval-mlogloss:0.309479\n",
            "[500]\teval-mlogloss:0.296742\n",
            "[550]\teval-mlogloss:0.285728\n",
            "[600]\teval-mlogloss:0.276616\n",
            "[650]\teval-mlogloss:0.268552\n",
            "[700]\teval-mlogloss:0.260596\n",
            "[750]\teval-mlogloss:0.253989\n",
            "[800]\teval-mlogloss:0.248497\n",
            "[850]\teval-mlogloss:0.243109\n",
            "[900]\teval-mlogloss:0.238425\n",
            "[950]\teval-mlogloss:0.233618\n",
            "[1000]\teval-mlogloss:0.228778\n",
            "[1050]\teval-mlogloss:0.224992\n",
            "[1100]\teval-mlogloss:0.221286\n",
            "[1150]\teval-mlogloss:0.218002\n",
            "[1200]\teval-mlogloss:0.214982\n",
            "[1250]\teval-mlogloss:0.211931\n",
            "[1300]\teval-mlogloss:0.209729\n",
            "[1350]\teval-mlogloss:0.207167\n",
            "[1400]\teval-mlogloss:0.204733\n",
            "[1450]\teval-mlogloss:0.202916\n",
            "[1500]\teval-mlogloss:0.200376\n",
            "[1550]\teval-mlogloss:0.198289\n",
            "[1600]\teval-mlogloss:0.196474\n",
            "[1650]\teval-mlogloss:0.194903\n",
            "[1700]\teval-mlogloss:0.193433\n",
            "[1750]\teval-mlogloss:0.192022\n",
            "[1800]\teval-mlogloss:0.190895\n",
            "[1850]\teval-mlogloss:0.189884\n",
            "[1900]\teval-mlogloss:0.188778\n",
            "[1950]\teval-mlogloss:0.187621\n",
            "[2000]\teval-mlogloss:0.186326\n",
            "[2050]\teval-mlogloss:0.185345\n",
            "[2100]\teval-mlogloss:0.18459\n",
            "[2150]\teval-mlogloss:0.184008\n",
            "[2200]\teval-mlogloss:0.183062\n",
            "[2250]\teval-mlogloss:0.182225\n",
            "[2300]\teval-mlogloss:0.181827\n",
            "[2350]\teval-mlogloss:0.181247\n",
            "[2400]\teval-mlogloss:0.180636\n",
            "[2450]\teval-mlogloss:0.17992\n",
            "[2500]\teval-mlogloss:0.179527\n",
            "[2550]\teval-mlogloss:0.178979\n",
            "[2600]\teval-mlogloss:0.178604\n",
            "[2650]\teval-mlogloss:0.178197\n",
            "[2700]\teval-mlogloss:0.178073\n",
            "[2750]\teval-mlogloss:0.177621\n",
            "[2800]\teval-mlogloss:0.177078\n",
            "[2850]\teval-mlogloss:0.176864\n",
            "[2900]\teval-mlogloss:0.176612\n",
            "[2950]\teval-mlogloss:0.176296\n",
            "[3000]\teval-mlogloss:0.176037\n",
            "[3050]\teval-mlogloss:0.175923\n",
            "[3100]\teval-mlogloss:0.175845\n",
            "[3150]\teval-mlogloss:0.175793\n",
            "[3200]\teval-mlogloss:0.175462\n",
            "[3250]\teval-mlogloss:0.17524\n",
            "[3300]\teval-mlogloss:0.175216\n",
            "[3350]\teval-mlogloss:0.175067\n",
            "[3400]\teval-mlogloss:0.174948\n",
            "[3450]\teval-mlogloss:0.174608\n",
            "[3500]\teval-mlogloss:0.174741\n",
            "[3550]\teval-mlogloss:0.174612\n",
            "[3600]\teval-mlogloss:0.174355\n",
            "[3650]\teval-mlogloss:0.174382\n",
            "[3700]\teval-mlogloss:0.174362\n",
            "Stopping. Best iteration:\n",
            "[3604]\teval-mlogloss:0.174326\n",
            "\n",
            "0.9340531343287332\n",
            "第 18 个Fold\n",
            "[0]\teval-mlogloss:1.08947\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.75609\n",
            "[100]\teval-mlogloss:0.574414\n",
            "[150]\teval-mlogloss:0.465326\n",
            "[200]\teval-mlogloss:0.394864\n",
            "[250]\teval-mlogloss:0.34638\n",
            "[300]\teval-mlogloss:0.313466\n",
            "[350]\teval-mlogloss:0.288681\n",
            "[400]\teval-mlogloss:0.270198\n",
            "[450]\teval-mlogloss:0.255248\n",
            "[500]\teval-mlogloss:0.243356\n",
            "[550]\teval-mlogloss:0.233313\n",
            "[600]\teval-mlogloss:0.224948\n",
            "[650]\teval-mlogloss:0.217373\n",
            "[700]\teval-mlogloss:0.210629\n",
            "[750]\teval-mlogloss:0.205072\n",
            "[800]\teval-mlogloss:0.199823\n",
            "[850]\teval-mlogloss:0.194957\n",
            "[900]\teval-mlogloss:0.190678\n",
            "[950]\teval-mlogloss:0.186521\n",
            "[1000]\teval-mlogloss:0.182896\n",
            "[1050]\teval-mlogloss:0.179165\n",
            "[1100]\teval-mlogloss:0.176239\n",
            "[1150]\teval-mlogloss:0.173283\n",
            "[1200]\teval-mlogloss:0.170548\n",
            "[1250]\teval-mlogloss:0.167861\n",
            "[1300]\teval-mlogloss:0.165497\n",
            "[1350]\teval-mlogloss:0.163394\n",
            "[1400]\teval-mlogloss:0.160943\n",
            "[1450]\teval-mlogloss:0.15888\n",
            "[1500]\teval-mlogloss:0.156991\n",
            "[1550]\teval-mlogloss:0.155042\n",
            "[1600]\teval-mlogloss:0.153442\n",
            "[1650]\teval-mlogloss:0.151689\n",
            "[1700]\teval-mlogloss:0.150211\n",
            "[1750]\teval-mlogloss:0.148807\n",
            "[1800]\teval-mlogloss:0.147426\n",
            "[1850]\teval-mlogloss:0.146144\n",
            "[1900]\teval-mlogloss:0.144692\n",
            "[1950]\teval-mlogloss:0.143619\n",
            "[2000]\teval-mlogloss:0.142736\n",
            "[2050]\teval-mlogloss:0.141623\n",
            "[2100]\teval-mlogloss:0.140674\n",
            "[2150]\teval-mlogloss:0.139891\n",
            "[2200]\teval-mlogloss:0.13908\n",
            "[2250]\teval-mlogloss:0.138333\n",
            "[2300]\teval-mlogloss:0.137581\n",
            "[2350]\teval-mlogloss:0.136848\n",
            "[2400]\teval-mlogloss:0.136211\n",
            "[2450]\teval-mlogloss:0.135431\n",
            "[2500]\teval-mlogloss:0.134773\n",
            "[2550]\teval-mlogloss:0.134287\n",
            "[2600]\teval-mlogloss:0.133844\n",
            "[2650]\teval-mlogloss:0.133333\n",
            "[2700]\teval-mlogloss:0.133053\n",
            "[2750]\teval-mlogloss:0.132712\n",
            "[2800]\teval-mlogloss:0.132197\n",
            "[2850]\teval-mlogloss:0.131857\n",
            "[2900]\teval-mlogloss:0.131573\n",
            "[2950]\teval-mlogloss:0.131131\n",
            "[3000]\teval-mlogloss:0.130893\n",
            "[3050]\teval-mlogloss:0.130641\n",
            "[3100]\teval-mlogloss:0.130262\n",
            "[3150]\teval-mlogloss:0.130001\n",
            "[3200]\teval-mlogloss:0.129881\n",
            "[3250]\teval-mlogloss:0.129656\n",
            "[3300]\teval-mlogloss:0.129422\n",
            "[3350]\teval-mlogloss:0.129291\n",
            "[3400]\teval-mlogloss:0.129153\n",
            "[3450]\teval-mlogloss:0.129238\n",
            "[3500]\teval-mlogloss:0.12894\n",
            "[3550]\teval-mlogloss:0.128779\n",
            "[3600]\teval-mlogloss:0.128731\n",
            "[3650]\teval-mlogloss:0.128868\n",
            "Stopping. Best iteration:\n",
            "[3583]\teval-mlogloss:0.128707\n",
            "\n",
            "0.9540544848507378\n",
            "第 19 个Fold\n",
            "[0]\teval-mlogloss:1.09017\n",
            "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
            "[50]\teval-mlogloss:0.77739\n",
            "[100]\teval-mlogloss:0.605693\n",
            "[150]\teval-mlogloss:0.498365\n",
            "[200]\teval-mlogloss:0.42913\n",
            "[250]\teval-mlogloss:0.38077\n",
            "[300]\teval-mlogloss:0.346557\n",
            "[350]\teval-mlogloss:0.32052\n",
            "[400]\teval-mlogloss:0.300696\n",
            "[450]\teval-mlogloss:0.284698\n",
            "[500]\teval-mlogloss:0.271952\n",
            "[550]\teval-mlogloss:0.260906\n",
            "[600]\teval-mlogloss:0.251818\n",
            "[650]\teval-mlogloss:0.243865\n",
            "[700]\teval-mlogloss:0.236578\n",
            "[750]\teval-mlogloss:0.229922\n",
            "[800]\teval-mlogloss:0.224022\n",
            "[850]\teval-mlogloss:0.218267\n",
            "[900]\teval-mlogloss:0.213104\n",
            "[950]\teval-mlogloss:0.20856\n",
            "[1000]\teval-mlogloss:0.204118\n",
            "[1050]\teval-mlogloss:0.200222\n",
            "[1100]\teval-mlogloss:0.19635\n",
            "[1150]\teval-mlogloss:0.192839\n",
            "[1200]\teval-mlogloss:0.189785\n",
            "[1250]\teval-mlogloss:0.187502\n",
            "[1300]\teval-mlogloss:0.184697\n",
            "[1350]\teval-mlogloss:0.182181\n",
            "[1400]\teval-mlogloss:0.179628\n",
            "[1450]\teval-mlogloss:0.177071\n",
            "[1500]\teval-mlogloss:0.174655\n",
            "[1550]\teval-mlogloss:0.172626\n",
            "[1600]\teval-mlogloss:0.170668\n",
            "[1650]\teval-mlogloss:0.168737\n",
            "[1700]\teval-mlogloss:0.16692\n",
            "[1750]\teval-mlogloss:0.165197\n",
            "[1800]\teval-mlogloss:0.163891\n",
            "[1850]\teval-mlogloss:0.162315\n",
            "[1900]\teval-mlogloss:0.160887\n",
            "[1950]\teval-mlogloss:0.159574\n",
            "[2000]\teval-mlogloss:0.158427\n",
            "[2050]\teval-mlogloss:0.157322\n",
            "[2100]\teval-mlogloss:0.156302\n",
            "[2150]\teval-mlogloss:0.155641\n",
            "[2200]\teval-mlogloss:0.154678\n",
            "[2250]\teval-mlogloss:0.153979\n",
            "[2300]\teval-mlogloss:0.15305\n",
            "[2350]\teval-mlogloss:0.15205\n",
            "[2400]\teval-mlogloss:0.151343\n",
            "[2450]\teval-mlogloss:0.150672\n",
            "[2500]\teval-mlogloss:0.149987\n",
            "[2550]\teval-mlogloss:0.149335\n",
            "[2600]\teval-mlogloss:0.148645\n",
            "[2650]\teval-mlogloss:0.148189\n",
            "[2700]\teval-mlogloss:0.147873\n",
            "[2750]\teval-mlogloss:0.147227\n",
            "[2800]\teval-mlogloss:0.146777\n",
            "[2850]\teval-mlogloss:0.14632\n",
            "[2900]\teval-mlogloss:0.145838\n",
            "[2950]\teval-mlogloss:0.145485\n",
            "[3000]\teval-mlogloss:0.145097\n",
            "[3050]\teval-mlogloss:0.144568\n",
            "[3100]\teval-mlogloss:0.144268\n",
            "[3150]\teval-mlogloss:0.143805\n",
            "[3200]\teval-mlogloss:0.143578\n",
            "[3250]\teval-mlogloss:0.143194\n",
            "[3300]\teval-mlogloss:0.143002\n",
            "[3350]\teval-mlogloss:0.142648\n",
            "[3400]\teval-mlogloss:0.142333\n",
            "[3450]\teval-mlogloss:0.14194\n",
            "[3500]\teval-mlogloss:0.14184\n",
            "[3550]\teval-mlogloss:0.141486\n",
            "[3600]\teval-mlogloss:0.141191\n",
            "[3650]\teval-mlogloss:0.140984\n",
            "[3700]\teval-mlogloss:0.140785\n",
            "[3750]\teval-mlogloss:0.14061\n",
            "[3800]\teval-mlogloss:0.140427\n",
            "[3850]\teval-mlogloss:0.140309\n",
            "[3900]\teval-mlogloss:0.140228\n",
            "[3950]\teval-mlogloss:0.140154\n",
            "[4000]\teval-mlogloss:0.13994\n",
            "[4050]\teval-mlogloss:0.140033\n",
            "[4100]\teval-mlogloss:0.139946\n",
            "Stopping. Best iteration:\n",
            "[4005]\teval-mlogloss:0.139888\n",
            "\n",
            "0.9464244895437556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtfmUULlelJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yu_type = {0:'拖网',1:'围网',2:'刺网'}\n",
        "res = finalRes(selectMost(np.vstack((xgb_preds,lgb_preds))))\n",
        "sub = test_dataset[['ship']]\n",
        "sub['pred'] = res\n",
        "sub.to_csv('/content/drive/My Drive/result_xgb_lgb_2.csv',index=False,header=False,encoding='utf_8_sig')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5NmSebF4yQ",
        "colab_type": "code",
        "outputId": "ded11f29-e94b-4817-d1d9-e46aabb2bf8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print('拖网:', 1249/sub.shape[0])\n",
        "print('围网:', 481/sub.shape[0])\n",
        "print('刺网:', 270/sub.shape[0])\n",
        "Counter(sub['pred'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "拖网: 0.6245\n",
            "围网: 0.2405\n",
            "刺网: 0.135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'刺网': 270, '围网': 481, '拖网': 1249})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcvHw9LpPd-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_features = []\n",
        "def CatKfoldResult(train=x_final,test=test_final,label=y_final,cat_features=cat_features,K=5):\n",
        "  fold = StratifiedKFold(n_splits=K,shuffle=True)\n",
        "  preds = []\n",
        "  models = []\n",
        "  i = 0\n",
        "  for train_index, valid_index in fold.split(train,label):\n",
        "      print('第',str(i),'个Fold')\n",
        "      i += 1\n",
        "      # train_x,valid_x,train_y,valid_y = train.iloc[train_index],train.iloc[valid_index],label[train_index],label[valid_index]\n",
        "      train_x,valid_x,train_y,valid_y = train[train_index],train[valid_index],label[train_index],label[valid_index]\n",
        "      eval_set = cat.Pool(data=valid_x,label=valid_y,cat_features=cat_features)\n",
        "      model = cat.CatBoostClassifier(iterations=5000, learning_rate=0.1, depth=7, loss_function='MultiClass')\n",
        "      model.fit(train_x,train_y,use_best_model=True,eval_set=eval_set,cat_features=cat_features,early_stopping_rounds=100,verbose_eval=50)\n",
        "      models.append(model)\n",
        "      val_pred = model.predict(valid_x).reshape((-1))\n",
        "      print(metrics.f1_score(valid_y, val_pred, average='macro'))\n",
        "      preds.append(model.predict(test).reshape((-1)))\n",
        "  \n",
        "  preds = np.array(preds)\n",
        "  return models,preds.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu6xB6izuPer",
        "colab_type": "code",
        "outputId": "8bb19edb-40ff-44e2-d807-b79108939334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cat_model, cat_preds = CatKfoldResult()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "第 0 个Fold\n",
            "0:\tlearn: 1.0128294\ttest: 1.0147437\tbest: 1.0147437 (0)\ttotal: 115ms\tremaining: 9m 37s\n",
            "50:\tlearn: 0.4426961\ttest: 0.4812284\tbest: 0.4812284 (50)\ttotal: 4.2s\tremaining: 6m 47s\n",
            "100:\tlearn: 0.3487435\ttest: 0.4063151\tbest: 0.4063151 (100)\ttotal: 8.37s\tremaining: 6m 46s\n",
            "150:\tlearn: 0.2881353\ttest: 0.3610745\tbest: 0.3610745 (150)\ttotal: 12.4s\tremaining: 6m 37s\n",
            "200:\tlearn: 0.2469707\ttest: 0.3343860\tbest: 0.3343860 (200)\ttotal: 16.4s\tremaining: 6m 30s\n",
            "250:\tlearn: 0.2119149\ttest: 0.3103364\tbest: 0.3103364 (250)\ttotal: 20.3s\tremaining: 6m 24s\n",
            "300:\tlearn: 0.1871538\ttest: 0.2946324\tbest: 0.2946324 (300)\ttotal: 24.4s\tremaining: 6m 20s\n",
            "350:\tlearn: 0.1659371\ttest: 0.2801876\tbest: 0.2801876 (350)\ttotal: 28.4s\tremaining: 6m 16s\n",
            "400:\tlearn: 0.1486965\ttest: 0.2694206\tbest: 0.2694206 (400)\ttotal: 32.6s\tremaining: 6m 13s\n",
            "450:\tlearn: 0.1344110\ttest: 0.2610661\tbest: 0.2610661 (450)\ttotal: 36.6s\tremaining: 6m 8s\n",
            "500:\tlearn: 0.1228347\ttest: 0.2532594\tbest: 0.2532594 (500)\ttotal: 40.6s\tremaining: 6m 4s\n",
            "550:\tlearn: 0.1114192\ttest: 0.2467605\tbest: 0.2467605 (550)\ttotal: 44.6s\tremaining: 6m\n",
            "600:\tlearn: 0.1010414\ttest: 0.2398765\tbest: 0.2398765 (600)\ttotal: 48.6s\tremaining: 5m 56s\n",
            "650:\tlearn: 0.0927568\ttest: 0.2352621\tbest: 0.2352605 (648)\ttotal: 52.8s\tremaining: 5m 52s\n",
            "700:\tlearn: 0.0849023\ttest: 0.2301956\tbest: 0.2301400 (699)\ttotal: 56.7s\tremaining: 5m 47s\n",
            "750:\tlearn: 0.0783946\ttest: 0.2263302\tbest: 0.2263302 (750)\ttotal: 1m\tremaining: 5m 43s\n",
            "800:\tlearn: 0.0721124\ttest: 0.2220986\tbest: 0.2220986 (800)\ttotal: 1m 4s\tremaining: 5m 39s\n",
            "850:\tlearn: 0.0667074\ttest: 0.2187362\tbest: 0.2187362 (850)\ttotal: 1m 9s\tremaining: 5m 36s\n",
            "900:\tlearn: 0.0619782\ttest: 0.2155635\tbest: 0.2155586 (899)\ttotal: 1m 13s\tremaining: 5m 32s\n",
            "950:\tlearn: 0.0580968\ttest: 0.2131231\tbest: 0.2131231 (950)\ttotal: 1m 17s\tremaining: 5m 28s\n",
            "1000:\tlearn: 0.0545084\ttest: 0.2104730\tbest: 0.2104728 (999)\ttotal: 1m 21s\tremaining: 5m 23s\n",
            "1050:\tlearn: 0.0510440\ttest: 0.2076524\tbest: 0.2076524 (1049)\ttotal: 1m 25s\tremaining: 5m 19s\n",
            "1100:\tlearn: 0.0477854\ttest: 0.2055528\tbest: 0.2055359 (1099)\ttotal: 1m 29s\tremaining: 5m 15s\n",
            "1150:\tlearn: 0.0450400\ttest: 0.2044695\tbest: 0.2044608 (1149)\ttotal: 1m 33s\tremaining: 5m 11s\n",
            "1200:\tlearn: 0.0424947\ttest: 0.2028856\tbest: 0.2028856 (1200)\ttotal: 1m 37s\tremaining: 5m 6s\n",
            "1250:\tlearn: 0.0401899\ttest: 0.2019777\tbest: 0.2019762 (1248)\ttotal: 1m 41s\tremaining: 5m 2s\n",
            "1300:\tlearn: 0.0378347\ttest: 0.2003397\tbest: 0.2002499 (1296)\ttotal: 1m 45s\tremaining: 4m 59s\n",
            "1350:\tlearn: 0.0358057\ttest: 0.1994930\tbest: 0.1994720 (1349)\ttotal: 1m 49s\tremaining: 4m 55s\n",
            "1400:\tlearn: 0.0339045\ttest: 0.1972367\tbest: 0.1972367 (1400)\ttotal: 1m 53s\tremaining: 4m 51s\n",
            "1450:\tlearn: 0.0322672\ttest: 0.1962442\tbest: 0.1961974 (1447)\ttotal: 1m 57s\tremaining: 4m 46s\n",
            "1500:\tlearn: 0.0306675\ttest: 0.1950403\tbest: 0.1950366 (1499)\ttotal: 2m 1s\tremaining: 4m 42s\n",
            "1550:\tlearn: 0.0289818\ttest: 0.1935504\tbest: 0.1935504 (1550)\ttotal: 2m 4s\tremaining: 4m 37s\n",
            "1600:\tlearn: 0.0277711\ttest: 0.1925134\tbest: 0.1923562 (1595)\ttotal: 2m 8s\tremaining: 4m 33s\n",
            "1650:\tlearn: 0.0264865\ttest: 0.1921437\tbest: 0.1921193 (1629)\ttotal: 2m 12s\tremaining: 4m 29s\n",
            "1700:\tlearn: 0.0251981\ttest: 0.1911164\tbest: 0.1911087 (1699)\ttotal: 2m 16s\tremaining: 4m 25s\n",
            "1750:\tlearn: 0.0241213\ttest: 0.1905750\tbest: 0.1905750 (1750)\ttotal: 2m 20s\tremaining: 4m 21s\n",
            "1800:\tlearn: 0.0230646\ttest: 0.1899820\tbest: 0.1899820 (1800)\ttotal: 2m 24s\tremaining: 4m 17s\n",
            "1850:\tlearn: 0.0220915\ttest: 0.1895145\tbest: 0.1894805 (1849)\ttotal: 2m 28s\tremaining: 4m 12s\n",
            "1900:\tlearn: 0.0211791\ttest: 0.1887474\tbest: 0.1886454 (1895)\ttotal: 2m 32s\tremaining: 4m 8s\n",
            "1950:\tlearn: 0.0203666\ttest: 0.1884596\tbest: 0.1884403 (1944)\ttotal: 2m 36s\tremaining: 4m 4s\n",
            "2000:\tlearn: 0.0194702\ttest: 0.1873545\tbest: 0.1872734 (1997)\ttotal: 2m 40s\tremaining: 4m\n",
            "2050:\tlearn: 0.0187355\ttest: 0.1870290\tbest: 0.1869491 (2047)\ttotal: 2m 44s\tremaining: 3m 56s\n",
            "2100:\tlearn: 0.0180313\ttest: 0.1869881\tbest: 0.1869491 (2047)\ttotal: 2m 48s\tremaining: 3m 51s\n",
            "2150:\tlearn: 0.0173581\ttest: 0.1868176\tbest: 0.1867009 (2130)\ttotal: 2m 52s\tremaining: 3m 47s\n",
            "2200:\tlearn: 0.0167022\ttest: 0.1867807\tbest: 0.1867009 (2130)\ttotal: 2m 55s\tremaining: 3m 43s\n",
            "2250:\tlearn: 0.0161167\ttest: 0.1866106\tbest: 0.1865126 (2216)\ttotal: 2m 59s\tremaining: 3m 39s\n",
            "2300:\tlearn: 0.0155662\ttest: 0.1864510\tbest: 0.1862768 (2291)\ttotal: 3m 3s\tremaining: 3m 35s\n",
            "2350:\tlearn: 0.0150125\ttest: 0.1861982\tbest: 0.1860336 (2344)\ttotal: 3m 7s\tremaining: 3m 31s\n",
            "2400:\tlearn: 0.0145434\ttest: 0.1859615\tbest: 0.1858295 (2388)\ttotal: 3m 11s\tremaining: 3m 27s\n",
            "2450:\tlearn: 0.0140757\ttest: 0.1857696\tbest: 0.1856392 (2443)\ttotal: 3m 15s\tremaining: 3m 23s\n",
            "2500:\tlearn: 0.0136150\ttest: 0.1855423\tbest: 0.1854579 (2486)\ttotal: 3m 19s\tremaining: 3m 18s\n",
            "2550:\tlearn: 0.0131814\ttest: 0.1854814\tbest: 0.1854526 (2549)\ttotal: 3m 23s\tremaining: 3m 14s\n",
            "2600:\tlearn: 0.0127896\ttest: 0.1855155\tbest: 0.1854526 (2549)\ttotal: 3m 26s\tremaining: 3m 10s\n",
            "2650:\tlearn: 0.0124265\ttest: 0.1852631\tbest: 0.1852034 (2645)\ttotal: 3m 30s\tremaining: 3m 6s\n",
            "2700:\tlearn: 0.0120897\ttest: 0.1852134\tbest: 0.1850212 (2674)\ttotal: 3m 34s\tremaining: 3m 2s\n",
            "2750:\tlearn: 0.0117206\ttest: 0.1846788\tbest: 0.1846788 (2750)\ttotal: 3m 38s\tremaining: 2m 58s\n",
            "2800:\tlearn: 0.0113809\ttest: 0.1845155\tbest: 0.1845055 (2799)\ttotal: 3m 42s\tremaining: 2m 54s\n",
            "2850:\tlearn: 0.0110618\ttest: 0.1844063\tbest: 0.1843383 (2844)\ttotal: 3m 46s\tremaining: 2m 50s\n",
            "2900:\tlearn: 0.0107779\ttest: 0.1845217\tbest: 0.1843383 (2844)\ttotal: 3m 50s\tremaining: 2m 46s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.1843382605\n",
            "bestIteration = 2844\n",
            "\n",
            "Shrink model to first 2845 iterations.\n",
            "0.9355588046877944\n",
            "第 1 个Fold\n",
            "0:\tlearn: 1.0184962\ttest: 1.0186085\tbest: 1.0186085 (0)\ttotal: 80.6ms\tremaining: 6m 42s\n",
            "50:\tlearn: 0.4463379\ttest: 0.4725595\tbest: 0.4725595 (50)\ttotal: 4.09s\tremaining: 6m 37s\n",
            "100:\tlearn: 0.3496651\ttest: 0.3989315\tbest: 0.3989315 (100)\ttotal: 8.06s\tremaining: 6m 31s\n",
            "150:\tlearn: 0.2860420\ttest: 0.3528571\tbest: 0.3528571 (150)\ttotal: 12.1s\tremaining: 6m 27s\n",
            "200:\tlearn: 0.2417777\ttest: 0.3227801\tbest: 0.3227801 (200)\ttotal: 16s\tremaining: 6m 21s\n",
            "250:\tlearn: 0.2103417\ttest: 0.2998581\tbest: 0.2998581 (250)\ttotal: 20.1s\tremaining: 6m 19s\n",
            "300:\tlearn: 0.1846105\ttest: 0.2839521\tbest: 0.2839521 (300)\ttotal: 24.3s\tremaining: 6m 18s\n",
            "350:\tlearn: 0.1645157\ttest: 0.2718403\tbest: 0.2718403 (350)\ttotal: 28.5s\tremaining: 6m 17s\n",
            "400:\tlearn: 0.1485223\ttest: 0.2621959\tbest: 0.2621959 (400)\ttotal: 32.7s\tremaining: 6m 15s\n",
            "450:\tlearn: 0.1339420\ttest: 0.2539111\tbest: 0.2539111 (450)\ttotal: 37s\tremaining: 6m 12s\n",
            "500:\tlearn: 0.1210764\ttest: 0.2465568\tbest: 0.2465568 (500)\ttotal: 41.2s\tremaining: 6m 10s\n",
            "550:\tlearn: 0.1107983\ttest: 0.2417269\tbest: 0.2417269 (550)\ttotal: 45.5s\tremaining: 6m 7s\n",
            "600:\tlearn: 0.1009686\ttest: 0.2361591\tbest: 0.2361591 (600)\ttotal: 49.6s\tremaining: 6m 2s\n",
            "650:\tlearn: 0.0925664\ttest: 0.2308784\tbest: 0.2308784 (650)\ttotal: 53.8s\tremaining: 5m 59s\n",
            "700:\tlearn: 0.0849077\ttest: 0.2266029\tbest: 0.2266029 (700)\ttotal: 58.1s\tremaining: 5m 56s\n",
            "750:\tlearn: 0.0784150\ttest: 0.2231656\tbest: 0.2231656 (750)\ttotal: 1m 2s\tremaining: 5m 51s\n",
            "800:\tlearn: 0.0728565\ttest: 0.2193837\tbest: 0.2193837 (800)\ttotal: 1m 6s\tremaining: 5m 46s\n",
            "850:\tlearn: 0.0673950\ttest: 0.2160191\tbest: 0.2160191 (850)\ttotal: 1m 10s\tremaining: 5m 41s\n",
            "900:\tlearn: 0.0625334\ttest: 0.2127404\tbest: 0.2127404 (900)\ttotal: 1m 14s\tremaining: 5m 37s\n",
            "950:\tlearn: 0.0581834\ttest: 0.2097774\tbest: 0.2097774 (950)\ttotal: 1m 18s\tremaining: 5m 32s\n",
            "1000:\tlearn: 0.0545799\ttest: 0.2075785\tbest: 0.2075785 (1000)\ttotal: 1m 22s\tremaining: 5m 27s\n",
            "1050:\tlearn: 0.0513089\ttest: 0.2052029\tbest: 0.2052029 (1050)\ttotal: 1m 25s\tremaining: 5m 22s\n",
            "1100:\tlearn: 0.0479553\ttest: 0.2031577\tbest: 0.2031577 (1100)\ttotal: 1m 29s\tremaining: 5m 18s\n",
            "1150:\tlearn: 0.0450949\ttest: 0.2017914\tbest: 0.2017822 (1148)\ttotal: 1m 33s\tremaining: 5m 13s\n",
            "1200:\tlearn: 0.0424273\ttest: 0.2006533\tbest: 0.2006533 (1200)\ttotal: 1m 37s\tremaining: 5m 8s\n",
            "1250:\tlearn: 0.0399538\ttest: 0.1995543\tbest: 0.1995543 (1250)\ttotal: 1m 41s\tremaining: 5m 4s\n",
            "1300:\tlearn: 0.0375539\ttest: 0.1985755\tbest: 0.1985755 (1300)\ttotal: 1m 45s\tremaining: 5m\n",
            "1350:\tlearn: 0.0353668\ttest: 0.1970568\tbest: 0.1970568 (1350)\ttotal: 1m 49s\tremaining: 4m 55s\n",
            "1400:\tlearn: 0.0335168\ttest: 0.1959772\tbest: 0.1959598 (1397)\ttotal: 1m 53s\tremaining: 4m 51s\n",
            "1450:\tlearn: 0.0318027\ttest: 0.1947591\tbest: 0.1947591 (1450)\ttotal: 1m 57s\tremaining: 4m 47s\n",
            "1500:\tlearn: 0.0304107\ttest: 0.1941610\tbest: 0.1940926 (1497)\ttotal: 2m 1s\tremaining: 4m 42s\n",
            "1550:\tlearn: 0.0290123\ttest: 0.1932161\tbest: 0.1931702 (1547)\ttotal: 2m 5s\tremaining: 4m 38s\n",
            "1600:\tlearn: 0.0276249\ttest: 0.1915860\tbest: 0.1915860 (1600)\ttotal: 2m 9s\tremaining: 4m 34s\n",
            "1650:\tlearn: 0.0262617\ttest: 0.1913291\tbest: 0.1911887 (1641)\ttotal: 2m 13s\tremaining: 4m 30s\n",
            "1700:\tlearn: 0.0250697\ttest: 0.1907477\tbest: 0.1906646 (1677)\ttotal: 2m 17s\tremaining: 4m 26s\n",
            "1750:\tlearn: 0.0239849\ttest: 0.1900484\tbest: 0.1900484 (1750)\ttotal: 2m 21s\tremaining: 4m 22s\n",
            "1800:\tlearn: 0.0229032\ttest: 0.1896314\tbest: 0.1895524 (1773)\ttotal: 2m 25s\tremaining: 4m 18s\n",
            "1850:\tlearn: 0.0219196\ttest: 0.1891690\tbest: 0.1891676 (1849)\ttotal: 2m 29s\tremaining: 4m 14s\n",
            "1900:\tlearn: 0.0209772\ttest: 0.1877231\tbest: 0.1877231 (1900)\ttotal: 2m 33s\tremaining: 4m 10s\n",
            "1950:\tlearn: 0.0200837\ttest: 0.1872472\tbest: 0.1871940 (1939)\ttotal: 2m 37s\tremaining: 4m 6s\n",
            "2000:\tlearn: 0.0193024\ttest: 0.1870162\tbest: 0.1869790 (1999)\ttotal: 2m 41s\tremaining: 4m 2s\n",
            "2050:\tlearn: 0.0185384\ttest: 0.1867444\tbest: 0.1867070 (2041)\ttotal: 2m 45s\tremaining: 3m 58s\n",
            "2100:\tlearn: 0.0177904\ttest: 0.1862614\tbest: 0.1862281 (2086)\ttotal: 2m 49s\tremaining: 3m 54s\n",
            "2150:\tlearn: 0.0171915\ttest: 0.1859337\tbest: 0.1858846 (2142)\ttotal: 2m 53s\tremaining: 3m 50s\n",
            "2200:\tlearn: 0.0165752\ttest: 0.1853372\tbest: 0.1853372 (2200)\ttotal: 2m 58s\tremaining: 3m 46s\n",
            "2250:\tlearn: 0.0159825\ttest: 0.1850317\tbest: 0.1849354 (2248)\ttotal: 3m 2s\tremaining: 3m 42s\n",
            "2300:\tlearn: 0.0154220\ttest: 0.1848389\tbest: 0.1847140 (2296)\ttotal: 3m 6s\tremaining: 3m 38s\n",
            "2350:\tlearn: 0.0148587\ttest: 0.1846557\tbest: 0.1846101 (2331)\ttotal: 3m 10s\tremaining: 3m 34s\n",
            "2400:\tlearn: 0.0143291\ttest: 0.1845594\tbest: 0.1845044 (2390)\ttotal: 3m 14s\tremaining: 3m 30s\n",
            "2450:\tlearn: 0.0138297\ttest: 0.1843964\tbest: 0.1843523 (2421)\ttotal: 3m 18s\tremaining: 3m 26s\n",
            "2500:\tlearn: 0.0134235\ttest: 0.1844488\tbest: 0.1842882 (2462)\ttotal: 3m 22s\tremaining: 3m 21s\n",
            "2550:\tlearn: 0.0130240\ttest: 0.1839316\tbest: 0.1839316 (2550)\ttotal: 3m 25s\tremaining: 3m 17s\n",
            "2600:\tlearn: 0.0125905\ttest: 0.1836468\tbest: 0.1836468 (2600)\ttotal: 3m 29s\tremaining: 3m 13s\n",
            "2650:\tlearn: 0.0121804\ttest: 0.1839315\tbest: 0.1835157 (2627)\ttotal: 3m 33s\tremaining: 3m 9s\n",
            "2700:\tlearn: 0.0118054\ttest: 0.1840069\tbest: 0.1835157 (2627)\ttotal: 3m 37s\tremaining: 3m 5s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.1835156901\n",
            "bestIteration = 2627\n",
            "\n",
            "Shrink model to first 2628 iterations.\n",
            "0.9402098180248739\n",
            "第 2 个Fold\n",
            "0:\tlearn: 1.0200024\ttest: 1.0177934\tbest: 1.0177934 (0)\ttotal: 81.2ms\tremaining: 6m 45s\n",
            "50:\tlearn: 0.4496035\ttest: 0.4592174\tbest: 0.4592174 (50)\ttotal: 4.22s\tremaining: 6m 49s\n",
            "100:\tlearn: 0.3522860\ttest: 0.3861724\tbest: 0.3861724 (100)\ttotal: 8.29s\tremaining: 6m 41s\n",
            "150:\tlearn: 0.2884887\ttest: 0.3382509\tbest: 0.3382509 (150)\ttotal: 12.4s\tremaining: 6m 37s\n",
            "200:\tlearn: 0.2463236\ttest: 0.3107431\tbest: 0.3107431 (200)\ttotal: 16.5s\tremaining: 6m 34s\n",
            "250:\tlearn: 0.2128561\ttest: 0.2893317\tbest: 0.2893317 (250)\ttotal: 20.6s\tremaining: 6m 29s\n",
            "300:\tlearn: 0.1876043\ttest: 0.2741473\tbest: 0.2741473 (300)\ttotal: 24.6s\tremaining: 6m 24s\n",
            "350:\tlearn: 0.1654752\ttest: 0.2606432\tbest: 0.2606432 (350)\ttotal: 28.7s\tremaining: 6m 19s\n",
            "400:\tlearn: 0.1482723\ttest: 0.2486877\tbest: 0.2486877 (400)\ttotal: 32.8s\tremaining: 6m 16s\n",
            "450:\tlearn: 0.1336094\ttest: 0.2385470\tbest: 0.2385470 (450)\ttotal: 36.9s\tremaining: 6m 12s\n",
            "500:\tlearn: 0.1210586\ttest: 0.2303577\tbest: 0.2303577 (500)\ttotal: 41s\tremaining: 6m 7s\n",
            "550:\tlearn: 0.1099994\ttest: 0.2234576\tbest: 0.2234576 (550)\ttotal: 45s\tremaining: 6m 2s\n",
            "600:\tlearn: 0.0999575\ttest: 0.2172691\tbest: 0.2172691 (600)\ttotal: 49s\tremaining: 5m 58s\n",
            "650:\tlearn: 0.0911639\ttest: 0.2128604\tbest: 0.2128604 (650)\ttotal: 53.1s\tremaining: 5m 54s\n",
            "700:\tlearn: 0.0844170\ttest: 0.2086012\tbest: 0.2086012 (700)\ttotal: 57.1s\tremaining: 5m 49s\n",
            "750:\tlearn: 0.0778039\ttest: 0.2040267\tbest: 0.2040267 (750)\ttotal: 1m 1s\tremaining: 5m 45s\n",
            "800:\tlearn: 0.0715607\ttest: 0.2011905\tbest: 0.2011905 (800)\ttotal: 1m 5s\tremaining: 5m 41s\n",
            "850:\tlearn: 0.0666406\ttest: 0.1982866\tbest: 0.1982866 (850)\ttotal: 1m 9s\tremaining: 5m 37s\n",
            "900:\tlearn: 0.0622855\ttest: 0.1953236\tbest: 0.1953236 (900)\ttotal: 1m 13s\tremaining: 5m 33s\n",
            "950:\tlearn: 0.0581551\ttest: 0.1929677\tbest: 0.1929677 (950)\ttotal: 1m 17s\tremaining: 5m 29s\n",
            "1000:\tlearn: 0.0541334\ttest: 0.1908146\tbest: 0.1907830 (998)\ttotal: 1m 21s\tremaining: 5m 25s\n",
            "1050:\tlearn: 0.0508280\ttest: 0.1891066\tbest: 0.1891066 (1050)\ttotal: 1m 25s\tremaining: 5m 21s\n",
            "1100:\tlearn: 0.0477906\ttest: 0.1871823\tbest: 0.1871823 (1100)\ttotal: 1m 29s\tremaining: 5m 17s\n",
            "1150:\tlearn: 0.0450632\ttest: 0.1861553\tbest: 0.1861053 (1147)\ttotal: 1m 33s\tremaining: 5m 13s\n",
            "1200:\tlearn: 0.0423205\ttest: 0.1841887\tbest: 0.1841887 (1200)\ttotal: 1m 37s\tremaining: 5m 9s\n",
            "1250:\tlearn: 0.0398324\ttest: 0.1824313\tbest: 0.1824313 (1250)\ttotal: 1m 41s\tremaining: 5m 5s\n",
            "1300:\tlearn: 0.0377628\ttest: 0.1814214\tbest: 0.1814214 (1300)\ttotal: 1m 45s\tremaining: 5m\n",
            "1350:\tlearn: 0.0355835\ttest: 0.1796250\tbest: 0.1796250 (1350)\ttotal: 1m 50s\tremaining: 4m 57s\n",
            "1400:\tlearn: 0.0336210\ttest: 0.1789533\tbest: 0.1789533 (1400)\ttotal: 1m 54s\tremaining: 4m 52s\n",
            "1450:\tlearn: 0.0318834\ttest: 0.1774457\tbest: 0.1774457 (1450)\ttotal: 1m 58s\tremaining: 4m 48s\n",
            "1500:\tlearn: 0.0302236\ttest: 0.1767595\tbest: 0.1766567 (1490)\ttotal: 2m 2s\tremaining: 4m 44s\n",
            "1550:\tlearn: 0.0286554\ttest: 0.1753563\tbest: 0.1753563 (1550)\ttotal: 2m 6s\tremaining: 4m 40s\n",
            "1600:\tlearn: 0.0274026\ttest: 0.1743718\tbest: 0.1743718 (1600)\ttotal: 2m 10s\tremaining: 4m 36s\n",
            "1650:\tlearn: 0.0261168\ttest: 0.1735804\tbest: 0.1735147 (1648)\ttotal: 2m 14s\tremaining: 4m 32s\n",
            "1700:\tlearn: 0.0249537\ttest: 0.1728015\tbest: 0.1727767 (1699)\ttotal: 2m 18s\tremaining: 4m 28s\n",
            "1750:\tlearn: 0.0236859\ttest: 0.1721838\tbest: 0.1721685 (1749)\ttotal: 2m 22s\tremaining: 4m 24s\n",
            "1800:\tlearn: 0.0226162\ttest: 0.1714239\tbest: 0.1714043 (1798)\ttotal: 2m 26s\tremaining: 4m 20s\n",
            "1850:\tlearn: 0.0216687\ttest: 0.1706644\tbest: 0.1706644 (1850)\ttotal: 2m 30s\tremaining: 4m 16s\n",
            "1900:\tlearn: 0.0207012\ttest: 0.1696172\tbest: 0.1695569 (1897)\ttotal: 2m 34s\tremaining: 4m 12s\n",
            "1950:\tlearn: 0.0198619\ttest: 0.1686642\tbest: 0.1686552 (1949)\ttotal: 2m 38s\tremaining: 4m 8s\n",
            "2000:\tlearn: 0.0191221\ttest: 0.1682705\tbest: 0.1682705 (2000)\ttotal: 2m 42s\tremaining: 4m 4s\n",
            "2050:\tlearn: 0.0183654\ttest: 0.1680438\tbest: 0.1680438 (2050)\ttotal: 2m 46s\tremaining: 3m 59s\n",
            "2100:\tlearn: 0.0177447\ttest: 0.1675483\tbest: 0.1674890 (2094)\ttotal: 2m 50s\tremaining: 3m 55s\n",
            "2150:\tlearn: 0.0170426\ttest: 0.1670767\tbest: 0.1670245 (2134)\ttotal: 2m 55s\tremaining: 3m 51s\n",
            "2200:\tlearn: 0.0163914\ttest: 0.1667128\tbest: 0.1667128 (2200)\ttotal: 2m 59s\tremaining: 3m 47s\n",
            "2250:\tlearn: 0.0158085\ttest: 0.1663757\tbest: 0.1663614 (2233)\ttotal: 3m 3s\tremaining: 3m 43s\n",
            "2300:\tlearn: 0.0152991\ttest: 0.1661633\tbest: 0.1661196 (2288)\ttotal: 3m 7s\tremaining: 3m 39s\n",
            "2350:\tlearn: 0.0148078\ttest: 0.1658322\tbest: 0.1658322 (2350)\ttotal: 3m 11s\tremaining: 3m 35s\n",
            "2400:\tlearn: 0.0143076\ttest: 0.1657641\tbest: 0.1657401 (2399)\ttotal: 3m 15s\tremaining: 3m 31s\n",
            "2450:\tlearn: 0.0138833\ttest: 0.1653941\tbest: 0.1653941 (2450)\ttotal: 3m 19s\tremaining: 3m 27s\n",
            "2500:\tlearn: 0.0134234\ttest: 0.1650740\tbest: 0.1649893 (2484)\ttotal: 3m 23s\tremaining: 3m 23s\n",
            "2550:\tlearn: 0.0130593\ttest: 0.1647604\tbest: 0.1647285 (2545)\ttotal: 3m 27s\tremaining: 3m 19s\n",
            "2600:\tlearn: 0.0126793\ttest: 0.1646145\tbest: 0.1645817 (2595)\ttotal: 3m 31s\tremaining: 3m 15s\n",
            "2650:\tlearn: 0.0123256\ttest: 0.1645154\tbest: 0.1644832 (2623)\ttotal: 3m 35s\tremaining: 3m 10s\n",
            "2700:\tlearn: 0.0119368\ttest: 0.1644476\tbest: 0.1643637 (2658)\ttotal: 3m 39s\tremaining: 3m 6s\n",
            "2750:\tlearn: 0.0115752\ttest: 0.1642244\tbest: 0.1642102 (2748)\ttotal: 3m 43s\tremaining: 3m 2s\n",
            "2800:\tlearn: 0.0112512\ttest: 0.1640726\tbest: 0.1640485 (2799)\ttotal: 3m 47s\tremaining: 2m 58s\n",
            "2850:\tlearn: 0.0109252\ttest: 0.1639356\tbest: 0.1639240 (2849)\ttotal: 3m 51s\tremaining: 2m 54s\n",
            "2900:\tlearn: 0.0106292\ttest: 0.1638508\tbest: 0.1638047 (2899)\ttotal: 3m 55s\tremaining: 2m 50s\n",
            "2950:\tlearn: 0.0103446\ttest: 0.1638656\tbest: 0.1638047 (2899)\ttotal: 3m 59s\tremaining: 2m 46s\n",
            "3000:\tlearn: 0.0100762\ttest: 0.1636962\tbest: 0.1636505 (2996)\ttotal: 4m 3s\tremaining: 2m 42s\n",
            "3050:\tlearn: 0.0098126\ttest: 0.1634418\tbest: 0.1634418 (3050)\ttotal: 4m 7s\tremaining: 2m 38s\n",
            "3100:\tlearn: 0.0095681\ttest: 0.1631524\tbest: 0.1631289 (3084)\ttotal: 4m 11s\tremaining: 2m 34s\n",
            "3150:\tlearn: 0.0093255\ttest: 0.1631748\tbest: 0.1631124 (3105)\ttotal: 4m 16s\tremaining: 2m 30s\n",
            "3200:\tlearn: 0.0090701\ttest: 0.1631024\tbest: 0.1629531 (3174)\ttotal: 4m 20s\tremaining: 2m 26s\n",
            "3250:\tlearn: 0.0088576\ttest: 0.1630722\tbest: 0.1629531 (3174)\ttotal: 4m 23s\tremaining: 2m 22s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.1629531042\n",
            "bestIteration = 3174\n",
            "\n",
            "Shrink model to first 3175 iterations.\n",
            "0.9379818172430875\n",
            "第 3 个Fold\n",
            "0:\tlearn: 1.0145552\ttest: 1.0164540\tbest: 1.0164540 (0)\ttotal: 82.5ms\tremaining: 6m 52s\n",
            "50:\tlearn: 0.4450298\ttest: 0.4809307\tbest: 0.4809307 (50)\ttotal: 4.3s\tremaining: 6m 57s\n",
            "100:\tlearn: 0.3539895\ttest: 0.4101643\tbest: 0.4101643 (100)\ttotal: 8.38s\tremaining: 6m 46s\n",
            "150:\tlearn: 0.2900037\ttest: 0.3637788\tbest: 0.3637788 (150)\ttotal: 12.4s\tremaining: 6m 39s\n",
            "200:\tlearn: 0.2467146\ttest: 0.3341450\tbest: 0.3341450 (200)\ttotal: 16.4s\tremaining: 6m 32s\n",
            "250:\tlearn: 0.2145497\ttest: 0.3124018\tbest: 0.3124018 (250)\ttotal: 20.6s\tremaining: 6m 29s\n",
            "300:\tlearn: 0.1879354\ttest: 0.2924279\tbest: 0.2924279 (300)\ttotal: 24.7s\tremaining: 6m 25s\n",
            "350:\tlearn: 0.1670224\ttest: 0.2781532\tbest: 0.2781532 (350)\ttotal: 28.7s\tremaining: 6m 19s\n",
            "400:\tlearn: 0.1494109\ttest: 0.2654515\tbest: 0.2654515 (400)\ttotal: 32.7s\tremaining: 6m 14s\n",
            "450:\tlearn: 0.1335907\ttest: 0.2547571\tbest: 0.2547571 (450)\ttotal: 36.7s\tremaining: 6m 10s\n",
            "500:\tlearn: 0.1203585\ttest: 0.2460317\tbest: 0.2460317 (500)\ttotal: 40.7s\tremaining: 6m 5s\n",
            "550:\tlearn: 0.1086685\ttest: 0.2377551\tbest: 0.2377551 (550)\ttotal: 44.8s\tremaining: 6m 1s\n",
            "600:\tlearn: 0.0995483\ttest: 0.2314832\tbest: 0.2314832 (600)\ttotal: 48.8s\tremaining: 5m 57s\n",
            "650:\tlearn: 0.0911813\ttest: 0.2250778\tbest: 0.2250778 (650)\ttotal: 52.9s\tremaining: 5m 53s\n",
            "700:\tlearn: 0.0835877\ttest: 0.2205025\tbest: 0.2205025 (700)\ttotal: 57s\tremaining: 5m 49s\n",
            "750:\tlearn: 0.0767296\ttest: 0.2164193\tbest: 0.2163424 (749)\ttotal: 1m 1s\tremaining: 5m 45s\n",
            "800:\tlearn: 0.0706093\ttest: 0.2125555\tbest: 0.2125555 (800)\ttotal: 1m 5s\tremaining: 5m 42s\n",
            "850:\tlearn: 0.0657079\ttest: 0.2095517\tbest: 0.2095517 (850)\ttotal: 1m 9s\tremaining: 5m 37s\n",
            "900:\tlearn: 0.0610284\ttest: 0.2066749\tbest: 0.2066749 (900)\ttotal: 1m 13s\tremaining: 5m 33s\n",
            "950:\tlearn: 0.0570073\ttest: 0.2039371\tbest: 0.2039371 (950)\ttotal: 1m 17s\tremaining: 5m 29s\n",
            "1000:\tlearn: 0.0533939\ttest: 0.2017399\tbest: 0.2017399 (1000)\ttotal: 1m 21s\tremaining: 5m 25s\n",
            "1050:\tlearn: 0.0496996\ttest: 0.1994472\tbest: 0.1993975 (1049)\ttotal: 1m 25s\tremaining: 5m 21s\n",
            "1100:\tlearn: 0.0462219\ttest: 0.1965181\tbest: 0.1964865 (1098)\ttotal: 1m 29s\tremaining: 5m 16s\n",
            "1150:\tlearn: 0.0433403\ttest: 0.1948565\tbest: 0.1948301 (1146)\ttotal: 1m 33s\tremaining: 5m 13s\n",
            "1200:\tlearn: 0.0407721\ttest: 0.1931647\tbest: 0.1931647 (1200)\ttotal: 1m 37s\tremaining: 5m 8s\n",
            "1250:\tlearn: 0.0383954\ttest: 0.1909209\tbest: 0.1909209 (1250)\ttotal: 1m 41s\tremaining: 5m 4s\n",
            "1300:\tlearn: 0.0360062\ttest: 0.1887066\tbest: 0.1887066 (1300)\ttotal: 1m 45s\tremaining: 5m\n",
            "1350:\tlearn: 0.0340645\ttest: 0.1872731\tbest: 0.1872731 (1350)\ttotal: 1m 49s\tremaining: 4m 57s\n",
            "1400:\tlearn: 0.0322528\ttest: 0.1861361\tbest: 0.1861361 (1400)\ttotal: 1m 54s\tremaining: 4m 52s\n",
            "1450:\tlearn: 0.0306286\ttest: 0.1849489\tbest: 0.1849161 (1446)\ttotal: 1m 58s\tremaining: 4m 48s\n",
            "1500:\tlearn: 0.0290337\ttest: 0.1837861\tbest: 0.1837663 (1499)\ttotal: 2m 2s\tremaining: 4m 44s\n",
            "1550:\tlearn: 0.0275991\ttest: 0.1831954\tbest: 0.1831954 (1550)\ttotal: 2m 6s\tremaining: 4m 40s\n",
            "1600:\tlearn: 0.0263704\ttest: 0.1824520\tbest: 0.1824520 (1600)\ttotal: 2m 10s\tremaining: 4m 36s\n",
            "1650:\tlearn: 0.0251438\ttest: 0.1819857\tbest: 0.1819690 (1637)\ttotal: 2m 14s\tremaining: 4m 32s\n",
            "1700:\tlearn: 0.0239416\ttest: 0.1811479\tbest: 0.1811479 (1700)\ttotal: 2m 18s\tremaining: 4m 28s\n",
            "1750:\tlearn: 0.0229473\ttest: 0.1804103\tbest: 0.1804103 (1750)\ttotal: 2m 22s\tremaining: 4m 24s\n",
            "1800:\tlearn: 0.0220137\ttest: 0.1799232\tbest: 0.1799232 (1800)\ttotal: 2m 26s\tremaining: 4m 20s\n",
            "1850:\tlearn: 0.0210992\ttest: 0.1791251\tbest: 0.1791251 (1850)\ttotal: 2m 30s\tremaining: 4m 16s\n",
            "1900:\tlearn: 0.0202172\ttest: 0.1786058\tbest: 0.1786058 (1900)\ttotal: 2m 34s\tremaining: 4m 12s\n",
            "1950:\tlearn: 0.0193981\ttest: 0.1779672\tbest: 0.1778980 (1937)\ttotal: 2m 38s\tremaining: 4m 7s\n",
            "2000:\tlearn: 0.0186361\ttest: 0.1772632\tbest: 0.1772539 (1999)\ttotal: 2m 42s\tremaining: 4m 3s\n",
            "2050:\tlearn: 0.0179007\ttest: 0.1763249\tbest: 0.1763249 (2050)\ttotal: 2m 46s\tremaining: 3m 59s\n",
            "2100:\tlearn: 0.0172512\ttest: 0.1763799\tbest: 0.1762380 (2075)\ttotal: 2m 51s\tremaining: 3m 55s\n",
            "2150:\tlearn: 0.0166274\ttest: 0.1763563\tbest: 0.1762380 (2075)\ttotal: 2m 55s\tremaining: 3m 51s\n",
            "2200:\tlearn: 0.0160022\ttest: 0.1761525\tbest: 0.1761348 (2199)\ttotal: 2m 59s\tremaining: 3m 47s\n",
            "2250:\tlearn: 0.0154432\ttest: 0.1759949\tbest: 0.1758905 (2233)\ttotal: 3m 3s\tremaining: 3m 43s\n",
            "2300:\tlearn: 0.0149089\ttest: 0.1759599\tbest: 0.1758608 (2274)\ttotal: 3m 7s\tremaining: 3m 39s\n",
            "2350:\tlearn: 0.0144078\ttest: 0.1755636\tbest: 0.1754459 (2334)\ttotal: 3m 11s\tremaining: 3m 35s\n",
            "2400:\tlearn: 0.0139526\ttest: 0.1754639\tbest: 0.1753743 (2389)\ttotal: 3m 15s\tremaining: 3m 31s\n",
            "2450:\tlearn: 0.0134783\ttest: 0.1754158\tbest: 0.1752919 (2442)\ttotal: 3m 19s\tremaining: 3m 27s\n",
            "2500:\tlearn: 0.0130819\ttest: 0.1754176\tbest: 0.1752919 (2442)\ttotal: 3m 23s\tremaining: 3m 23s\n",
            "2550:\tlearn: 0.0126888\ttest: 0.1748246\tbest: 0.1748246 (2550)\ttotal: 3m 27s\tremaining: 3m 19s\n",
            "2600:\tlearn: 0.0123162\ttest: 0.1747942\tbest: 0.1746913 (2556)\ttotal: 3m 31s\tremaining: 3m 14s\n",
            "2650:\tlearn: 0.0119423\ttest: 0.1744204\tbest: 0.1744204 (2650)\ttotal: 3m 35s\tremaining: 3m 10s\n",
            "2700:\tlearn: 0.0115893\ttest: 0.1741839\tbest: 0.1741345 (2687)\ttotal: 3m 39s\tremaining: 3m 6s\n",
            "2750:\tlearn: 0.0112444\ttest: 0.1738023\tbest: 0.1737577 (2743)\ttotal: 3m 43s\tremaining: 3m 2s\n",
            "2800:\tlearn: 0.0108910\ttest: 0.1738445\tbest: 0.1737214 (2774)\ttotal: 3m 47s\tremaining: 2m 58s\n",
            "2850:\tlearn: 0.0106120\ttest: 0.1740306\tbest: 0.1737214 (2774)\ttotal: 3m 51s\tremaining: 2m 54s\n",
            "2900:\tlearn: 0.0103277\ttest: 0.1733816\tbest: 0.1733816 (2900)\ttotal: 3m 55s\tremaining: 2m 50s\n",
            "2950:\tlearn: 0.0100530\ttest: 0.1729112\tbest: 0.1728761 (2946)\ttotal: 3m 59s\tremaining: 2m 46s\n",
            "3000:\tlearn: 0.0098120\ttest: 0.1727262\tbest: 0.1727134 (2991)\ttotal: 4m 3s\tremaining: 2m 42s\n",
            "3050:\tlearn: 0.0095562\ttest: 0.1725644\tbest: 0.1725316 (3046)\ttotal: 4m 7s\tremaining: 2m 37s\n",
            "3100:\tlearn: 0.0093066\ttest: 0.1726277\tbest: 0.1725199 (3082)\ttotal: 4m 11s\tremaining: 2m 33s\n",
            "3150:\tlearn: 0.0090598\ttest: 0.1723123\tbest: 0.1723123 (3150)\ttotal: 4m 15s\tremaining: 2m 29s\n",
            "3200:\tlearn: 0.0088346\ttest: 0.1720871\tbest: 0.1720754 (3198)\ttotal: 4m 18s\tremaining: 2m 25s\n",
            "3250:\tlearn: 0.0086136\ttest: 0.1719798\tbest: 0.1719415 (3208)\ttotal: 4m 22s\tremaining: 2m 21s\n",
            "3300:\tlearn: 0.0084082\ttest: 0.1718488\tbest: 0.1718350 (3298)\ttotal: 4m 26s\tremaining: 2m 17s\n",
            "3350:\tlearn: 0.0082281\ttest: 0.1716980\tbest: 0.1716821 (3342)\ttotal: 4m 30s\tremaining: 2m 13s\n",
            "3400:\tlearn: 0.0080261\ttest: 0.1715416\tbest: 0.1715019 (3395)\ttotal: 4m 34s\tremaining: 2m 9s\n",
            "3450:\tlearn: 0.0078497\ttest: 0.1714145\tbest: 0.1713738 (3413)\ttotal: 4m 38s\tremaining: 2m 5s\n",
            "3500:\tlearn: 0.0076560\ttest: 0.1714615\tbest: 0.1713738 (3413)\ttotal: 4m 42s\tremaining: 2m 1s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.171373774\n",
            "bestIteration = 3413\n",
            "\n",
            "Shrink model to first 3414 iterations.\n",
            "0.9362873389016562\n",
            "第 4 个Fold\n",
            "0:\tlearn: 1.0167470\ttest: 1.0185589\tbest: 1.0185589 (0)\ttotal: 79.2ms\tremaining: 6m 35s\n",
            "50:\tlearn: 0.4449429\ttest: 0.4887100\tbest: 0.4887100 (50)\ttotal: 4.17s\tremaining: 6m 44s\n",
            "100:\tlearn: 0.3488614\ttest: 0.4168058\tbest: 0.4168058 (100)\ttotal: 8.13s\tremaining: 6m 34s\n",
            "150:\tlearn: 0.2850638\ttest: 0.3679280\tbest: 0.3679280 (150)\ttotal: 12.1s\tremaining: 6m 27s\n",
            "200:\tlearn: 0.2421517\ttest: 0.3405768\tbest: 0.3405768 (200)\ttotal: 16s\tremaining: 6m 21s\n",
            "250:\tlearn: 0.2080217\ttest: 0.3181636\tbest: 0.3181636 (250)\ttotal: 20.1s\tremaining: 6m 19s\n",
            "300:\tlearn: 0.1830976\ttest: 0.3022982\tbest: 0.3022982 (300)\ttotal: 24s\tremaining: 6m 15s\n",
            "350:\tlearn: 0.1629775\ttest: 0.2901217\tbest: 0.2901217 (350)\ttotal: 27.9s\tremaining: 6m 10s\n",
            "400:\tlearn: 0.1456503\ttest: 0.2780615\tbest: 0.2780615 (400)\ttotal: 31.9s\tremaining: 6m 5s\n",
            "450:\tlearn: 0.1317647\ttest: 0.2685075\tbest: 0.2685075 (450)\ttotal: 35.8s\tremaining: 6m 1s\n",
            "500:\tlearn: 0.1189593\ttest: 0.2629622\tbest: 0.2629622 (500)\ttotal: 39.8s\tremaining: 5m 57s\n",
            "550:\tlearn: 0.1079863\ttest: 0.2572238\tbest: 0.2572238 (550)\ttotal: 43.7s\tremaining: 5m 53s\n",
            "600:\tlearn: 0.0987490\ttest: 0.2518564\tbest: 0.2518564 (600)\ttotal: 47.6s\tremaining: 5m 48s\n",
            "650:\tlearn: 0.0903081\ttest: 0.2457818\tbest: 0.2457818 (650)\ttotal: 51.5s\tremaining: 5m 44s\n",
            "700:\tlearn: 0.0830431\ttest: 0.2419419\tbest: 0.2419419 (700)\ttotal: 55.5s\tremaining: 5m 40s\n",
            "750:\tlearn: 0.0767588\ttest: 0.2380618\tbest: 0.2380468 (748)\ttotal: 59.4s\tremaining: 5m 35s\n",
            "800:\tlearn: 0.0712220\ttest: 0.2346224\tbest: 0.2345765 (799)\ttotal: 1m 3s\tremaining: 5m 32s\n",
            "850:\tlearn: 0.0657001\ttest: 0.2305778\tbest: 0.2305778 (850)\ttotal: 1m 7s\tremaining: 5m 28s\n",
            "900:\tlearn: 0.0615906\ttest: 0.2278164\tbest: 0.2278113 (899)\ttotal: 1m 11s\tremaining: 5m 23s\n",
            "950:\tlearn: 0.0573235\ttest: 0.2250044\tbest: 0.2249973 (949)\ttotal: 1m 15s\tremaining: 5m 19s\n",
            "1000:\tlearn: 0.0534509\ttest: 0.2217461\tbest: 0.2217461 (1000)\ttotal: 1m 19s\tremaining: 5m 16s\n",
            "1050:\tlearn: 0.0501274\ttest: 0.2195223\tbest: 0.2195223 (1050)\ttotal: 1m 23s\tremaining: 5m 12s\n",
            "1100:\tlearn: 0.0466744\ttest: 0.2172068\tbest: 0.2172068 (1100)\ttotal: 1m 27s\tremaining: 5m 8s\n",
            "1150:\tlearn: 0.0439483\ttest: 0.2157461\tbest: 0.2157461 (1150)\ttotal: 1m 30s\tremaining: 5m 4s\n",
            "1200:\tlearn: 0.0413038\ttest: 0.2147831\tbest: 0.2147262 (1189)\ttotal: 1m 34s\tremaining: 4m 59s\n",
            "1250:\tlearn: 0.0390349\ttest: 0.2130547\tbest: 0.2130042 (1246)\ttotal: 1m 38s\tremaining: 4m 56s\n",
            "1300:\tlearn: 0.0366698\ttest: 0.2109859\tbest: 0.2109859 (1300)\ttotal: 1m 42s\tremaining: 4m 52s\n",
            "1350:\tlearn: 0.0344839\ttest: 0.2096121\tbest: 0.2096121 (1350)\ttotal: 1m 46s\tremaining: 4m 48s\n",
            "1400:\tlearn: 0.0326848\ttest: 0.2083143\tbest: 0.2082948 (1399)\ttotal: 1m 50s\tremaining: 4m 43s\n",
            "1450:\tlearn: 0.0308916\ttest: 0.2070564\tbest: 0.2070337 (1449)\ttotal: 1m 54s\tremaining: 4m 40s\n",
            "1500:\tlearn: 0.0293150\ttest: 0.2055809\tbest: 0.2055587 (1494)\ttotal: 1m 58s\tremaining: 4m 35s\n",
            "1550:\tlearn: 0.0278821\ttest: 0.2050924\tbest: 0.2047536 (1540)\ttotal: 2m 2s\tremaining: 4m 32s\n",
            "1600:\tlearn: 0.0265206\ttest: 0.2039307\tbest: 0.2039307 (1600)\ttotal: 2m 6s\tremaining: 4m 28s\n",
            "1650:\tlearn: 0.0252598\ttest: 0.2026023\tbest: 0.2026023 (1650)\ttotal: 2m 10s\tremaining: 4m 24s\n",
            "1700:\tlearn: 0.0241475\ttest: 0.2012629\tbest: 0.2012629 (1700)\ttotal: 2m 14s\tremaining: 4m 20s\n",
            "1750:\tlearn: 0.0230409\ttest: 0.2007320\tbest: 0.2006541 (1747)\ttotal: 2m 18s\tremaining: 4m 16s\n",
            "1800:\tlearn: 0.0220153\ttest: 0.2003508\tbest: 0.2002699 (1795)\ttotal: 2m 22s\tremaining: 4m 12s\n",
            "1850:\tlearn: 0.0212232\ttest: 0.2001505\tbest: 0.2000748 (1847)\ttotal: 2m 26s\tremaining: 4m 8s\n",
            "1900:\tlearn: 0.0203840\ttest: 0.1997879\tbest: 0.1995381 (1891)\ttotal: 2m 29s\tremaining: 4m 4s\n",
            "1950:\tlearn: 0.0196128\ttest: 0.1992388\tbest: 0.1990145 (1946)\ttotal: 2m 33s\tremaining: 4m\n",
            "2000:\tlearn: 0.0189184\ttest: 0.1989816\tbest: 0.1988145 (1997)\ttotal: 2m 37s\tremaining: 3m 56s\n",
            "2050:\tlearn: 0.0181810\ttest: 0.1981576\tbest: 0.1981576 (2050)\ttotal: 2m 41s\tremaining: 3m 52s\n",
            "2100:\tlearn: 0.0174864\ttest: 0.1976630\tbest: 0.1976630 (2100)\ttotal: 2m 45s\tremaining: 3m 48s\n",
            "2150:\tlearn: 0.0168469\ttest: 0.1975185\tbest: 0.1974039 (2140)\ttotal: 2m 49s\tremaining: 3m 44s\n",
            "2200:\tlearn: 0.0162781\ttest: 0.1970970\tbest: 0.1970796 (2194)\ttotal: 2m 53s\tremaining: 3m 40s\n",
            "2250:\tlearn: 0.0157250\ttest: 0.1968814\tbest: 0.1968154 (2244)\ttotal: 2m 57s\tremaining: 3m 36s\n",
            "2300:\tlearn: 0.0151733\ttest: 0.1965183\tbest: 0.1964858 (2296)\ttotal: 3m 1s\tremaining: 3m 32s\n",
            "2350:\tlearn: 0.0146068\ttest: 0.1960001\tbest: 0.1960001 (2350)\ttotal: 3m 5s\tremaining: 3m 28s\n",
            "2400:\tlearn: 0.0140781\ttest: 0.1960040\tbest: 0.1958111 (2356)\ttotal: 3m 9s\tremaining: 3m 24s\n",
            "2450:\tlearn: 0.0136337\ttest: 0.1959548\tbest: 0.1958111 (2356)\ttotal: 3m 13s\tremaining: 3m 20s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.1958111037\n",
            "bestIteration = 2356\n",
            "\n",
            "Shrink model to first 2357 iterations.\n",
            "0.9284584848543692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYX1BDshupDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yu_type = {0:'拖网',1:'围网',2:'刺网'}\n",
        "res = finalRes(selectMost(cat_preds))\n",
        "sub = test_dataset[['ship']]\n",
        "sub['pred'] = res\n",
        "sub.to_csv('/content/drive/My Drive/result_cat.csv',index=False,header=False,encoding='utf_8_sig')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB6tdyOolQQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}